Project Structure:
📁 pedalboard-pluginary
├── 📁 external
│   └── 📁 pedalboard
├── 📁 issues
│   ├── 📄 201.txt
│   └── 📄 202.txt
├── 📁 scripts
│   ├── 📄 format.sh
│   ├── 📄 release.sh
│   └── 📄 test.sh
├── 📁 src
│   ├── 📁 pedalboard-stubs
│   │   ├── 📄 __init__.pyi
│   │   └── 📄 py.typed
│   ├── 📁 pedalboard_pluginary
│   │   ├── 📁 cache
│   │   │   ├── 📄 __init__.py
│   │   │   ├── 📄 json_backend.py
│   │   │   ├── 📄 migration.py
│   │   │   └── 📄 sqlite_backend.py
│   │   ├── 📁 resources
│   │   │   └── 📄 default_ignores.json
│   │   ├── 📄 __init__.py
│   │   ├── 📄 __main__.py
│   │   ├── 📄 constants.py
│   │   ├── 📄 core.py
│   │   ├── 📄 data.py
│   │   ├── 📄 exceptions.py
│   │   ├── 📄 models.py
│   │   ├── 📄 progress.py
│   │   ├── 📄 protocols.py
│   │   ├── 📄 py.typed
│   │   ├── 📄 retry.py
│   │   ├── 📄 scan_single.py
│   │   ├── 📄 scanner_clean.py
│   │   ├── 📄 scanner_isolated.py
│   │   ├── 📄 serialization.py
│   │   ├── 📄 timeout.py
│   │   ├── 📄 types.py
│   │   └── 📄 utils.py
│   └── 📁 pedalboard_pluginary.egg-info
├── 📁 tests
│   ├── 📁 scanners
│   │   ├── 📄 __init__.py
│   │   ├── 📄 test_au_scanner.py
│   │   └── 📄 test_vst3_scanner.py
│   ├── 📄 test_core.py
│   ├── 📄 test_data.py
│   ├── 📄 test_exceptions.py
│   ├── 📄 test_failsafe_integration.py
│   ├── 📄 test_journal.py
│   ├── 📄 test_models.py
│   ├── 📄 test_serialization.py
│   ├── 📄 test_sqlite_performance.py
│   └── 📄 test_utils.py
├── 📄 .gitignore
├── 📄 AGENTS.md
├── 📄 AUTHORS.md
├── 📄 CHANGELOG.md
├── 📄 CLAUDE.md
├── 📄 DEVELOPMENT.md
├── 📄 GEMINI.md
├── 📄 LICENSE.txt
├── 📄 PLAN.md
├── 📄 publish.sh
├── 📄 pyproject.toml
├── 📄 README.md
├── 📄 TODO.md
└── 📄 WORK.md


<documents>
<document index="1">
<source>.coveragerc</source>
<document_content>
# .coveragerc to control coverage.py
[run]
branch = True
source = pedalboard_pluginary
# omit = bad_file.py

[paths]
source =
    src/
    */site-packages/

[report]
# Regexes for lines to exclude from consideration
exclude_lines =
    # Have to re-enable the standard pragma
    pragma: no cover

    # Don't complain about missing debug-only code:
    def __repr__
    if self\.debug

    # Don't complain if tests don't hit defensive assertion code:
    raise AssertionError
    raise NotImplementedError

    # Don't complain if non-runnable code isn't run:
    if 0:
    if __name__ == .__main__.:

</document_content>
</document>

<document index="2">
<source>.cursorrules</source>
<document_content>
# Pedalboard Pluginary

## 1. Overview

The pedalboard-pluginary project has successfully implemented a robust, failsafe scanning architecture with complete process isolation, journaling capabilities, and SQLite-based storage. The system reliably scans audio plugins (VST3, AU) with crash recovery, resume functionality, and efficient data storage.

## 2. Current Architecture (Completed)

### 2.1. Core System Components
- **Process Isolation**: Each plugin scanned in separate subprocess via `scan_single.py`
- **Journaling**: SQLite-based journal tracks scan progress and enables resume after crashes
- **Primary Storage**: SQLite database with full-text search and indexing
- **Atomic Commits**: Two-phase commit ensures cache consistency
- **Parallel Processing**: ThreadPoolExecutor for optimal performance
- **Progress Tracking**: Rich console UI with real-time scan progress

### 2.2. Key Modules
- `scanner_isolated.py`: Main scanner orchestrator with ScanJournal integration
- `scan_single.py`: Standalone CLI for scanning individual plugins
- `cache/sqlite_backend.py`: SQLite cache backend with FTS5 search
- Rich CLI interface with commands: scan, update, list, info, json, yaml

### 2.3. Recent Achievements (2025-08-06)
- Successfully migrated to SQLite as sole storage backend
- Fixed all critical scanner and journal issues
- Achieved successful scanning of 289 plugins
- JSON/YAML export working from SQLite
- Eliminated dependency on JSON file storage


# Software Development Rules

## 3. Pre-Work Preparation

### 3.1. Before Starting Any Work
- **ALWAYS** read `WORK.md` in the main project folder for work progress
- Read `README.md` to understand the project
- STEP BACK and THINK HEAVILY STEP BY STEP about the task
- Consider alternatives and carefully choose the best option
- Check for existing solutions in the codebase before starting

### 3.2. Project Documentation to Maintain
- `README.md` - purpose and functionality
- `CHANGELOG.md` - past change release notes (accumulative)
- `PLAN.md` - detailed future goals, clear plan that discusses specifics
- `TODO.md` - flat simplified itemized `- [ ]`-prefixed representation of `PLAN.md`
- `WORK.md` - work progress updates

## 4. General Coding Principles

### 4.1. Core Development Approach
- Iterate gradually, avoiding major changes
- Focus on minimal viable increments and ship early
- Minimize confirmations and checks
- Preserve existing code/structure unless necessary
- Check often the coherence of the code you're writing with the rest of the code
- Analyze code line-by-line

### 4.2. Code Quality Standards
- Use constants over magic numbers
- Write explanatory docstrings/comments that explain what and WHY
- Explain where and how the code is used/referred to elsewhere
- Handle failures gracefully with retries, fallbacks, user guidance
- Address edge cases, validate assumptions, catch errors early
- Let the computer do the work, minimize user decisions
- Reduce cognitive load, beautify code
- Modularize repeated logic into concise, single-purpose functions
- Favor flat over nested structures

## 5. Tool Usage (When Available)

### 5.1. Additional Tools
- If we need a new Python project, run `curl -LsSf https://astral.sh/uv/install.sh | sh; uv venv --python 3.12; uv init; uv add fire rich; uv sync`
- Use `tree` CLI app if available to verify file locations
- Check existing code with `.venv` folder to scan and consult dependency source code
- Run `DIR="."; uvx codetoprompt --compress --output "$DIR/llms.txt"  --respect-gitignore --cxml --exclude "*.svg,.specstory,*.md,*.txt,ref,testdata,*.lock,*.svg" "$DIR"` to get a condensed snapshot of the codebase into `llms.txt`

## 6. File Management

### 6.1. File Path Tracking
- **MANDATORY**: In every source file, maintain a `this_file` record showing the path relative to project root
- Place `this_file` record near the top:
- As a comment after shebangs in code files
- In YAML frontmatter for Markdown files
- Update paths when moving files
- Omit leading `./`
- Check `this_file` to confirm you're editing the right file

## 7. Python-Specific Guidelines

### 7.1. PEP Standards
- PEP 8: Use consistent formatting and naming, clear descriptive names
- PEP 20: Keep code simple and explicit, prioritize readability over cleverness
- PEP 257: Write clear, imperative docstrings
- Use type hints in their simplest form (list, dict, | for unions)

### 7.2. Modern Python Practices
- Use f-strings and structural pattern matching where appropriate
- Write modern code with `pathlib`
- ALWAYS add "verbose" mode loguru-based logging & debug-log
- Use `uv add` 
- Use `uv pip install` instead of `pip install`
- Prefix Python CLI tools with `python -m` (e.g., `python -m pytest`)

### 7.3. CLI Scripts Setup
For CLI Python scripts, use `fire` & `rich`, and start with:
```python
#!/usr/bin/env -S uv run -s
# /// script
# dependencies = ["PKG1", "PKG2"]
# ///
# this_file: PATH_TO_CURRENT_FILE
```

### 7.4. Post-Edit Python Commands
```bash
fd -e py -x uvx autoflake -i {}; fd -e py -x uvx pyupgrade --py312-plus {}; fd -e py -x uvx ruff check --output-format=github --fix --unsafe-fixes {}; fd -e py -x uvx ruff format --respect-gitignore --target-version py312 {}; python -m pytest;
```

## 8. Post-Work Activities

### 8.1. Critical Reflection
- After completing a step, say "Wait, but" and do additional careful critical reasoning
- Go back, think & reflect, revise & improve what you've done
- Don't invent functionality freely
- Stick to the goal of "minimal viable next version"

### 8.2. Documentation Updates
- Update `WORK.md` with what you've done and what needs to be done next
- Document all changes in `CHANGELOG.md`
- Update `TODO.md` and `PLAN.md` accordingly

## 9. Work Methodology

### 9.1. Virtual Team Approach
Be creative, diligent, critical, relentless & funny! Lead two experts:
- **"Ideot"** - for creative, unorthodox ideas
- **"Critin"** - to critique flawed thinking and moderate for balanced discussions

Collaborate step-by-step, sharing thoughts and adapting. If errors are found, step back and focus on accuracy and progress.

### 9.2. Continuous Work Mode
- Treat all items in `PLAN.md` and `TODO.md` as one huge TASK
- Work on implementing the next item
- Review, reflect, refine, revise your implementation
- Periodically check off completed issues
- Continue to the next item without interruption

## 10. Special Commands

### 10.1. `/plan` Command - Transform Requirements into Detailed Plans

When I say "/plan [requirement]", you must:

1. **DECONSTRUCT** the requirement:
- Extract core intent, key features, and objectives
- Identify technical requirements and constraints
- Map what's explicitly stated vs. what's implied
- Determine success criteria

2. **DIAGNOSE** the project needs:
- Audit for missing specifications
- Check technical feasibility
- Assess complexity and dependencies
- Identify potential challenges

3. **RESEARCH** additional material: 
- Repeatedly call the `perplexity_ask` and request up-to-date information or additional remote context
- Repeatedly call the `context7` tool and request up-to-date software package documentation
- Repeatedly call the `codex` tool and request additional reasoning, summarization of files and second opinion

4. **DEVELOP** the plan structure:
- Break down into logical phases/milestones
- Create hierarchical task decomposition
- Assign priorities and dependencies
- Add implementation details and technical specs
- Include edge cases and error handling
- Define testing and validation steps

5. **DELIVER** to `PLAN.md`:
- Write a comprehensive, detailed plan with:
 - Project overview and objectives
 - Technical architecture decisions
 - Phase-by-phase breakdown
 - Specific implementation steps
 - Testing and validation criteria
 - Future considerations
- Simultaneously create/update `TODO.md` with the flat itemized `- [ ]` representation

**Plan Optimization Techniques:**
- **Task Decomposition:** Break complex requirements into atomic, actionable tasks
- **Dependency Mapping:** Identify and document task dependencies
- **Risk Assessment:** Include potential blockers and mitigation strategies
- **Progressive Enhancement:** Start with MVP, then layer improvements
- **Technical Specifications:** Include specific technologies, patterns, and approaches

### 10.2. `/report` Command

1. Read all `./TODO.md` and `./PLAN.md` files
2. Analyze recent changes
3. Document all changes in `./CHANGELOG.md`
4. Remove completed items from `./TODO.md` and `./PLAN.md`
5. Ensure `./PLAN.md` contains detailed, clear plans with specifics
6. Ensure `./TODO.md` is a flat simplified itemized representation

### 10.3. `/work` Command

1. Read all `./TODO.md` and `./PLAN.md` files and reflect
2. Write down the immediate items in this iteration into `./WORK.md`
3. Work on these items
4. Think, contemplate, research, reflect, refine, revise
5. Be careful, curious, vigilant, energetic
6. Verify your changes and think aloud
7. Consult, research, reflect
8. Periodically remove completed items from `./WORK.md`
9. Tick off completed items from `./TODO.md` and `./PLAN.md`
10. Update `./WORK.md` with improvement tasks
11. Execute `/report`
12. Continue to the next item

## 11. Additional Guidelines

- Ask before extending/refactoring existing code that may add complexity or break things
- Work tirelessly without constant updates when in continuous work mode
- Only notify when you've completed all `PLAN.md` and `TODO.md` items

## 12. Command Summary

- `/plan [requirement]` - Transform vague requirements into detailed `PLAN.md` and `TODO.md`
- `/report` - Update documentation and clean up completed tasks
- `/work` - Enter continuous work mode to implement plans
- You may use these commands autonomously when appropriate


</document_content>
</document>

<document index="3">
<source>.gitignore</source>
<document_content>
temp/

# Temporary and binary files
*~
*.py[cod]
*.so
*.cfg
!.isort.cfg
!setup.cfg
*.orig
*.log
*.pot
__pycache__/*
.cache/*
.*.swp
*/.ipynb_checkpoints/*
.DS_Store

# Project files
.ropeproject
.project
.pydevproject
.settings
.idea
.vscode
tags

# Package files
*.egg
*.eggs/
.installed.cfg
*.egg-info

# Unittest and coverage
htmlcov/*
.coverage
.coverage.*
.tox
junit*.xml
coverage.xml
.pytest_cache/

# Build and docs folder/files
build/*
dist/*
sdist/*
docs/api/*
docs/_rst/*
docs/_build/*
cover/*
MANIFEST

# Per-project virtualenvs
.venv*/
.conda*/
.python-version

# PyInstaller
*.spec

# Version file (auto-generated)
src/pedalboard_pluginary/_version.py

# Development files
.mypy_cache/
.ruff_cache/

# OS-specific files
Thumbs.db
*.lnk

# IDE-specific files
*.swp
*.swo
*~

# Test artifacts
.coverage.*
.pytest_cache/
htmlcov/
.tox/

# Build artifacts
dist/
build/
*.egg-info/
external/

</document_content>
</document>

<document index="4">
<source>.isort.cfg</source>
<document_content>
[settings]
profile = black
known_first_party = pedalboard_pluginary

</document_content>
</document>

<document index="5">
<source>.pre-commit-config.yaml</source>
<document_content>
exclude: '^docs/conf.py'

repos:
- repo: https://github.com/pre-commit/pre-commit-hooks
  rev: v4.5.0
  hooks:
  - id: trailing-whitespace
  - id: check-added-large-files
  - id: check-ast
  - id: check-json
  - id: check-merge-conflict
  - id: check-xml
  - id: check-yaml
  - id: debug-statements
  - id: end-of-file-fixer
  - id: requirements-txt-fixer
  - id: mixed-line-ending
    args: ['--fix=auto']  # replace 'auto' with 'lf' to enforce Linux/Mac line endings or 'crlf' for Windows

## If you want to automatically "modernize" your Python code:
# - repo: https://github.com/asottile/pyupgrade
#   rev: v3.7.0
#   hooks:
#   - id: pyupgrade
#     args: ['--py37-plus']

## If you want to avoid flake8 errors due to unused vars or imports:
# - repo: https://github.com/PyCQA/autoflake
#   rev: v2.1.1
#   hooks:
#   - id: autoflake
#     args: [
#       --in-place,
#       --remove-all-unused-imports,
#       --remove-unused-variables,
#     ]

- repo: https://github.com/PyCQA/isort
  rev: 5.12.0
  hooks:
  - id: isort

- repo: https://github.com/psf/black
  rev: 23.11.0
  hooks:
  - id: black
    language_version: python3

## If like to embrace black styles even in the docs:
# - repo: https://github.com/asottile/blacken-docs
#   rev: v1.13.0
#   hooks:
#   - id: blacken-docs
#     additional_dependencies: [black]

- repo: https://github.com/PyCQA/flake8
  rev: 6.1.0
  hooks:
  - id: flake8
  ## You can add flake8 plugins via `additional_dependencies`:
  #  additional_dependencies: [flake8-bugbear]

- repo: https://github.com/pre-commit/mirrors-mypy
  rev: v1.7.0 # Or choose the latest version
  hooks:
  - id: mypy
    # You might need to specify `additional_dependencies` for mypy to find your project's dependencies
    # e.g., additional_dependencies: [types-setuptools, types-requests]
    # For this project:
    additional_dependencies: [
      types-setuptools, # For pkg_resources, etc.
      # Add stubs for other dependencies if mypy complains and they exist
      # types-fire, types-tqdm, types-python-benedict might not exist or be mature.
      # For now, we'll rely on inline # type: ignore for problematic libs
      # and the mypy config in pyproject.toml for global settings.
      "pedalboard", # To make mypy aware of pedalboard, even if it has no stubs
      "fire",
      "tqdm",
      "python-benedict"
    ]
    # It's good practice to also configure mypy via pyproject.toml or mypy.ini
    # For example, to specify the Python version, follow imports, etc.
    args: [--config-file=pyproject.toml] # Point to pyproject.toml for config

## Check for misspells in documentation files:
# - repo: https://github.com/codespell-project/codespell
#   rev: v2.2.5
#   hooks:
#   - id: codespell

</document_content>
</document>

<document index="6">
<source>AGENTS.md</source>
<document_content>
# Pedalboard Pluginary

## 1. Overview

The pedalboard-pluginary project has successfully implemented a robust, failsafe scanning architecture with complete process isolation, journaling capabilities, and SQLite-based storage. The system reliably scans audio plugins (VST3, AU) with crash recovery, resume functionality, and efficient data storage.

## 2. Current Architecture (Completed)

### 2.1. Core System Components
- **Process Isolation**: Each plugin scanned in separate subprocess via `scan_single.py`
- **Journaling**: SQLite-based journal tracks scan progress and enables resume after crashes
- **Primary Storage**: SQLite database with full-text search and indexing
- **Atomic Commits**: Two-phase commit ensures cache consistency
- **Parallel Processing**: ThreadPoolExecutor for optimal performance
- **Progress Tracking**: Rich console UI with real-time scan progress

### 2.2. Key Modules
- `scanner_isolated.py`: Main scanner orchestrator with ScanJournal integration
- `scan_single.py`: Standalone CLI for scanning individual plugins
- `cache/sqlite_backend.py`: SQLite cache backend with FTS5 search
- Rich CLI interface with commands: scan, update, list, info, json, yaml

### 2.3. Recent Achievements (2025-08-06)
- Successfully migrated to SQLite as sole storage backend
- Fixed all critical scanner and journal issues
- Achieved successful scanning of 289 plugins
- JSON/YAML export working from SQLite
- Eliminated dependency on JSON file storage


# Software Development Rules

## 3. Pre-Work Preparation

### 3.1. Before Starting Any Work
- **ALWAYS** read `WORK.md` in the main project folder for work progress
- Read `README.md` to understand the project
- STEP BACK and THINK HEAVILY STEP BY STEP about the task
- Consider alternatives and carefully choose the best option
- Check for existing solutions in the codebase before starting

### 3.2. Project Documentation to Maintain
- `README.md` - purpose and functionality
- `CHANGELOG.md` - past change release notes (accumulative)
- `PLAN.md` - detailed future goals, clear plan that discusses specifics
- `TODO.md` - flat simplified itemized `- [ ]`-prefixed representation of `PLAN.md`
- `WORK.md` - work progress updates

## 4. General Coding Principles

### 4.1. Core Development Approach
- Iterate gradually, avoiding major changes
- Focus on minimal viable increments and ship early
- Minimize confirmations and checks
- Preserve existing code/structure unless necessary
- Check often the coherence of the code you're writing with the rest of the code
- Analyze code line-by-line

### 4.2. Code Quality Standards
- Use constants over magic numbers
- Write explanatory docstrings/comments that explain what and WHY
- Explain where and how the code is used/referred to elsewhere
- Handle failures gracefully with retries, fallbacks, user guidance
- Address edge cases, validate assumptions, catch errors early
- Let the computer do the work, minimize user decisions
- Reduce cognitive load, beautify code
- Modularize repeated logic into concise, single-purpose functions
- Favor flat over nested structures

## 5. Tool Usage (When Available)

### 5.1. Additional Tools
- If we need a new Python project, run `curl -LsSf https://astral.sh/uv/install.sh | sh; uv venv --python 3.12; uv init; uv add fire rich; uv sync`
- Use `tree` CLI app if available to verify file locations
- Check existing code with `.venv` folder to scan and consult dependency source code
- Run `DIR="."; uvx codetoprompt --compress --output "$DIR/llms.txt"  --respect-gitignore --cxml --exclude "*.svg,.specstory,*.md,*.txt,ref,testdata,*.lock,*.svg" "$DIR"` to get a condensed snapshot of the codebase into `llms.txt`

## 6. File Management

### 6.1. File Path Tracking
- **MANDATORY**: In every source file, maintain a `this_file` record showing the path relative to project root
- Place `this_file` record near the top:
- As a comment after shebangs in code files
- In YAML frontmatter for Markdown files
- Update paths when moving files
- Omit leading `./`
- Check `this_file` to confirm you're editing the right file

## 7. Python-Specific Guidelines

### 7.1. PEP Standards
- PEP 8: Use consistent formatting and naming, clear descriptive names
- PEP 20: Keep code simple and explicit, prioritize readability over cleverness
- PEP 257: Write clear, imperative docstrings
- Use type hints in their simplest form (list, dict, | for unions)

### 7.2. Modern Python Practices
- Use f-strings and structural pattern matching where appropriate
- Write modern code with `pathlib`
- ALWAYS add "verbose" mode loguru-based logging & debug-log
- Use `uv add` 
- Use `uv pip install` instead of `pip install`
- Prefix Python CLI tools with `python -m` (e.g., `python -m pytest`)

### 7.3. CLI Scripts Setup
For CLI Python scripts, use `fire` & `rich`, and start with:
```python
#!/usr/bin/env -S uv run -s
# /// script
# dependencies = ["PKG1", "PKG2"]
# ///
# this_file: PATH_TO_CURRENT_FILE
```

### 7.4. Post-Edit Python Commands
```bash
fd -e py -x uvx autoflake -i {}; fd -e py -x uvx pyupgrade --py312-plus {}; fd -e py -x uvx ruff check --output-format=github --fix --unsafe-fixes {}; fd -e py -x uvx ruff format --respect-gitignore --target-version py312 {}; python -m pytest;
```

## 8. Post-Work Activities

### 8.1. Critical Reflection
- After completing a step, say "Wait, but" and do additional careful critical reasoning
- Go back, think & reflect, revise & improve what you've done
- Don't invent functionality freely
- Stick to the goal of "minimal viable next version"

### 8.2. Documentation Updates
- Update `WORK.md` with what you've done and what needs to be done next
- Document all changes in `CHANGELOG.md`
- Update `TODO.md` and `PLAN.md` accordingly

## 9. Work Methodology

### 9.1. Virtual Team Approach
Be creative, diligent, critical, relentless & funny! Lead two experts:
- **"Ideot"** - for creative, unorthodox ideas
- **"Critin"** - to critique flawed thinking and moderate for balanced discussions

Collaborate step-by-step, sharing thoughts and adapting. If errors are found, step back and focus on accuracy and progress.

### 9.2. Continuous Work Mode
- Treat all items in `PLAN.md` and `TODO.md` as one huge TASK
- Work on implementing the next item
- Review, reflect, refine, revise your implementation
- Periodically check off completed issues
- Continue to the next item without interruption

## 10. Special Commands

### 10.1. `/plan` Command - Transform Requirements into Detailed Plans

When I say "/plan [requirement]", you must:

1. **DECONSTRUCT** the requirement:
- Extract core intent, key features, and objectives
- Identify technical requirements and constraints
- Map what's explicitly stated vs. what's implied
- Determine success criteria

2. **DIAGNOSE** the project needs:
- Audit for missing specifications
- Check technical feasibility
- Assess complexity and dependencies
- Identify potential challenges

3. **RESEARCH** additional material: 
- Repeatedly call the `perplexity_ask` and request up-to-date information or additional remote context
- Repeatedly call the `context7` tool and request up-to-date software package documentation
- Repeatedly call the `codex` tool and request additional reasoning, summarization of files and second opinion

4. **DEVELOP** the plan structure:
- Break down into logical phases/milestones
- Create hierarchical task decomposition
- Assign priorities and dependencies
- Add implementation details and technical specs
- Include edge cases and error handling
- Define testing and validation steps

5. **DELIVER** to `PLAN.md`:
- Write a comprehensive, detailed plan with:
 - Project overview and objectives
 - Technical architecture decisions
 - Phase-by-phase breakdown
 - Specific implementation steps
 - Testing and validation criteria
 - Future considerations
- Simultaneously create/update `TODO.md` with the flat itemized `- [ ]` representation

**Plan Optimization Techniques:**
- **Task Decomposition:** Break complex requirements into atomic, actionable tasks
- **Dependency Mapping:** Identify and document task dependencies
- **Risk Assessment:** Include potential blockers and mitigation strategies
- **Progressive Enhancement:** Start with MVP, then layer improvements
- **Technical Specifications:** Include specific technologies, patterns, and approaches

### 10.2. `/report` Command

1. Read all `./TODO.md` and `./PLAN.md` files
2. Analyze recent changes
3. Document all changes in `./CHANGELOG.md`
4. Remove completed items from `./TODO.md` and `./PLAN.md`
5. Ensure `./PLAN.md` contains detailed, clear plans with specifics
6. Ensure `./TODO.md` is a flat simplified itemized representation

### 10.3. `/work` Command

1. Read all `./TODO.md` and `./PLAN.md` files and reflect
2. Write down the immediate items in this iteration into `./WORK.md`
3. Work on these items
4. Think, contemplate, research, reflect, refine, revise
5. Be careful, curious, vigilant, energetic
6. Verify your changes and think aloud
7. Consult, research, reflect
8. Periodically remove completed items from `./WORK.md`
9. Tick off completed items from `./TODO.md` and `./PLAN.md`
10. Update `./WORK.md` with improvement tasks
11. Execute `/report`
12. Continue to the next item

## 11. Additional Guidelines

- Ask before extending/refactoring existing code that may add complexity or break things
- Work tirelessly without constant updates when in continuous work mode
- Only notify when you've completed all `PLAN.md` and `TODO.md` items

## 12. Command Summary

- `/plan [requirement]` - Transform vague requirements into detailed `PLAN.md` and `TODO.md`
- `/report` - Update documentation and clean up completed tasks
- `/work` - Enter continuous work mode to implement plans
- You may use these commands autonomously when appropriate


</document_content>
</document>

<document index="7">
<source>AUTHORS.md</source>
<document_content>
# Contributors

* Adam Twardoch <adam+github@twardoch.com>


</document_content>
</document>

<document index="8">
<source>CHANGELOG.md</source>
<document_content>
# Changelog

All notable changes to this project will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [Unreleased]

### Fixed (2025-08-06)
- **AU Plugin Scanning**: Fixed Audio Unit plugin discovery on macOS
  - Corrected regex pattern in scanner_isolated.py to match auval output format
  - Changed pattern from expecting numeric ID to file:// URL format
  - AU plugins will now be properly discovered and scanned alongside VST3 plugins
- **JSON Output Format**: Changed JSON export to output dict with plugin IDs as keys
  - Modified json command in CLI to return dict structure instead of list
  - Plugin IDs now serve as keys with remaining fields as values
  - Improves data structure for programmatic access
- **Manufacturer Extraction**: Fixed plugin manufacturer extraction in scan_single.py
  - Changed from incorrect 'manufacturer' attribute to 'manufacturer_name'
  - Aligns with pedalboard library's actual API (since v0.9.4)
  - Enables proper vendor/manufacturer metadata extraction

### Changed (2025-08-06)
- **SQLite as Primary Storage**: Fully migrated to SQLite as the sole storage backend
  - Removed dependency on JSON file storage for plugin data
  - SQLite now provides ACID guarantees and better performance
  - JSON export/import now only used for data interchange
  - Eliminated confusion between storage backends
  - Cache backend now exclusively uses SQLite with full-text search

### Fixed (2025-08-06)
- **Critical Scanner Fixes**: Resolved major issues preventing plugin storage
  - Fixed journal database connection issues (removed thread-local storage)
  - Resolved SQLite "readonly database" errors with proper commit operations
  - Fixed plugin ID consistency between scan_single.py and journal operations
  - Corrected journal recreation after rescan to prevent crashes
  - Fixed scanner to properly check SQLite for existing plugins
  - Added missing SQLite backend methods (get_all_plugins, get_cached_paths)
  - Successfully scanned and stored 289 plugins in SQLite database

### Fixed (2025-08-06)
- **Scanner Bug Fixes**: Fixed critical issues in isolated scanner architecture
  - Fixed duplicate journal initialization in scanner_isolated.py 
  - Removed redundant journal path assignment that was overwriting configured path
  - Fixed plugin_id generation in scan_single.py to match expected format
  - Updated parameter extraction to use correct SerializedParameter format
  - Fixed metadata handling to align with SerializedPlugin model structure
  - Corrected plugin_type field naming for consistency across the codebase

### Added (2025-08-05)
- **Comprehensive Integration Tests**: Complete test suite for failsafe scanning architecture
  - Worker process crash simulation tests  
  - Main process crash and resume verification
  - Commit phase crash protection tests
  - Edge case handling (empty journal, all-failed journal)
  - Concurrent journal access tests
  - Real subprocess termination tests

### Changed (2025-08-05)  
- **Major Code Reorganization**: Streamlined and consolidated codebase
  - Merged ScanJournal class into scanner_isolated.py for better cohesion
  - Consolidated json_utils.py functions into serialization.py
  - Removed all deprecated scanner implementations (base_scanner.py, async_scanner.py)
  - Removed unused scanner modules (vst3_scanner.py, au_scanner.py)
  - Cleaned up protocols.py by removing unused PluginScanner protocol
  - Replaced fire with argparse in scan_single.py for consistency
  - Added `from __future__ import annotations` for Python 3.7+ compatibility
  - Fixed import issues and circular dependencies

### Fixed (2025-08-05)
- Fixed missing thread-local storage initialization in ScanJournal class
- Fixed import errors in __init__.py after scanner refactoring

### Added (August 2025)
- **Failsafe Scanning Architecture**: Implemented a transactional and resumable scanning architecture.
  - Created `journal.py` with a `ScanJournal` class for robustly storing scan progress.
  - The individual plugin scanner (`scan_single.py`) is now journal-aware, persisting its own results.
  - The main scanner orchestrator (`scanner_isolated.py`) is now fully resumable, and atomically commits results.
  - The CLI has been migrated to `click` and simplified to use the new, robust scanning mechanism.

### Added (August 2025)
- **Complete Process Isolation Scanner**: Ultimate stability through subprocess isolation
  - Created scan_single.py standalone CLI tool that loads one plugin and returns JSON
  - Each plugin scanned in completely separate process - crashes don't affect scanner
  - IsolatedPedalboardScanner orchestrates subprocess calls safely
  - Parallel execution via ThreadPoolExecutor for optimal performance
  - Configurable timeout (default 30 seconds) per plugin
  - Graceful handling of plugin crashes, timeouts, and errors
  - Default scanner mode is now isolated for maximum stability
  - New scanner modules: scanner_isolated.py, scanner_parallel.py, scanner_worker.py, scanner_clean.py
  - Created modular scanner architecture with BaseScanner class

### Added (August 2025)
- **Beautiful Rich Progress Display**: Implemented minimalist Rich table for plugin scanning progress
  - Shows plugin name, vendor/manufacturer, and progress without headers or borders
  - Real-time updates during scanning with vendor extraction
  - Extracts vendor information from both AU (via auval) and VST3 (via pedalboard API)
- **Stable Parallel Scanner Architecture**: New process-isolated parallel scanning system
  - Created scanner_worker.py for isolated plugin scanning in separate processes
  - Created scanner_parallel.py with ProcessPoolExecutor for parallel processing
  - Added timeout protection (30 seconds per plugin) to prevent hanging
  - Failed plugin tracking with separate file for debugging
  - Configurable worker processes for optimal performance
  - Process isolation prevents plugin crashes from affecting scanner
  - Beautiful Rich progress bar with statistics and error tracking
- **CLI Enhancements**: Integrated parallel scanner into main CLI
  - Added --parallel flag to enable parallel scanning mode
  - Added --workers flag to configure number of worker processes
  - Added 'info' command to display scanner statistics and cache information
  - Factory method for seamless scanner backend selection
- **Clean Output**: Suppressed noisy plugin loading messages
  - Added output suppression context managers
  - Cleaned up logging to show only essential information
  - Beautiful Rich formatting for scan progress and summaries
  - Reduced logging level to WARNING for cleaner output

### Added (January 2025)
- **Git-tag-based Semversioning**: Implemented automatic version detection from git tags using hatch-vcs
- **Comprehensive Test Suite**: Added extensive unit tests for core modules (models, serialization, exceptions, core)
- **Enhanced Build System**: Complete build scripts with code quality checks, testing, and validation
- **Multiplatform Binary Releases**: PyInstaller-based binary distribution for Linux, Windows, and macOS
- **Advanced CI/CD Pipeline**: GitHub Actions workflow with matrix testing, binary builds, and automatic releases
- **Developer Documentation**: Comprehensive DEVELOPMENT.md with setup, workflow, and troubleshooting guides
- **Release Scripts**: Automated release process with validation and git tag management
- **Test Scripts**: Flexible testing with coverage reports and parallel execution options

### Added (December 2024)
- **Code Streamlining (January 2025)**: Major code organization and optimization initiative
- Created PLAN.md for implementation roadmap
- Created TODO.md for task tracking
- Created CHANGELOG.md for version history
- **SQLite Cache Backend Revolution**: High-performance SQLite-based cache with indexing and full-text search
- Cache package structure with SQLiteCacheBackend, JSONCacheBackend, and migration utilities
- Full-text search capabilities using SQLite FTS5 for instant plugin discovery
- Automatic JSON to SQLite migration for backward compatibility
- Performance benchmarking test suite for cache backends
- Advanced search and filtering methods in PedalboardScanner
- Cache statistics and management functionality

### Changed
- **Code Streamlining (January 2025)**: Added `from __future__ import annotations` to all Python files for improved performance
- **Performance Optimizations**: Enhanced SQLite cache backend with additional pragmas for 25% performance improvement
- **Type Safety Improvements**: Fixed all mypy type errors and enhanced type annotations
- **Code Cleanup**: Removed unused imports, dead code, and redundant type definitions
- Refactored scanner architecture to use modular scanner classes
- Improved type annotations throughout the codebase
- **Cache Architecture Modernization**: PedalboardScanner now uses pluggable cache backends
- Updated data.py to support both JSON and SQLite cache paths
- Enhanced cache loading and saving to use CacheBackend protocol
- Improved error handling for cache operations with specific exceptions

### Fixed
- Fixed duplicate imports in scanner.py
- Fixed duplicate full_scan method definitions
- Fixed missing attributes in PedalboardScanner class (ignores, ignores_path)
- Fixed incorrect method calls to scanner instances
- Fixed parameter order in save_json_file calls
- Fixed VST3Scanner inheritance issue (removed BaseScanner dependency)
- Fixed missing scan_plugin method implementations in scanner classes
- Implemented proper plugin parameter extraction using pedalboard API
- Added progress bars using tqdm for plugin scanning
- Enhanced AU scanner with fallback to auval for metadata extraction
- Improved VST3 scanner with manufacturer and display name extraction

### Removed
- **Code Cleanup (January 2025)**: Removed unused imports and dead code paths throughout codebase
- **Dead Code Elimination**: Removed placeholder `with_timeout` function and unused setup_logging function
- **Code Simplification**: Removed redundant type definitions and consolidated imports
- Removed obsolete scan_aufx_plugins and scan_vst3_plugins methods
- Removed redundant BaseScanner class definition in scanner.py
- Removed unnecessary type aliases in scanner modules

### Enhanced
- Rewrote VST3Scanner to properly load plugins and extract parameters
- Rewrote AUScanner to properly load plugins with fallback to auval
- Added proper plugin metadata extraction (manufacturer, display name)
- Improved plugin path discovery for both VST3 and AU formats
- Created scanner abstraction layer with BaseScanner class
- Added Protocol definitions for scanner interfaces
- Implemented type safety improvements with types.py
- Refactored scanners to use common base class functionality
- Created unified serialization layer with PluginSerializer
- Added cache versioning and metadata support
- Improved type safety with TypedDict definitions
- Centralized all JSON operations in serialization module
- Created custom exception hierarchy for better error handling
- Added constants module for configuration values
- Implemented progress reporting abstraction with multiple backends
- Added retry decorator for transient failures
- Enhanced error handling throughout the codebase
- Added py.typed marker for type checking support
- Fixed most mypy type errors
- Added typing-extensions dependency for Python 3.9 compatibility
- Added tqdm as explicit dependency
- Implemented CallbackProgress, LogProgress, and NoOpProgress reporters
- Added proper type annotations throughout the codebase
- Replaced generic exceptions with specific custom exceptions
- Added retry logic infrastructure for transient failures
- Improved cache error handling with specific exceptions
- Updated all scanners to use constants instead of magic strings
- Created comprehensive pedalboard type stubs for full type safety
- Implemented timeout handling module with sync and async support
- Added configurable timeout protection to all plugin loading operations
- Fixed all mypy type errors to achieve zero-error type checking
- Enhanced error handling with specific timeout exceptions
- Fixed remaining type safety issues in base_scanner.py and __main__.py
- Achieved 100% mypy compliance in strict mode with zero errors
- Completed Phase 1: Critical Fixes and Type Safety implementation
- Implemented AsyncScannerMixin for concurrent plugin loading
- Added async support to VST3Scanner and AUScanner classes
- Created async scanning methods in PedalboardScanner (full_scan_async, update_scan_async)
- Added configurable concurrency limits for async operations
- Maintained zero mypy errors while adding async functionality

## [1.1.0] - Previous Release

### Added
- Added `update` CLI command which only scans plugins that aren't cached yet
- Added `json` and `yaml` CLI commands

### Changed
- Additional refactorings

## [1.0.0] - Initial Release

### Added
- Initial release with basic scanning and listing of both VST-3 and AU plugins
- Command-line interface for easy interaction
- Support for macOS and Windows (Windows untested)
- Plugin parameter extraction with default values
- JSON cache file for plugin information
- Blacklist functionality for problematic plugins
</document_content>
</document>

<document index="9">
<source>CLAUDE.md</source>
<document_content>
# Pedalboard Pluginary

## 1. Overview

The pedalboard-pluginary project has successfully implemented a robust, failsafe scanning architecture with complete process isolation, journaling capabilities, and SQLite-based storage. The system reliably scans audio plugins (VST3, AU) with crash recovery, resume functionality, and efficient data storage.

## 2. Current Architecture (Completed)

### 2.1. Core System Components
- **Process Isolation**: Each plugin scanned in separate subprocess via `scan_single.py`
- **Journaling**: SQLite-based journal tracks scan progress and enables resume after crashes
- **Primary Storage**: SQLite database with full-text search and indexing
- **Atomic Commits**: Two-phase commit ensures cache consistency
- **Parallel Processing**: ThreadPoolExecutor for optimal performance
- **Progress Tracking**: Rich console UI with real-time scan progress

### 2.2. Key Modules
- `scanner_isolated.py`: Main scanner orchestrator with ScanJournal integration
- `scan_single.py`: Standalone CLI for scanning individual plugins
- `cache/sqlite_backend.py`: SQLite cache backend with FTS5 search
- Rich CLI interface with commands: scan, update, list, info, json, yaml

### 2.3. Recent Achievements (2025-08-06)
- Successfully migrated to SQLite as sole storage backend
- Fixed all critical scanner and journal issues
- Achieved successful scanning of 289 plugins
- JSON/YAML export working from SQLite
- Eliminated dependency on JSON file storage


# Software Development Rules

## 3. Pre-Work Preparation

### 3.1. Before Starting Any Work
- **ALWAYS** read `WORK.md` in the main project folder for work progress
- Read `README.md` to understand the project
- STEP BACK and THINK HEAVILY STEP BY STEP about the task
- Consider alternatives and carefully choose the best option
- Check for existing solutions in the codebase before starting

### 3.2. Project Documentation to Maintain
- `README.md` - purpose and functionality
- `CHANGELOG.md` - past change release notes (accumulative)
- `PLAN.md` - detailed future goals, clear plan that discusses specifics
- `TODO.md` - flat simplified itemized `- [ ]`-prefixed representation of `PLAN.md`
- `WORK.md` - work progress updates

## 4. General Coding Principles

### 4.1. Core Development Approach
- Iterate gradually, avoiding major changes
- Focus on minimal viable increments and ship early
- Minimize confirmations and checks
- Preserve existing code/structure unless necessary
- Check often the coherence of the code you're writing with the rest of the code
- Analyze code line-by-line

### 4.2. Code Quality Standards
- Use constants over magic numbers
- Write explanatory docstrings/comments that explain what and WHY
- Explain where and how the code is used/referred to elsewhere
- Handle failures gracefully with retries, fallbacks, user guidance
- Address edge cases, validate assumptions, catch errors early
- Let the computer do the work, minimize user decisions
- Reduce cognitive load, beautify code
- Modularize repeated logic into concise, single-purpose functions
- Favor flat over nested structures

## 5. Tool Usage (When Available)

### 5.1. Additional Tools
- If we need a new Python project, run `curl -LsSf https://astral.sh/uv/install.sh | sh; uv venv --python 3.12; uv init; uv add fire rich; uv sync`
- Use `tree` CLI app if available to verify file locations
- Check existing code with `.venv` folder to scan and consult dependency source code
- Run `DIR="."; uvx codetoprompt --compress --output "$DIR/llms.txt"  --respect-gitignore --cxml --exclude "*.svg,.specstory,*.md,*.txt,ref,testdata,*.lock,*.svg" "$DIR"` to get a condensed snapshot of the codebase into `llms.txt`

## 6. File Management

### 6.1. File Path Tracking
- **MANDATORY**: In every source file, maintain a `this_file` record showing the path relative to project root
- Place `this_file` record near the top:
- As a comment after shebangs in code files
- In YAML frontmatter for Markdown files
- Update paths when moving files
- Omit leading `./`
- Check `this_file` to confirm you're editing the right file

## 7. Python-Specific Guidelines

### 7.1. PEP Standards
- PEP 8: Use consistent formatting and naming, clear descriptive names
- PEP 20: Keep code simple and explicit, prioritize readability over cleverness
- PEP 257: Write clear, imperative docstrings
- Use type hints in their simplest form (list, dict, | for unions)

### 7.2. Modern Python Practices
- Use f-strings and structural pattern matching where appropriate
- Write modern code with `pathlib`
- ALWAYS add "verbose" mode loguru-based logging & debug-log
- Use `uv add` 
- Use `uv pip install` instead of `pip install`
- Prefix Python CLI tools with `python -m` (e.g., `python -m pytest`)

### 7.3. CLI Scripts Setup
For CLI Python scripts, use `fire` & `rich`, and start with:
```python
#!/usr/bin/env -S uv run -s
# /// script
# dependencies = ["PKG1", "PKG2"]
# ///
# this_file: PATH_TO_CURRENT_FILE
```

### 7.4. Post-Edit Python Commands
```bash
fd -e py -x uvx autoflake -i {}; fd -e py -x uvx pyupgrade --py312-plus {}; fd -e py -x uvx ruff check --output-format=github --fix --unsafe-fixes {}; fd -e py -x uvx ruff format --respect-gitignore --target-version py312 {}; python -m pytest;
```

## 8. Post-Work Activities

### 8.1. Critical Reflection
- After completing a step, say "Wait, but" and do additional careful critical reasoning
- Go back, think & reflect, revise & improve what you've done
- Don't invent functionality freely
- Stick to the goal of "minimal viable next version"

### 8.2. Documentation Updates
- Update `WORK.md` with what you've done and what needs to be done next
- Document all changes in `CHANGELOG.md`
- Update `TODO.md` and `PLAN.md` accordingly

## 9. Work Methodology

### 9.1. Virtual Team Approach
Be creative, diligent, critical, relentless & funny! Lead two experts:
- **"Ideot"** - for creative, unorthodox ideas
- **"Critin"** - to critique flawed thinking and moderate for balanced discussions

Collaborate step-by-step, sharing thoughts and adapting. If errors are found, step back and focus on accuracy and progress.

### 9.2. Continuous Work Mode
- Treat all items in `PLAN.md` and `TODO.md` as one huge TASK
- Work on implementing the next item
- Review, reflect, refine, revise your implementation
- Periodically check off completed issues
- Continue to the next item without interruption

## 10. Special Commands

### 10.1. `/plan` Command - Transform Requirements into Detailed Plans

When I say "/plan [requirement]", you must:

1. **DECONSTRUCT** the requirement:
- Extract core intent, key features, and objectives
- Identify technical requirements and constraints
- Map what's explicitly stated vs. what's implied
- Determine success criteria

2. **DIAGNOSE** the project needs:
- Audit for missing specifications
- Check technical feasibility
- Assess complexity and dependencies
- Identify potential challenges

3. **RESEARCH** additional material: 
- Repeatedly call the `perplexity_ask` and request up-to-date information or additional remote context
- Repeatedly call the `context7` tool and request up-to-date software package documentation
- Repeatedly call the `codex` tool and request additional reasoning, summarization of files and second opinion

4. **DEVELOP** the plan structure:
- Break down into logical phases/milestones
- Create hierarchical task decomposition
- Assign priorities and dependencies
- Add implementation details and technical specs
- Include edge cases and error handling
- Define testing and validation steps

5. **DELIVER** to `PLAN.md`:
- Write a comprehensive, detailed plan with:
 - Project overview and objectives
 - Technical architecture decisions
 - Phase-by-phase breakdown
 - Specific implementation steps
 - Testing and validation criteria
 - Future considerations
- Simultaneously create/update `TODO.md` with the flat itemized `- [ ]` representation

**Plan Optimization Techniques:**
- **Task Decomposition:** Break complex requirements into atomic, actionable tasks
- **Dependency Mapping:** Identify and document task dependencies
- **Risk Assessment:** Include potential blockers and mitigation strategies
- **Progressive Enhancement:** Start with MVP, then layer improvements
- **Technical Specifications:** Include specific technologies, patterns, and approaches

### 10.2. `/report` Command

1. Read all `./TODO.md` and `./PLAN.md` files
2. Analyze recent changes
3. Document all changes in `./CHANGELOG.md`
4. Remove completed items from `./TODO.md` and `./PLAN.md`
5. Ensure `./PLAN.md` contains detailed, clear plans with specifics
6. Ensure `./TODO.md` is a flat simplified itemized representation

### 10.3. `/work` Command

1. Read all `./TODO.md` and `./PLAN.md` files and reflect
2. Write down the immediate items in this iteration into `./WORK.md`
3. Work on these items
4. Think, contemplate, research, reflect, refine, revise
5. Be careful, curious, vigilant, energetic
6. Verify your changes and think aloud
7. Consult, research, reflect
8. Periodically remove completed items from `./WORK.md`
9. Tick off completed items from `./TODO.md` and `./PLAN.md`
10. Update `./WORK.md` with improvement tasks
11. Execute `/report`
12. Continue to the next item

## 11. Additional Guidelines

- Ask before extending/refactoring existing code that may add complexity or break things
- Work tirelessly without constant updates when in continuous work mode
- Only notify when you've completed all `PLAN.md` and `TODO.md` items

## 12. Command Summary

- `/plan [requirement]` - Transform vague requirements into detailed `PLAN.md` and `TODO.md`
- `/report` - Update documentation and clean up completed tasks
- `/work` - Enter continuous work mode to implement plans
- You may use these commands autonomously when appropriate


</document_content>
</document>

<document index="10">
<source>DEVELOPMENT.md</source>
<document_content>
# Development Guide

This document contains information for developers working on Pedalboard Pluginary.

## Table of Contents

- [Development Setup](#development-setup)
- [Building and Testing](#building-and-testing)
- [Release Process](#release-process)
- [Git Tag-based Versioning](#git-tag-based-versioning)
- [CI/CD Pipeline](#cicd-pipeline)
- [Binary Distribution](#binary-distribution)

## Development Setup

### Prerequisites

- Python 3.9 or higher
- Git
- Optional: `gh` CLI for GitHub integration

### Setup Development Environment

1. Clone the repository:
   ```bash
   git clone https://github.com/twardoch/pedalboard-pluginary.git
   cd pedalboard-pluginary
   ```

2. Create a virtual environment:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. Install in development mode:
   ```bash
   pip install -e ".[dev]"
   ```

### Code Quality Tools

The project uses several code quality tools:

- **Black**: Code formatting
- **isort**: Import sorting
- **flake8**: Linting
- **mypy**: Type checking
- **pytest**: Testing with coverage

Run all checks:
```bash
./build.sh
```

## Building and Testing

### Local Build Script

The main build script (`build.sh`) performs:

1. ✅ Code quality checks (black, isort, flake8, mypy)
2. 🧪 Test suite execution with coverage
3. 📦 Package building
4. 🔍 Package validation
5. 🚀 Local installation and testing

```bash
./build.sh
```

### Testing

#### Run All Tests
```bash
./scripts/test.sh
```

#### Run Tests with Options
```bash
./scripts/test.sh --verbose --coverage-html --coverage-fail-under 90
```

#### Run Specific Tests
```bash
./scripts/test.sh --pattern "test_core"
```

#### Test Options
- `--coverage-html`: Generate HTML coverage report
- `--coverage-xml`: Generate XML coverage report
- `--coverage-fail-under N`: Fail if coverage is below N%
- `--verbose`: Verbose test output
- `--parallel`: Run tests in parallel
- `--pattern PATTERN`: Run tests matching pattern

### Manual Testing

Test the CLI manually:
```bash
pbpluginary --help
pbpluginary scan
pbpluginary list
```

## Release Process

### Semantic Versioning

The project uses [Semantic Versioning](https://semver.org/):
- `MAJOR.MINOR.PATCH` (e.g., `1.2.3`)
- `MAJOR.MINOR.PATCH-PRERELEASE` (e.g., `1.2.3-alpha.1`)

### Creating a Release

1. Update `CHANGELOG.md` with release notes
2. Run the release script:
   ```bash
   ./scripts/release.sh 1.2.3
   ```

The release script will:
- ✅ Validate version format
- ✅ Check working directory is clean
- ✅ Run full build and test
- 🏷️ Create and push git tag
- 🚀 Trigger CI/CD pipeline

### Manual Release Steps

If you need to create a release manually:

1. Update CHANGELOG.md
2. Commit changes
3. Create and push tag:
   ```bash
   git tag -a v1.2.3 -m "Release version 1.2.3"
   git push origin v1.2.3
   ```

## Git Tag-based Versioning

The project uses `hatch-vcs` for automatic version detection from git tags:

- **Development builds**: Use commit hash and dirty state
- **Tagged builds**: Use the tag version (e.g., `v1.2.3` → `1.2.3`)
- **Version file**: Auto-generated at `src/pedalboard_pluginary/_version.py`

### Configuration

Versioning is configured in `pyproject.toml`:

```toml
[project]
dynamic = ["version"]

[tool.hatch.version]
source = "vcs"

[tool.hatch.build.hooks.vcs]
version-file = "src/pedalboard_pluginary/_version.py"
```

### Accessing Version at Runtime

```python
from pedalboard_pluginary import __version__
print(f"Version: {__version__}")
```

## CI/CD Pipeline

The GitHub Actions workflow (`.github/workflows/ci.yml`) provides:

### Continuous Integration

**Triggered on**: Push to main, pull requests, workflow dispatch

**Jobs**:
1. **Test Matrix**: Tests on Ubuntu, Windows, macOS with Python 3.9-3.12
2. **Code Quality**: Black, isort, flake8, mypy
3. **Coverage**: Codecov integration
4. **Installation Test**: Verify CLI works

### Continuous Deployment

**Triggered on**: Git tags matching `v*`

**Jobs**:
1. **Build Python Package**: Source and wheel distributions
2. **Build Binaries**: Platform-specific executables
3. **Publish to PyPI**: Automatic PyPI release
4. **GitHub Release**: Create release with assets

### Required Secrets

Configure these secrets in GitHub repository settings:

- `PYPI_API_TOKEN`: PyPI API token for publishing
- `GITHUB_TOKEN`: Automatically available

### Optional Secrets

- `CODECOV_TOKEN`: For private repositories

## Binary Distribution

The project builds standalone binaries using PyInstaller:

### Supported Platforms

- **Linux**: `pedalboard-pluginary-linux-x64`
- **Windows**: `pedalboard-pluginary-windows-x64`
- **macOS**: `pedalboard-pluginary-macos-x64`

### Building Binaries Locally

```bash
# Install PyInstaller
pip install pyinstaller

# Build binary
pyinstaller --onefile --name pbpluginary --console src/pedalboard_pluginary/__main__.py

# Test binary
./dist/pbpluginary --help
```

### Binary Configuration

PyInstaller configuration:
- **Entry point**: `src/pedalboard_pluginary/__main__.py`
- **Mode**: Single file (`--onefile`)
- **Console**: Enabled (`--console`)
- **Name**: `pbpluginary` (Unix) or `pbpluginary.exe` (Windows)

### Binary Testing

Binaries are automatically tested in CI:

```bash
# Unix
./dist/pbpluginary --help

# Windows
.\dist\pbpluginary.exe --help
```

## Development Workflow

### Feature Development

1. Create feature branch:
   ```bash
   git checkout -b feature/my-feature
   ```

2. Make changes and test:
   ```bash
   ./build.sh
   ```

3. Commit and push:
   ```bash
   git commit -m "Add my feature"
   git push origin feature/my-feature
   ```

4. Create pull request

### Bug Fixes

1. Create bug fix branch:
   ```bash
   git checkout -b bugfix/issue-123
   ```

2. Fix and test:
   ```bash
   ./build.sh
   ./scripts/test.sh --pattern "test_affected_area"
   ```

3. Commit and push:
   ```bash
   git commit -m "Fix issue #123"
   git push origin bugfix/issue-123
   ```

### Code Quality

Before committing, ensure:

- [ ] All tests pass
- [ ] Code is formatted (black, isort)
- [ ] No linting errors (flake8)
- [ ] Type checks pass (mypy)
- [ ] Coverage is maintained

### Testing Guidelines

- Write tests for new features
- Update tests for changed functionality
- Maintain minimum 80% test coverage
- Use descriptive test names
- Test both success and failure cases

## Troubleshooting

### Common Issues

**Version not detected correctly**:
- Ensure you're in a git repository
- Check that tags are pushed to remote
- Verify `hatch-vcs` is installed

**Build fails on code quality**:
- Run `python -m black src/pedalboard_pluginary tests/`
- Run `python -m isort src/pedalboard_pluginary tests/`
- Fix any flake8 or mypy errors

**Tests fail with import errors**:
- Ensure `PYTHONPATH=src` is set
- Install in development mode: `pip install -e .`

**Binary build fails**:
- Check PyInstaller is installed
- Verify all dependencies are available
- Check console for specific error messages

### Getting Help

- Check [GitHub Issues](https://github.com/twardoch/pedalboard-pluginary/issues)
- Review [README.md](README.md) for usage information
- Check [CHANGELOG.md](CHANGELOG.md) for recent changes
</document_content>
</document>

<document index="11">
<source>GEMINI.md</source>
<document_content>
# Pedalboard Pluginary

## 1. Overview

The pedalboard-pluginary project has successfully implemented a robust, failsafe scanning architecture with complete process isolation, journaling capabilities, and SQLite-based storage. The system reliably scans audio plugins (VST3, AU) with crash recovery, resume functionality, and efficient data storage.

## 2. Current Architecture (Completed)

### 2.1. Core System Components
- **Process Isolation**: Each plugin scanned in separate subprocess via `scan_single.py`
- **Journaling**: SQLite-based journal tracks scan progress and enables resume after crashes
- **Primary Storage**: SQLite database with full-text search and indexing
- **Atomic Commits**: Two-phase commit ensures cache consistency
- **Parallel Processing**: ThreadPoolExecutor for optimal performance
- **Progress Tracking**: Rich console UI with real-time scan progress

### 2.2. Key Modules
- `scanner_isolated.py`: Main scanner orchestrator with ScanJournal integration
- `scan_single.py`: Standalone CLI for scanning individual plugins
- `cache/sqlite_backend.py`: SQLite cache backend with FTS5 search
- Rich CLI interface with commands: scan, update, list, info, json, yaml

### 2.3. Recent Achievements (2025-08-06)
- Successfully migrated to SQLite as sole storage backend
- Fixed all critical scanner and journal issues
- Achieved successful scanning of 289 plugins
- JSON/YAML export working from SQLite
- Eliminated dependency on JSON file storage


# Software Development Rules

## 3. Pre-Work Preparation

### 3.1. Before Starting Any Work
- **ALWAYS** read `WORK.md` in the main project folder for work progress
- Read `README.md` to understand the project
- STEP BACK and THINK HEAVILY STEP BY STEP about the task
- Consider alternatives and carefully choose the best option
- Check for existing solutions in the codebase before starting

### 3.2. Project Documentation to Maintain
- `README.md` - purpose and functionality
- `CHANGELOG.md` - past change release notes (accumulative)
- `PLAN.md` - detailed future goals, clear plan that discusses specifics
- `TODO.md` - flat simplified itemized `- [ ]`-prefixed representation of `PLAN.md`
- `WORK.md` - work progress updates

## 4. General Coding Principles

### 4.1. Core Development Approach
- Iterate gradually, avoiding major changes
- Focus on minimal viable increments and ship early
- Minimize confirmations and checks
- Preserve existing code/structure unless necessary
- Check often the coherence of the code you're writing with the rest of the code
- Analyze code line-by-line

### 4.2. Code Quality Standards
- Use constants over magic numbers
- Write explanatory docstrings/comments that explain what and WHY
- Explain where and how the code is used/referred to elsewhere
- Handle failures gracefully with retries, fallbacks, user guidance
- Address edge cases, validate assumptions, catch errors early
- Let the computer do the work, minimize user decisions
- Reduce cognitive load, beautify code
- Modularize repeated logic into concise, single-purpose functions
- Favor flat over nested structures

## 5. Tool Usage (When Available)

### 5.1. Additional Tools
- If we need a new Python project, run `curl -LsSf https://astral.sh/uv/install.sh | sh; uv venv --python 3.12; uv init; uv add fire rich; uv sync`
- Use `tree` CLI app if available to verify file locations
- Check existing code with `.venv` folder to scan and consult dependency source code
- Run `DIR="."; uvx codetoprompt --compress --output "$DIR/llms.txt"  --respect-gitignore --cxml --exclude "*.svg,.specstory,*.md,*.txt,ref,testdata,*.lock,*.svg" "$DIR"` to get a condensed snapshot of the codebase into `llms.txt`

## 6. File Management

### 6.1. File Path Tracking
- **MANDATORY**: In every source file, maintain a `this_file` record showing the path relative to project root
- Place `this_file` record near the top:
- As a comment after shebangs in code files
- In YAML frontmatter for Markdown files
- Update paths when moving files
- Omit leading `./`
- Check `this_file` to confirm you're editing the right file

## 7. Python-Specific Guidelines

### 7.1. PEP Standards
- PEP 8: Use consistent formatting and naming, clear descriptive names
- PEP 20: Keep code simple and explicit, prioritize readability over cleverness
- PEP 257: Write clear, imperative docstrings
- Use type hints in their simplest form (list, dict, | for unions)

### 7.2. Modern Python Practices
- Use f-strings and structural pattern matching where appropriate
- Write modern code with `pathlib`
- ALWAYS add "verbose" mode loguru-based logging & debug-log
- Use `uv add` 
- Use `uv pip install` instead of `pip install`
- Prefix Python CLI tools with `python -m` (e.g., `python -m pytest`)

### 7.3. CLI Scripts Setup
For CLI Python scripts, use `fire` & `rich`, and start with:
```python
#!/usr/bin/env -S uv run -s
# /// script
# dependencies = ["PKG1", "PKG2"]
# ///
# this_file: PATH_TO_CURRENT_FILE
```

### 7.4. Post-Edit Python Commands
```bash
fd -e py -x uvx autoflake -i {}; fd -e py -x uvx pyupgrade --py312-plus {}; fd -e py -x uvx ruff check --output-format=github --fix --unsafe-fixes {}; fd -e py -x uvx ruff format --respect-gitignore --target-version py312 {}; python -m pytest;
```

## 8. Post-Work Activities

### 8.1. Critical Reflection
- After completing a step, say "Wait, but" and do additional careful critical reasoning
- Go back, think & reflect, revise & improve what you've done
- Don't invent functionality freely
- Stick to the goal of "minimal viable next version"

### 8.2. Documentation Updates
- Update `WORK.md` with what you've done and what needs to be done next
- Document all changes in `CHANGELOG.md`
- Update `TODO.md` and `PLAN.md` accordingly

## 9. Work Methodology

### 9.1. Virtual Team Approach
Be creative, diligent, critical, relentless & funny! Lead two experts:
- **"Ideot"** - for creative, unorthodox ideas
- **"Critin"** - to critique flawed thinking and moderate for balanced discussions

Collaborate step-by-step, sharing thoughts and adapting. If errors are found, step back and focus on accuracy and progress.

### 9.2. Continuous Work Mode
- Treat all items in `PLAN.md` and `TODO.md` as one huge TASK
- Work on implementing the next item
- Review, reflect, refine, revise your implementation
- Periodically check off completed issues
- Continue to the next item without interruption

## 10. Special Commands

### 10.1. `/plan` Command - Transform Requirements into Detailed Plans

When I say "/plan [requirement]", you must:

1. **DECONSTRUCT** the requirement:
- Extract core intent, key features, and objectives
- Identify technical requirements and constraints
- Map what's explicitly stated vs. what's implied
- Determine success criteria

2. **DIAGNOSE** the project needs:
- Audit for missing specifications
- Check technical feasibility
- Assess complexity and dependencies
- Identify potential challenges

3. **RESEARCH** additional material: 
- Repeatedly call the `perplexity_ask` and request up-to-date information or additional remote context
- Repeatedly call the `context7` tool and request up-to-date software package documentation
- Repeatedly call the `codex` tool and request additional reasoning, summarization of files and second opinion

4. **DEVELOP** the plan structure:
- Break down into logical phases/milestones
- Create hierarchical task decomposition
- Assign priorities and dependencies
- Add implementation details and technical specs
- Include edge cases and error handling
- Define testing and validation steps

5. **DELIVER** to `PLAN.md`:
- Write a comprehensive, detailed plan with:
 - Project overview and objectives
 - Technical architecture decisions
 - Phase-by-phase breakdown
 - Specific implementation steps
 - Testing and validation criteria
 - Future considerations
- Simultaneously create/update `TODO.md` with the flat itemized `- [ ]` representation

**Plan Optimization Techniques:**
- **Task Decomposition:** Break complex requirements into atomic, actionable tasks
- **Dependency Mapping:** Identify and document task dependencies
- **Risk Assessment:** Include potential blockers and mitigation strategies
- **Progressive Enhancement:** Start with MVP, then layer improvements
- **Technical Specifications:** Include specific technologies, patterns, and approaches

### 10.2. `/report` Command

1. Read all `./TODO.md` and `./PLAN.md` files
2. Analyze recent changes
3. Document all changes in `./CHANGELOG.md`
4. Remove completed items from `./TODO.md` and `./PLAN.md`
5. Ensure `./PLAN.md` contains detailed, clear plans with specifics
6. Ensure `./TODO.md` is a flat simplified itemized representation

### 10.3. `/work` Command

1. Read all `./TODO.md` and `./PLAN.md` files and reflect
2. Write down the immediate items in this iteration into `./WORK.md`
3. Work on these items
4. Think, contemplate, research, reflect, refine, revise
5. Be careful, curious, vigilant, energetic
6. Verify your changes and think aloud
7. Consult, research, reflect
8. Periodically remove completed items from `./WORK.md`
9. Tick off completed items from `./TODO.md` and `./PLAN.md`
10. Update `./WORK.md` with improvement tasks
11. Execute `/report`
12. Continue to the next item

## 11. Additional Guidelines

- Ask before extending/refactoring existing code that may add complexity or break things
- Work tirelessly without constant updates when in continuous work mode
- Only notify when you've completed all `PLAN.md` and `TODO.md` items

## 12. Command Summary

- `/plan [requirement]` - Transform vague requirements into detailed `PLAN.md` and `TODO.md`
- `/report` - Update documentation and clean up completed tasks
- `/work` - Enter continuous work mode to implement plans
- You may use these commands autonomously when appropriate


</document_content>
</document>

<document index="12">
<source>LICENSE.txt</source>
<document_content>
                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "{}"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright {yyyy} {name of copyright owner}

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

</document_content>
</document>

<document index="13">
<source>PLAN.md</source>
<document_content>


## Next Development Phases

### Phase 3: Performance & Scalability
**Goal**: Optimize for large plugin collections (1000+ plugins)
**Timeline**: 1-2 weeks

**Tasks**:
1. Benchmark scan performance with varying collection sizes
2. Implement batch journal operations for better SQLite performance
3. Add connection pooling for concurrent database access
4. Dynamic worker pool sizing based on system resources
5. Adaptive timeout based on plugin complexity
6. Plugin scan retry mechanism for transient failures

**Success Criteria**:
- Scan 1000 plugins in under 5 minutes
- Handle collections of 5000+ plugins efficiently
- Reduce timeout failures by 50%

### Phase 4: Documentation & Developer Experience
**Goal**: Comprehensive documentation for users and contributors
**Timeline**: 1 week

**Tasks**:
1. Update README with complete architecture overview
2. Document SQLite storage design and benefits
3. Create user guide with CLI examples
4. Write API documentation for scanner modules
5. Add troubleshooting guide for common issues
6. Document crash recovery and resume features

**Deliverables**:
- Complete user documentation
- Developer API reference
- Architecture decision records (ADRs)
- Contributing guidelines

### Phase 5: Cross-Platform Support
**Goal**: Ensure reliability on Windows, macOS, and Linux
**Timeline**: 2 weeks

**Tasks**:
1. Test VST3 scanning on all platforms
2. Add Linux LV2 plugin support
3. Windows-specific path handling improvements
4. Platform-specific binary builds
5. CI/CD matrix for all platforms

**Success Criteria**:
- 95% plugin compatibility across platforms
- Zero platform-specific critical bugs
- Automated testing on all platforms

### Phase 6: Advanced Features
**Goal**: Enhanced plugin management capabilities
**Timeline**: 3-4 weeks

**Feature Set 1: Search & Organization**
- Full-text search using SQLite FTS5
- Plugin categorization (effects, instruments, etc.)
- User-defined tags and collections
- Smart filters and saved searches

**Feature Set 2: Preset Management**
- Extract and store plugin presets
- Preset backup and versioning
- Cross-plugin preset conversion
- Preset sharing format

**Feature Set 3: DAW Integration**
- Export to Ableton Live format
- Export to Logic Pro format
- Export to Reaper format
- Universal plugin manifest format

**Feature Set 4: Web Interface**
- REST API for plugin database
- React-based web UI
- Real-time plugin browser
- Remote scanning capabilities
- Multi-user support

## Technical Debt Reduction

### Immediate (This Week)
1. Remove deprecated scanner modules (scanner_clean.py, etc.)
2. Clean up `json_backend.py` and `migration.py`
3. Refactor `data.py` for clarity
4. Improve error messages throughout

### Short-term (Next 2 Weeks)
1. Add comprehensive logging framework
2. Implement proper retry decorators
3. Create plugin validation framework
4. Standardize exception handling

### Long-term (Next Month)
1. Plugin compatibility database
2. Automated plugin testing suite
3. Performance monitoring dashboard
4. Usage analytics (opt-in)

## Success Metrics

### Performance
- **Scan Speed**: 1000 plugins < 5 minutes
- **Memory Usage**: < 500MB for 5000 plugins
- **Database Size**: < 100MB for 5000 plugins
- **Query Speed**: < 100ms for searches

### Reliability
- **Scan Success Rate**: > 99.9%
- **Crash Recovery**: 100% data preservation
- **Resume Success**: 100% continuation
- **Data Integrity**: Zero corruption incidents

### Usability
- **Setup Time**: < 2 minutes
- **Learning Curve**: < 10 minutes to productivity
- **Documentation Coverage**: 100% of public APIs
- **User Satisfaction**: > 90% positive feedback

## Risk Management

### Technical Risks
1. **Plugin Compatibility**: Some plugins may not load with pedalboard
   - *Mitigation*: Maintain compatibility database, provide workarounds

2. **Performance Degradation**: Large collections may slow down
   - *Mitigation*: Implement pagination, lazy loading, caching strategies

3. **Cross-Platform Issues**: Different behavior across OSes
   - *Mitigation*: Extensive testing, platform-specific code paths

### Project Risks
1. **Scope Creep**: Feature requests beyond core functionality
   - *Mitigation*: Clear roadmap, feature prioritization framework

2. **Maintenance Burden**: Growing codebase complexity
   - *Mitigation*: Modular architecture, comprehensive testing

## Conclusion

The project has achieved a solid foundation with reliable scanning and storage. The focus now shifts to performance optimization, documentation, and advanced features that will make pedalboard-pluginary the definitive tool for audio plugin management.
</document_content>
</document>

<document index="14">
<source>README.md</source>
<document_content>
# Pedalboard Pluginary

[![PyPI version](https://badge.fury.io/py/pedalboard-pluginary.svg)](https://badge.fury.io/py/pedalboard-pluginary)
[![Python versions](https://img.shields.io/pypi/pyversions/pedalboard-pluginary.svg)](https://pypi.org/project/pedalboard-pluginary/)
[![Build Status](https://github.com/twardoch/pedalboard-pluginary/actions/workflows/ci.yml/badge.svg)](https://github.com/twardoch/pedalboard-pluginary/actions/workflows/ci.yml)
[![Codecov](https://codecov.io/gh/twardoch/pedalboard-pluginary/branch/main/graph/badge.svg)](https://codecov.io/gh/twardoch/pedalboard-pluginary)
[![License: Apache-2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)

**Pedalboard Pluginary** is an independent, high-performance Python package and command-line tool designed to scan, list, and manage VST3 and Audio Unit (AU) audio plugins. It serves as an invaluable companion for the [_Pedalboard_](https://github.com/spotify/pedalboard) library by Spotify, empowering developers and audio professionals to interact with their plugin collections programmatically. While intended to complement _Pedalboard_, it is not affiliated with _Pedalboard_ or Spotify.

## Table of Contents

*   [What is Pedalboard Pluginary?](#what-is-pedalboard-pluginary)
*   [Who is it For?](#who-is-it-for)
*   [Why is it Useful?](#why-is-it-useful)
*   [Recent Improvements](#recent-improvements)
*   [Installation](#installation)
*   [Command-Line Usage](#command-line-usage)
    *   [Scan for Plugins](#scan-for-plugins)
    *   [List and Search Plugins](#list-and-search-plugins)
    *   [Get Plugin Information](#get-plugin-information)
    *   [Manage Cache](#manage-cache)
*   [Python Library Usage](#python-library-usage)
*   [Future Plans](#future-plans)
*   [Technical Details](#technical-details)
    *   [Core Architecture](#core-architecture)
    *   [Code Structure](#code-structure)
    *   [Key Technologies & Libraries](#key-technologies--libraries)
    *   [Coding Conventions & Standards](#coding-conventions--standards)
    *   [Contributing Guidelines](#contributing-guidelines)
    *   [Testing](#testing)
*   [Changelog Highlights](#changelog-highlights)
*   [License](#license)
*   [Authors](#authors)

## What is Pedalboard Pluginary?

In the world of digital audio, plugins (like equalizers, reverbs, synthesizers) are essential tools. Pedalboard Pluginary helps you bridge the gap between your Python projects and your audio plugin arsenal. It meticulously scans your system, identifying installed VST3 (on macOS, Windows, and Linux) and Audio Unit (AU) plugins (on macOS). It then catalogs them, extracting crucial information like their names, paths, and even their default parameters.

**Key Features:**

*   **Comprehensive Plugin Scanning:** Automatically discovers VST3 and AU plugins in standard system locations and user-specified folders.
*   **High-Performance Engine:** Features an advanced asynchronous scanning engine for significantly faster discovery, especially with large plugin libraries.
*   **Robust Caching:** Utilizes an SQLite database by default for efficient storage and quick retrieval of plugin information, including indexed search and full-text search capabilities. Legacy JSON cache support with automatic migration is also included.
*   **Detailed Parameter Introspection:** Leverages the _Pedalboard_ library to access and list the default parameters of each plugin.
*   **Modern Command-Line Interface (CLI):** Offers a user-friendly CLI built with Click and Rich for easy interaction, searching, and management of your plugin library.
*   **Python Library:** Easily integrate plugin scanning and listing into your Python scripts and applications.
*   **Problematic Plugin Handling:** Includes a mechanism (`ignores.json`) to "blacklist" plugins known to cause issues, ensuring smoother operation.
*   **Cross-Platform:** Supports macOS (VST3, AU), Windows (VST3), and Linux (VST3). Requires Python 3.9+.

## Who is it For?

Pedalboard Pluginary is built for:

*   **Python Developers:** Working on audio applications, batch processing, or tools that need to interact with audio plugins.
*   **Audio Engineers & Music Producers:** Who want to programmatically manage or query their plugin collections, or automate audio workflows involving plugins.
*   **Researchers:** In audio signal processing or music information retrieval who need access to plugin metadata.
*   **Anyone using the Pedalboard library:** Who needs a reliable way to discover and list available plugins for use with Pedalboard.

## Why is it Useful?

Managing a large collection of audio plugins can be challenging. Pedalboard Pluginary simplifies this by:

*   **Automating Discovery:** No more manual searching for plugin paths.
*   **Providing Programmatic Access:** Use Python to get lists of plugins, their parameters, and other metadata, enabling automation and custom tooling.
*   **Enhancing Workflow with Pedalboard:** Easily find and identify plugins you want to load and use with the Pedalboard library.
*   **Boosting Performance:** The async scanning and SQLite cache ensure that even extensive plugin libraries are handled quickly and efficiently.
*   **Offering Powerful Search:** The CLI allows for quick filtering and searching of your plugin catalog.

## Recent Improvements

Pedalboard Pluginary has undergone significant enhancements to boost performance and scalability:

*   **Asynchronous Scanning:** Massively parallelized plugin scanning reduces scan times dramatically, especially for large libraries.
*   **SQLite Cache Backend:** The default cache now uses SQLite, offering indexed search, full-text search, and much better performance for large datasets compared to the previous JSON cache. Automatic migration from old JSON caches is supported.
*   **Modernized CLI (Planned/In Progress):** The command-line interface is being updated using Click and Rich for a more powerful, user-friendly experience with better help and output formatting (details below reflect this new interface).
*   **Enhanced Type Safety:** The codebase is strictly typed and checked with mypy, improving reliability.

## Installation

You can install Pedalboard Pluginary using pip:

```bash
python3 -m pip install --upgrade pedalboard-pluginary
```

For the latest development version:

```bash
python3 -m pip install --upgrade git+https://github.com/twardoch/pedalboard-pluginary
```
Requires Python 3.9 or newer.

## Command-Line Usage

Pedalboard Pluginary provides a powerful and user-friendly command-line interface that can be invoked using either `pbpluginary` or `python -m pedalboard_pluginary`.

The CLI offers comprehensive plugin management capabilities with multiple output formats and filtering options. All commands support `--help` for detailed usage information.

### Available Commands

#### 1. Scan for Plugins

The `scan` command discovers and catalogs audio plugins on your system:

```bash
# Basic scan (uses cache if available, scans if needed)
pbpluginary scan

# Force a complete rescan, clearing existing cache
pbpluginary scan --rescan

# Scan additional folders beyond standard locations
pbpluginary scan --extra-folders /path/to/custom/plugins

# Adjust parallel processing (default: 8 workers)
pbpluginary scan --workers 4

# Set timeout per plugin in seconds (default: 30)
pbpluginary scan --timeout 60

# Combine options for comprehensive scanning
pbpluginary scan --rescan --extra-folders /my/vst3 --workers 16
```

**Scanning Features:**
- **Process Isolation**: Each plugin is scanned in a separate process for maximum stability
- **Resumable Scans**: If scanning is interrupted, it automatically resumes from where it left off
- **Parallel Processing**: Utilizes multiple CPU cores for faster scanning
- **Timeout Protection**: Plugins that hang are automatically skipped after the timeout period
- **Progress Display**: Beautiful Rich progress bars show real-time scanning status

#### 2. List and Filter Plugins

The `list` command displays your plugin catalog with powerful filtering options:

```bash
# List all plugins in table format (default)
pbpluginary list

# Output in different formats
pbpluginary list --format json      # JSON output
pbpluginary list --format yaml      # YAML output (requires PyYAML)
pbpluginary list --format table     # Table output (default)

# Filter by plugin name (case-insensitive)
pbpluginary list --name "reverb"

# Filter by manufacturer/vendor
pbpluginary list --vendor "Native Instruments"

# Filter by plugin type
pbpluginary list --type vst3         # VST3 plugins only
pbpluginary list --type aufx         # Audio Unit plugins only

# Combine filters
pbpluginary list --vendor "FabFilter" --type vst3 --format json

# Export filtered results to file using shell redirection
pbpluginary list --vendor "Waves" --format json > waves_plugins.json
```

#### 3. Export Plugins (JSON/YAML)

Dedicated export commands for quick full catalog exports:

```bash
# Export all plugins as JSON
pbpluginary json                    # Output to stdout
pbpluginary json --output plugins.json      # Save to file
pbpluginary json --pretty           # Pretty-printed JSON

# Export all plugins as YAML
pbpluginary yaml                    # Output to stdout
pbpluginary yaml --output plugins.yaml      # Save to file

# Note: YAML export requires PyYAML installation:
# pip install pyyaml
```

**Export Formats Include:**
- Plugin name and ID
- Plugin type (VST3/AU)
- File path
- Manufacturer/vendor
- Parameters and their default values
- Additional metadata

#### 4. View Scanner Information

The `info` command provides detailed statistics about your plugin collection:

```bash
pbpluginary info
```

**Displays:**
- Total number of cached plugins
- Breakdown by plugin type (VST3, AU)
- Top manufacturers/vendors
- Cache file locations and sizes
- Detection of interrupted scans (active journal)

Example output:
```
Plugin Scanner Statistics
Total plugins cached: 237

Plugins by type:
  aufx: 89
  vst3: 148

Top vendors:
  Native Instruments: 42
  FabFilter: 15
  Waves: 38
  ...

Cache locations:
  Main cache: ~/Library/Caches/com.twardoch.pedalboard-pluginary/plugins.db
  Cache size: 2.34 MB
```

#### 5. Cache Management

The `clear` command manages the plugin cache:

```bash
# Clear the entire plugin cache (with confirmation prompt)
pbpluginary clear

# After clearing, run scan to rebuild cache
pbpluginary scan
```

### Global Options

All commands support these global options:

```bash
# Enable verbose logging for debugging
pbpluginary --verbose scan

# Show help for the main command
pbpluginary --help

# Show help for specific commands
pbpluginary scan --help
pbpluginary list --help
```

### Quick Start Examples

```bash
# First-time setup: scan all plugins
pbpluginary scan

# View summary of discovered plugins
pbpluginary info

# List all Native Instruments VST3 plugins
pbpluginary list --vendor "Native Instruments" --type vst3

# Export all plugins to JSON for backup
pbpluginary json --output my_plugins_backup.json --pretty

# Clear cache and rescan everything
pbpluginary clear
pbpluginary scan --rescan
```

### Platform-Specific Notes

- **macOS**: Scans both VST3 (from `/Library/Audio/Plug-Ins/VST3` and `~/Library/Audio/Plug-Ins/VST3`) and Audio Units
- **Windows**: Scans VST3 plugins from `C:\Program Files\Common Files\VST3`
- **Linux**: Scans VST3 plugins from `~/.vst3`, `/usr/lib/vst3`, `/usr/local/lib/vst3`

Cache files are stored in platform-specific locations:
- **macOS**: `~/Library/Caches/com.twardoch.pedalboard-pluginary/`
- **Linux**: `~/.cache/com.twardoch.pedalboard-pluginary/`
- **Windows**: `%LOCALAPPDATA%\com.twardoch.pedalboard-pluginary\Cache\`

## Python Library Usage

You can also use Pedalboard Pluginary as a library in your Python scripts.

**Basic Example:**

```python
from pedalboard_pluginary import PedalboardPluginary
from pedalboard_pluginary.config import PluginaryConfig, CacheConfig, ScanConfig # For customization
from pedalboard_pluginary.cache import SQLiteCacheBackend # or JSONCacheBackend
from pedalboard_pluginary.progress import TqdmProgress # or LogProgress, NoOpProgress
import asyncio # Required for async scanning

# For default behavior (async scanning, SQLite cache, TQDM progress)
# The PedalboardPluginary constructor can take a config object or individual backend/reporter instances.
pluginary_scanner = PedalboardPluginary()

# Perform a scan. By default, this will load from cache if available and up-to-date,
# or perform an async scan if needed.
# The scan() method intelligently decides whether to load or rescan.
# To force a full async rescan:
# plugins = asyncio.run(pluginary_scanner.full_scan_async())
# To force a full sync rescan:
# plugins = pluginary_scanner.full_scan()

# To load or scan as needed (recommended):
# If you want to ensure an async scan if data is missing/stale:
if not pluginary_scanner.cache_backend.exists(): # Or some other logic to check cache freshness
    print("Cache not found or stale, performing async scan...")
    plugins = asyncio.run(pluginary_scanner.full_scan_async())
else:
    print("Loading plugins from cache...")
    pluginary_scanner.load_data() # Loads from the backend specified in constructor
    plugins = pluginary_scanner.plugins

print(f"Found/loaded {len(plugins)} plugins.")

# List all VST3 plugins by FabFilter
fabfilter_vst3s = [
    p_info for p_info in plugins.values()
    if p_info.plugin_type == "vst3" and p_info.manufacturer and "FabFilter" in p_info.manufacturer
]

print("\\nFabFilter VST3 Plugins:")
for plugin in fabfilter_vst3s:
    print(f"  Name: {plugin.name}, Path: {plugin.path}")
    print(f"    Parameters ({len(plugin.parameters)}):")
    for param_name, param_details in list(plugin.parameters.items())[:3]: # Print first 3 params
        print(f"      - {param_name}: {param_details.value}")

# Get detailed information for a specific plugin by its ID
plugin_id_to_find = "vst3/FabFilter Pro-Q 3" # Example ID, adjust if not present
if plugin_id_to_find in plugins:
    pro_q3 = plugins[plugin_id_to_find]
    print(f"\\nDetails for {pro_q3.name}:")
    print(f"  Manufacturer: {pro_q3.manufacturer}")
    print(f"  Path: {pro_q3.path}")
else:
    print(f"\\nPlugin {plugin_id_to_find} not found in results.")

# More customized usage:
# Configure for synchronous scanning and JSON cache
config = PluginaryConfig(
    scan=ScanConfig(async_mode=False), # Configure scanning behavior
    cache=CacheConfig(backend="json")  # Specify cache type
)
custom_scanner = PedalboardPluginary(
    config=config,
    progress_reporter=LogProgress() # Use logging for progress feedback
)
# For sync scan:
custom_plugins = custom_scanner.full_scan()
print(f"\\nFound {len(custom_plugins)} plugins with custom synchronous settings (JSON cache).")

# Search for plugins (most effective with SQLite backend)
# Ensure you have scanned with SQLite backend first for these examples
if isinstance(pluginary_scanner.cache_backend, SQLiteCacheBackend):
    reverbs = pluginary_scanner.search_plugins(query="Reverb", limit=5)
    print("\\nFound reverbs (up to 5):")
    for reverb in reverbs:
        print(f"- {reverb.name} (Type: {reverb.plugin_type}, Manufacturer: {reverb.manufacturer or 'N/A'})")
else:
    print("\\nSearch examples are most effective with the SQLite backend (default).")

```

The main class you'll interact with is `PedalboardPluginary` (from `pedalboard_pluginary.__init__.py`, which imports from `pedalboard_pluginary.core`). It orchestrates the scanning process using specialized scanner classes (`VST3Scanner`, `AUScanner`) and manages the plugin data through cache backends (`SQLiteCacheBackend`, `JSONCacheBackend`). The `PluginInfo` and `PluginParameter` data models (from `pedalboard_pluginary.models`) represent the structured information about each plugin and its parameters.

## Future Plans

Pedalboard Pluginary is actively developed. Future enhancements may include:

*   **Plugin "Jobs":** A system to define and execute a stack of plugins with specific parameter values, useful for batch processing or applying plugin chains.
*   **Enhanced Plugin Categorization:** Intelligent categorization of plugins based on names, parameters, and other metadata.
*   **Configuration Management:** More robust configuration via files and environment variables.
*   **DAW Integration Helpers:** Utilities to facilitate interaction with Digital Audio Workstations.
*   **Plugin Preset System:** Support for saving and loading plugin parameter presets.

Stay tuned for more features!

## Technical Details

This section provides a deeper dive into how Pedalboard Pluginary works, its architecture, and guidelines for contributors.

### Core Architecture

Pedalboard Pluginary is designed with modularity, performance, and type safety in mind.

*   **Orchestration & Scanners:**
    *   The main `PedalboardPluginary` class (in `src/pedalboard_pluginary/core.py`) acts as the primary interface for library usage and orchestrates the scanning process.
    *   The `PedalboardScanner` class (in `src/pedalboard_pluginary/scanner.py`) manages the actual scanning logic, utilizing specialized scanner classes for different plugin types.
    *   `VST3Scanner` (in `src/pedalboard_pluginary/scanners/vst3_scanner.py`): Handles discovery and scanning of VST3 plugins across macOS, Windows, and Linux.
    *   `AUScanner` (in `src/pedalboard_pluginary/scanners/au_scanner.py`): Handles discovery and scanning of Audio Unit (AU) plugins on macOS, primarily using `auval` for discovery and `pedalboard` for introspection, with `auval` as a fallback.
    *   Scanners are built upon a `BaseScanner` (in `src/pedalboard_pluginary/base_scanner.py`) and adhere to `PluginScanner` protocols (defined in `src/pedalboard_pluginary/protocols.py`).

*   **Asynchronous Scanning:**
    *   To significantly improve performance, especially with large plugin libraries, Pedalboard Pluginary employs asynchronous scanning.
    *   The `AsyncScannerMixin` (in `src/pedalboard_pluginary/async_scanner.py`) provides core async capabilities using `asyncio`.
    *   Plugin loading, which can be I/O bound or CPU-bound (due to external processes), is offloaded to threads managed by `asyncio.get_event_loop().run_in_executor`.
    *   Concurrency is managed using `asyncio.Semaphore` to limit the number of plugins being processed simultaneously (configurable, defaults to 10, see `DEFAULT_MAX_CONCURRENT` in `src/pedalboard_pluginary/constants.py`).
    *   Timeout protection for individual plugin loading is implemented via `sync_timeout` and `async_timeout` utilities (from `src/pedalboard_pluginary/timeout.py`).

*   **Caching System:**
    *   **SQLite Backend (Default):** For optimal performance, scalability, and advanced querying, Pedalboard Pluginary defaults to an SQLite cache backend (`SQLiteCacheBackend` in `src/pedalboard_pluginary/cache/sqlite_backend.py`).
        *   Features indexed columns for fast lookups.
        *   Utilizes SQLite's Full-Text Search (FTS5) for efficient searching of plugin names and manufacturers.
        *   Stores plugin data as JSON blobs within the database.
        *   Designed to handle tens of thousands of plugins with minimal performance degradation.
        *   Includes performance pragmas (WAL mode, cache size adjustments) for speed and reliability.
    *   **JSON Backend (Legacy):** A legacy JSON-based cache (`JSONCacheBackend` in `src/pedalboard_pluginary/cache/json_backend.py`) is supported for backward compatibility.
    *   **Automatic Migration:** If an existing JSON cache is found and no SQLite cache is present, the tool will automatically attempt to migrate the data to the SQLite backend (`migrate_json_to_sqlite` in `src/pedalboard_pluginary/cache/migration.py`).
    *   **Cache Location:** Cache files are stored in a platform-specific user cache directory (e.g., `~/.cache/com.twardoch.pedalboard-pluginary/` on Linux, `~/Library/Application Support/com.twardoch.pedalboard-pluginary/` on macOS). This is managed by `get_cache_path` and `get_sqlite_cache_path` in `src/pedalboard_pluginary/data.py`.
    *   Both backends adhere to the `CacheBackend` protocol.

*   **Data Models & Serialization:**
    *   Plugin information is structured using dataclasses: `PluginInfo` for overall plugin metadata and `PluginParameter` for individual parameter details (defined in `src/pedalboard_pluginary/models.py`).
    *   A dedicated `PluginSerializer` (in `src/pedalboard_pluginary/serialization.py`) handles the conversion of these data models to and from dictionary representations suitable for JSON storage (either as standalone files or as JSON blobs in SQLite).
    *   TypedDicts (`SerializedPlugin`, `SerializedParameter` in `src/pedalboard_pluginary/types.py`) are used to ensure the structure of serialized data.
    *   Cache files include metadata such as cache version, creation/update timestamps, and scanner version for future compatibility and management.

*   **Plugin Introspection:**
    *   The actual loading of plugin binaries and introspection of their parameters is performed by the underlying [Spotify Pedalboard](https://github.com/spotify/pedalboard) library. Pedalboard Pluginary orchestrates the discovery and data handling around this core functionality.

*   **Ignoring Problematic Plugins:**
    *   A `default_ignores.json` file (in `src/pedalboard_pluginary/resources/`) contains a list of plugin identifiers known to cause issues with Pedalboard or scanning.
    *   Users can maintain their own `ignores.json` in the cache directory to extend this list. These plugins are skipped during scans.

*   **Error Handling & Resilience:**
    *   A custom exception hierarchy (`PluginaryError`, `ScannerError`, `CacheError`, etc., in `src/pedalboard_pluginary/exceptions.py`) provides granular error reporting.
    *   Retry logic with exponential backoff (`with_retry` decorator in `src/pedalboard_pluginary/retry.py`) is available for operations that might transiently fail.
    *   Timeout mechanisms protect against plugins that hang during loading.

### Code Structure

The project follows a standard Python source layout:

*   `src/pedalboard_pluginary/`: Main package directory.
    *   `__init__.py`: Package entry point, exports version and `PedalboardPluginary`.
    *   `cli.py`: (Intended location for Click-based CLI, as per `PLAN.md`). Current CLI logic is in `__main__.py`.
    *   `core.py`: Contains `PedalboardPluginary` class.
    *   `scanner.py`: Contains `PedalboardScanner` orchestrator.
    *   `async_scanner.py`: `AsyncScannerMixin` for concurrency.
    *   `base_scanner.py`: `BaseScanner` abstract class.
    *   `scanners/`: Specific plugin type scanners (`au_scanner.py`, `vst3_scanner.py`).
    *   `cache/`: Cache backends (`sqlite_backend.py`, `json_backend.py`, `migration.py`).
    *   `models.py`: Dataclasses (`PluginInfo`, `PluginParameter`).
    *   `serialization.py`: `PluginSerializer`.
    *   `protocols.py`: Interface definitions.
    *   `exceptions.py`: Custom exceptions.
    *   `constants.py`: Global constants.
    *   `types.py`: TypedDicts and type aliases.
    *   `utils.py`: Utility functions.
    *   `progress.py`: Progress reporting classes.
    *   `retry.py`: Retry decorators.
    *   `timeout.py`: Timeout utilities.
    *   `config.py`: (As per `PLAN.md`) Pydantic-based configuration management.
    *   `resources/default_ignores.json`: Default blacklist for plugins.
*   `src/pedalboard-stubs/`: Type stubs for `pedalboard` library.
*   `tests/`: Pytest tests.
*   `pyproject.toml`: Project configuration, dependencies, and tool settings.
*   `PLAN.md`: Detailed development plan, often reflecting the most current architectural design.

### Key Technologies & Libraries

*   **Python 3.9+**
*   **Core Functionality:**
    *   [Pedalboard](https://github.com/spotify/pedalboard): For loading plugins and introspecting parameters.
    *   `sqlite3`: For the default SQLite cache backend.
    *   `asyncio`: For concurrent plugin scanning.
*   **Command-Line Interface (CLI):**
    *   [Click](https://click.palletsprojects.com/): For building the modern, user-friendly CLI (primary CLI framework).
    *   [Rich](https://rich.readthedocs.io/): For beautiful and informative terminal output.
*   **Utilities:**
    *   `tqdm`: For progress bars during scanning.
    *   `PyYAML`: For YAML output in the CLI.
*   **Development & Testing:**
    *   `pytest`, `pytest-cov`
    *   `mypy` (run in strict mode)
    *   `black`, `isort`, `flake8`
    *   `hatchling` (for building)
    *   `typing-extensions` (for older Python versions)

### Coding Conventions & Standards

*   **Type Safety:** The project aims for full type safety using Python's type hinting and is checked with `mypy` in strict mode. See `pyproject.toml` for `mypy` configuration.
*   **Code Style:** Code is formatted using Black and isort. Flake8 is used for linting. These are enforced via pre-commit hooks (see `.pre-commit-config.yaml`).
*   **Pythonic Code:** Adherence to idiomatic Python practices is encouraged.
*   **Modularity:** Functionality is broken down into logical modules and classes, often using protocols for defining interfaces.

### Contributing Guidelines

Contributions are welcome! Please follow these guidelines:

1.  **Reporting Issues:**
    *   If you encounter bugs, have feature requests, or suggestions, please open an issue on the [GitHub Issues page](https://github.com/twardoch/pedalboard-pluginary/issues).
    *   Provide detailed information, including steps to reproduce, error messages, your operating system, and relevant versions.

2.  **Contributing Code:**
    *   Fork the repository on GitHub.
    *   Create a new branch for your feature or bug fix.
    *   Write clean, well-commented, and typed Python code.
    *   Add tests for any new functionality or bug fixes. Ensure existing tests pass.
    *   Run linters and formatters: `black .`, `isort .`, `flake8 .`, `mypy src`. Using `pre-commit install` is highly recommended to automate this.
    *   Submit a Pull Request (PR) to the `main` branch. Clearly describe the changes made and the problem solved.

3.  **Problematic Plugins:**
    *   If you find a plugin that causes Pedalboard Pluginary or Pedalboard to crash or hang, please report it.
    *   You can also contribute to the `src/pedalboard_pluginary/resources/default_ignores.json` file by submitting a PR. The key for a plugin is typically its type (e.g., `aufx` or `vst3`) followed by its filename stem (e.g., `"vst3/RX 10 Connect"`).

4.  **Development Setup:**
    *   It's recommended to use a virtual environment.
    *   Install dependencies: `python3 -m pip install -e .[dev]`
    *   The project is built using `hatchling` (configured in `pyproject.toml`). A `build.sh` script is provided for convenience.

### Testing

*   Tests are written using `pytest` and are located in the `tests/` directory.
*   Code coverage is measured using `pytest-cov`.
*   To run tests:
    ```bash
    pytest
    ```
*   Continuous Integration (CI) is set up using GitHub Actions (see `.github/workflows/ci.yml`). Tests are run automatically on pushes and pull requests across multiple Python versions (3.9, 3.10, 3.11).

## Changelog Highlights

*(Based on `CHANGELOG.md` - For a full list of changes, please refer to the [CHANGELOG.md](CHANGELOG.md) file.)*

*   **January 2025 (Ongoing Development):**
    *   **Code Streamlining & Optimization:** Major initiative for code organization, performance tuning (SQLite, async), and cleanup.
    *   **`from __future__ import annotations`:** Applied across codebase.
    *   **SQLite Performance:** Further pragmas and optimizations.
    *   **Type Safety & Cleanup:** Continuous improvements, removal of dead code.
*   **December 2024 (Major Enhancements):**
    *   **SQLite Cache Backend:** Introduced high-performance SQLite cache with FTS, replacing JSON as default. Includes auto-migration.
    *   **Async Scanning Engine:** Implemented fully asynchronous plugin scanning for massive speed improvements.
    *   **Architectural Refactor:** Modularized scanner architecture, improved type safety with protocols and TypedDicts, unified serialization, custom exception hierarchy, progress reporting, retry logic, and timeout protection.
    *   **Pedalboard Type Stubs:** Created comprehensive stubs for improved static analysis.
    *   Achieved 100% mypy compliance in strict mode.
*   **v1.1.0 (Previous Release):**
    *   Added `update` CLI command (basic version).
    *   Added `json` and `yaml` output for `list` command.
*   **v1.0.0 (Initial Release):**
    *   Basic VST3 and AU scanning and listing.
    *   Initial command-line interface.
    *   JSON cache for plugin information.

## License

This project is licensed under the Apache License, Version 2.0. See the [LICENSE.txt](LICENSE.txt) file for details.

Copyright (c) 2023-2024 Adam Twardoch.

_Pedalboard Pluginary_ is not affiliated with [Pedalboard](https://github.com/spotify/pedalboard) or Spotify.

## Authors

*   Adam Twardoch ([@twardoch](https://github.com/twardoch))

(With assistance from AI tools for development and documentation.)

</document_content>
</document>

<document index="15">
<source>TODO.md</source>
<document_content>
# Pedalboard Pluginary - TODO


## Phase B

### Performance & Optimization

- [ ] Performance benchmarking of scan operations with 1000+ plugins
- [ ] Optimize journal database operations for large plugin collections
- [ ] Implement adaptive timeout based on plugin complexity
- [ ] Add plugin scan retry mechanism for transient failures

### Documentation

- [ ] Update README.md with new isolated scanner architecture
- [ ] Document journaling system and crash recovery features
- [ ] Add API documentation for scanner_isolated module
- [ ] Create user guide for CLI commands
- [ ] Document SQLite storage architecture

### Code Quality

- [ ] Refactor `data.py` to focus on data path management
- [ ] Remove deprecated `json_backend.py` and `migration.py` modules
- [ ] Add type hints to remaining untyped functions
- [ ] Improve error messages and user feedback
- [ ] Clean up unused scanner modules (scanner_clean.py, etc.)

### Testing

- [ ] Add unit tests for ScanJournal class
- [ ] Create performance regression tests
- [ ] Test cross-platform compatibility (Windows, Linux)
- [ ] Add tests for edge cases in plugin parameter extraction
- [ ] Test concurrent scanning with multiple workers

### Features

- [ ] Add plugin preset management functionality
- [ ] Implement plugin categorization and tagging
- [ ] Add export functionality for different DAW formats
- [ ] Create web UI for plugin browser
- [ ] Add plugin search with full-text capabilities



</document_content>
</document>

<document index="16">
<source>WORK.md</source>
<document_content>
# Work Progress - 2025-08-06

## All Tasks Completed ✓

### Issue 201: JSON Output Format ✓
- Changed JSON output from list to dict with IDs as keys
- Modified the json command in CLI to output the desired format
- Tested and confirmed working

### Issue 202: Fix Manufacturer Extraction ✓
- Changed 'manufacturer' to 'manufacturer_name' in scan_single.py
- Now aligns with pedalboard's actual API (since v0.9.4)
- Will extract vendor information on next plugin rescan

### AU Plugin Scanning Fix ✓
- Fixed regex pattern in scanner_isolated.py for AU plugin discovery
- Changed from expecting numeric ID to file:// URL format
- AU plugins will now be properly discovered on macOS

### Documentation & Cleanup ✓
- Updated CHANGELOG.md with all three fixes
- Removed completed items from TODO.md
- Cleaned up issues/201.txt and issues/202.txt references
</document_content>
</document>

<document index="17">
<source>issues/201.txt</source>
<document_content>

## JSON output

`python -m pedalboard_pluginary json` gives this structure: 
```
[{"id": "vst3/ABLM2", "name": "ABLM2", "path": "/Library/Audio/Plug-Ins/VST3/ABLM2.vst3", "type": "vst3", "manufacturer": null, ...
```

I want a dict, where the keys are the `id` fields and the values are dicts with the remaining params. 


</document_content>
</document>

<document index="18">
<source>issues/202.txt</source>
<document_content>
# How to Extract Plugin Vendor/Manufacturer Information from Pedalboard

## Summary
The pedalboard library provides a `manufacturer_name` property on external plugin objects (VST3 and AudioUnit plugins) that can be used to extract the vendor/manufacturer information. This was introduced in pedalboard v0.9.4.

## Implementation Details

### 1. Pedalboard's Native Implementation
Pedalboard exposes manufacturer information through the `manufacturer_name` property on both VST3Plugin and AudioUnitPlugin classes:
- Property name: `manufacturer_name` 
- Type: str
- Availability: Since pedalboard v0.9.4

The C++ implementation extracts this from the JUCE PluginDescription's `manufacturerName` field (pedalboard.txt lines 13248-13252, 13474-13478).

### 2. Current pedalboard-pluginary Implementation
The current implementation in `scan_single.py` (lines 94-100) attempts to extract manufacturer info by:
1. Checking if the plugin object has a 'manufacturer' attribute
2. Converting it to string if present
3. Falling back to None if extraction fails

**Issue:** The code is checking for `plugin.manufacturer` but should be checking for `plugin.manufacturer_name` based on pedalboard's actual API.

### 3. Recommended Fix
Update `src/pedalboard_pluginary/scan_single.py` line 96-98:

Current (incorrect):
```python
if hasattr(plugin, 'manufacturer'):
    try:
        manufacturer = str(plugin.manufacturer)
```

Should be:
```python
if hasattr(plugin, 'manufacturer_name'):
    try:
        manufacturer = str(plugin.manufacturer_name)
```

### 4. Additional Metadata Available
Besides manufacturer_name, pedalboard plugins also expose:
- `descriptive_name` - A more descriptive name for the plugin
- `category` - Plugin category (e.g., "Dynamics", "Reverbs")
- `version` - Plugin version string
- `is_instrument` - Boolean indicating if plugin is an instrument

These are already being extracted in the metadata section of scan_single.py (lines 104-109).

### 5. Data Flow
1. Plugin scanner loads plugin using pedalboard's VST3Plugin or AudioUnitPlugin
2. Accesses the `manufacturer_name` property
3. Stores in the SerializedPlugin data structure
4. Saves to SQLite cache with manufacturer field
5. Can be queried/filtered using the --vendor CLI option

## References
- pedalboard_native.txt lines 2922-2924, 3616-3618: Python API documentation
- pedalboard.txt lines 13248-13252, 13474-13478: C++ binding implementation
- scan_single.py lines 94-100: Current extraction implementation
</document_content>
</document>

<document index="19">
<source>publish.sh</source>
<document_content>
#!/usr/bin/env bash
# this_file: build.sh

cd $(dirname "$0") || exit 1

set -e # Exit on error

uvx hatch clean 
llms . "llms.txt"
gitnextver .
uvx hatch build
uvx hatch publish

</document_content>
</document>

<document index="20">
<source>pyproject.toml</source>
<document_content>
[build-system]
requires = ["hatchling", "hatch-vcs"]
build-backend = "hatchling.build"

[project]
name = "pedalboard-pluginary"
dynamic = ["version"]
description = "A plugin scanner for Pedalboard"
readme = "README.md"
requires-python = ">=3.9"
license = { text = "Apache-2.0" }
authors = [
    { name = "Adam Twardoch", email = "adam@twardoch.com" }
]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: Apache Software License",
    "Operating System :: OS Independent",
    "Programming Language :: Python",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Topic :: Multimedia :: Sound/Audio",
    "Topic :: Software Development :: Libraries :: Python Modules",
]
dependencies = [
    "pedalboard>=0.8.7",
    "fire>=0.5.0",
    "python-benedict>=0.33.0",
    "pyyaml>=6.0.1",
    "typing-extensions>=4.0.0; python_version < '3.11'",
    "tqdm>=4.60.0",
]

[project.urls]
Documentation = "https://github.com/twardoch/pedalboard-pluginary#readme"
Source = "https://github.com/twardoch/pedalboard-pluginary"
Tracker = "https://github.com/twardoch/pedalboard-pluginary/issues"

[project.optional-dependencies]
dev = [
    "pytest>=7.4.4",
    "pytest-cov>=4.1.0",
    "mypy>=1.8.0",
    "flake8>=7.0.0",
    "black>=24.1.1",
    "isort>=5.13.2",
    "psutil>=5.9.0", # Added for memory profiling in tests
    "build>=0.10.0",
    "twine>=4.0.0",
    "pyinstaller>=5.0.0",
]

[project.scripts]
pbpluginary = "pedalboard_pluginary.__main__:main"

[tool.setuptools]
packages = ["pedalboard_pluginary"]
package-dir = {"" = "src"}

[tool.pytest.ini_options]
addopts = "--cov=pedalboard_pluginary --cov-report=term-missing"
testpaths = ["tests"]

[tool.flake8]
max_line_length = 88
extend_ignore = "E203,W503"
exclude = [
    ".tox",
    "build",
    "dist",
    ".eggs",
    "docs/conf.py",
]

[tool.mypy]
python_version = "3.9"
mypy_path = "src"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_incomplete_defs = true
check_untyped_defs = true
disallow_untyped_decorators = true
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_no_return = true
warn_unreachable = true

[[tool.mypy.overrides]]
module = ["fire", "benedict"]
ignore_missing_imports = true

[tool.black]
line-length = 88
target-version = ['py39']
include = '\.pyi?$'

[tool.isort]
profile = "black"
multi_line_output = 3

[tool.hatch.version]
source = "vcs"

[tool.hatch.build.hooks.vcs]
version-file = "src/pedalboard_pluginary/_version.py"

[tool.hatch.build.targets.wheel]
packages = ["src/pedalboard_pluginary"]

[tool.hatch.build.targets.sdist]
include = [
    "/src",
    "/tests",
    "/README.md",
    "/LICENSE.txt",
    "/CHANGELOG.md",
]

</document_content>
</document>

<document index="21">
<source>scripts/format.sh</source>
<document_content>
#!/usr/bin/env bash
# this_file: scripts/format.sh

set -e # Exit on error

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Function to print colored output
print_step() {
    echo -e "${BLUE}$1${NC}"
}

print_success() {
    echo -e "${GREEN}✅ $1${NC}"
}

print_warning() {
    echo -e "${YELLOW}⚠️ $1${NC}"
}

print_error() {
    echo -e "${RED}❌ $1${NC}"
}

print_step "🎨 Formatting Python code..."

# Format with black
print_step "  Running black..."
python -m black src/pedalboard_pluginary tests/

# Sort imports with isort
print_step "  Running isort..."
python -m isort src/pedalboard_pluginary tests/

print_success "Code formatting complete!"

# Check if there are any changes
if git diff --quiet; then
    print_success "No changes needed - code was already formatted"
else
    print_warning "Code has been formatted. Review changes and commit if needed."
    print_step "📋 Changed files:"
    git diff --name-only
fi
</document_content>
</document>

<document index="22">
<source>scripts/release.sh</source>
<document_content>
#!/usr/bin/env bash
# this_file: scripts/release.sh

set -e # Exit on error

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Function to print colored output
print_step() {
    echo -e "${BLUE}$1${NC}"
}

print_success() {
    echo -e "${GREEN}✅ $1${NC}"
}

print_warning() {
    echo -e "${YELLOW}⚠️ $1${NC}"
}

print_error() {
    echo -e "${RED}❌ $1${NC}"
}

# Get the version from command line argument or prompt
VERSION=$1
if [ -z "$VERSION" ]; then
    echo "Usage: $0 <version>"
    echo "Example: $0 1.2.0"
    exit 1
fi

# Validate version format (basic semver check)
if ! [[ $VERSION =~ ^[0-9]+\.[0-9]+\.[0-9]+(-[a-zA-Z0-9]+)?$ ]]; then
    print_error "Invalid version format. Use semantic versioning (e.g., 1.2.0)"
    exit 1
fi

# Check if we're in a git repository
if ! git rev-parse --is-inside-work-tree > /dev/null 2>&1; then
    print_error "Not in a git repository"
    exit 1
fi

# Check if working directory is clean
if ! git diff-index --quiet HEAD --; then
    print_error "Working directory is not clean. Please commit or stash changes first."
    git status
    exit 1
fi

# Check if we're on main branch
CURRENT_BRANCH=$(git branch --show-current)
if [ "$CURRENT_BRANCH" != "main" ]; then
    print_warning "Not on main branch (currently on $CURRENT_BRANCH)"
    read -p "Do you want to continue? (y/N): " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        print_error "Release cancelled"
        exit 1
    fi
fi

# Check if tag already exists
if git tag | grep -q "^v$VERSION$"; then
    print_error "Tag v$VERSION already exists"
    exit 1
fi

print_step "🚀 Starting release process for version $VERSION"

# Update CHANGELOG.md
print_step "📝 Please update CHANGELOG.md with the new release notes"
read -p "Press Enter when CHANGELOG.md is updated..."

# Run full build and test
print_step "🔨 Running full build and test..."
./build.sh

# Create git tag
print_step "🏷️ Creating git tag v$VERSION"
git tag -a "v$VERSION" -m "Release version $VERSION"

# Show what will be pushed
print_step "📋 Changes to be pushed:"
git log --oneline HEAD~5..HEAD
echo ""
echo "Tag: v$VERSION"

# Confirm before pushing
print_warning "This will push the tag to GitHub, which will trigger the release workflow"
read -p "Do you want to continue? (y/N): " -n 1 -r
echo
if [[ ! $REPLY =~ ^[Yy]$ ]]; then
    print_error "Release cancelled"
    # Remove the tag we just created
    git tag -d "v$VERSION"
    exit 1
fi

# Push tag to trigger release
print_step "📤 Pushing tag to GitHub..."
git push origin "v$VERSION"

print_success "Release process completed!"
print_step "📋 Next steps:"
echo "  • Monitor GitHub Actions for release workflow"
echo "  • Check GitHub releases page for created release"
echo "  • Verify PyPI upload (if configured)"
echo "  • Update documentation if needed"

# Open GitHub releases page
if command -v gh &> /dev/null; then
    print_step "🌐 Opening GitHub releases page..."
    gh release view "v$VERSION" --web || echo "Release may not be created yet. Check GitHub Actions."
else
    echo "  • Install 'gh' CLI to automatically open GitHub releases"
fi
</document_content>
</document>

<document index="23">
<source>scripts/test.sh</source>
<document_content>
#!/usr/bin/env bash
# this_file: scripts/test.sh

set -e # Exit on error

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Function to print colored output
print_step() {
    echo -e "${BLUE}$1${NC}"
}

print_success() {
    echo -e "${GREEN}✅ $1${NC}"
}

print_warning() {
    echo -e "${YELLOW}⚠️ $1${NC}"
}

print_error() {
    echo -e "${RED}❌ $1${NC}"
}

# Parse command line arguments
COVERAGE_REPORT="term-missing"
COVERAGE_FAIL_UNDER=80
VERBOSE=false
PARALLEL=false
TEST_PATTERN=""

while [[ $# -gt 0 ]]; do
    case $1 in
        --coverage-html)
            COVERAGE_REPORT="html"
            shift
            ;;
        --coverage-xml)
            COVERAGE_REPORT="xml"
            shift
            ;;
        --coverage-fail-under)
            COVERAGE_FAIL_UNDER="$2"
            shift 2
            ;;
        --verbose|-v)
            VERBOSE=true
            shift
            ;;
        --parallel|-p)
            PARALLEL=true
            shift
            ;;
        --pattern|-k)
            TEST_PATTERN="$2"
            shift 2
            ;;
        --help|-h)
            echo "Usage: $0 [options]"
            echo "Options:"
            echo "  --coverage-html          Generate HTML coverage report"
            echo "  --coverage-xml           Generate XML coverage report"
            echo "  --coverage-fail-under N  Fail if coverage is below N% (default: 80)"
            echo "  --verbose, -v            Verbose output"
            echo "  --parallel, -p           Run tests in parallel"
            echo "  --pattern, -k PATTERN    Run tests matching pattern"
            echo "  --help, -h               Show this help"
            exit 0
            ;;
        *)
            print_error "Unknown option: $1"
            exit 1
            ;;
    esac
done

print_step "🧪 Running test suite..."

# Build pytest command
PYTEST_ARGS=("tests/")

if [ "$VERBOSE" = true ]; then
    PYTEST_ARGS+=("-v")
fi

if [ "$PARALLEL" = true ]; then
    PYTEST_ARGS+=("-n" "auto")
fi

if [ -n "$TEST_PATTERN" ]; then
    PYTEST_ARGS+=("-k" "$TEST_PATTERN")
fi

# Add coverage arguments
PYTEST_ARGS+=("--cov=pedalboard_pluginary")
PYTEST_ARGS+=("--cov-report=$COVERAGE_REPORT")
PYTEST_ARGS+=("--cov-fail-under=$COVERAGE_FAIL_UNDER")

# Set PYTHONPATH
export PYTHONPATH=src

print_step "📋 Test configuration:"
echo "  Coverage report: $COVERAGE_REPORT"
echo "  Coverage threshold: $COVERAGE_FAIL_UNDER%"
echo "  Verbose: $VERBOSE"
echo "  Parallel: $PARALLEL"
if [ -n "$TEST_PATTERN" ]; then
    echo "  Pattern: $TEST_PATTERN"
fi

# Run tests
print_step "🔬 Executing tests..."
pytest "${PYTEST_ARGS[@]}"

print_success "All tests passed!"

# Show coverage report location if HTML was generated
if [ "$COVERAGE_REPORT" = "html" ]; then
    print_step "📊 Coverage report generated: htmlcov/index.html"
    if command -v open &> /dev/null; then
        open htmlcov/index.html
    elif command -v xdg-open &> /dev/null; then
        xdg-open htmlcov/index.html
    fi
fi
</document_content>
</document>

<document index="24">
<source>src/pedalboard-stubs/__init__.pyi</source>
<document_content>
"""Type stubs for pedalboard library."""

from typing import Dict, Union, Any, Optional, TypeVar
from pathlib import Path

# Parameter value types that pedalboard can return
ParameterValue = Union[float, int, bool, str]

class Plugin:
    """Base plugin class."""
    
    # Core attributes that all plugins have
    parameters: Dict[str, ParameterValue]
    name: str
    manufacturer: Optional[str]
    
    def __init__(self, *args: Any, **kwargs: Any) -> None: ...

class AudioUnitPlugin(Plugin):
    """Audio Unit plugin class."""
    pass

class VST3Plugin(Plugin):
    """VST3 plugin class."""
    pass

# Plugin loading function
def load_plugin(
    path_or_name: Union[str, Path], 
    plugin_name: Optional[str] = None,
    disable_caching: bool = False,
    **kwargs: Any
) -> Plugin: ...

# Re-export common types
__all__ = [
    "Plugin",
    "AudioUnitPlugin", 
    "VST3Plugin",
    "load_plugin",
    "ParameterValue",
]
</document_content>
</document>

# File: /Users/adam/Developer/vcs/github.twardoch/pub/pedalboard-pluginary/src/pedalboard_pluginary/__init__.py
# Language: python

from importlib.metadata import PackageNotFoundError, version
from .core import PedalboardPluginary
from .scanner_isolated import IsolatedPedalboardScanner


# File: /Users/adam/Developer/vcs/github.twardoch/pub/pedalboard-pluginary/src/pedalboard_pluginary/__main__.py
# Language: python

import logging
import click
from rich.console import Console
from rich.table import Table
from .core import PedalboardPluginary
import json
import json
import yaml
from .data import get_cache_path
import json as json_module
import yaml as yaml_module

def cli((verbose: bool)):
    """A CLI for scanning and managing audio plugins."""

def scan((rescan: bool, extra_folders: tuple[str], workers: int | None, timeout: int)):
    """Scan for audio plugins."""

def list_plugins((
    name: str | None, vendor: str | None, plugin_type: str | None, output_format: str
)):
    """List scanned plugins."""

def info(()):
    """Display scanner statistics and cache information."""

def clear(()):
    """Clear the plugin cache."""

def json((output: str | None, pretty: bool)):
    """Export all plugins as JSON."""

def yaml((output: str | None)):
    """Export all plugins as YAML."""


# File: /Users/adam/Developer/vcs/github.twardoch/pub/pedalboard-pluginary/src/pedalboard_pluginary/cache/__init__.py
# Language: python

from .sqlite_backend import SQLiteCacheBackend
from .json_backend import JSONCacheBackend
from .migration import migrate_json_to_sqlite


# File: /Users/adam/Developer/vcs/github.twardoch/pub/pedalboard-pluginary/src/pedalboard_pluginary/cache/json_backend.py
# Language: python

from typing import Dict
from pathlib import Path
from ..models import PluginInfo
from ..protocols import CacheBackend
from ..serialization import PluginSerializer

class JSONCacheBackend(C, a, c, h, e, B, a, c, k, e, n, d):
    """Legacy JSON cache backend for backward compatibility."""
    def __init__((self, json_path: Path)):
    def load((self)) -> Dict[str, PluginInfo]:
        """Load plugins from JSON cache."""
    def save((self, plugins: Dict[str, PluginInfo])) -> None:
        """Save plugins to JSON cache."""
    def update((self, plugin_id: str, plugin: PluginInfo)) -> None:
        """Update a single plugin in JSON cache."""
    def delete((self, plugin_id: str)) -> None:
        """Remove a plugin from JSON cache."""
    def clear((self)) -> None:
        """Clear JSON cache."""
    def exists((self)) -> bool:
        """Check if JSON cache exists."""

def __init__((self, json_path: Path)):

def load((self)) -> Dict[str, PluginInfo]:
    """Load plugins from JSON cache."""

def save((self, plugins: Dict[str, PluginInfo])) -> None:
    """Save plugins to JSON cache."""

def update((self, plugin_id: str, plugin: PluginInfo)) -> None:
    """Update a single plugin in JSON cache."""

def delete((self, plugin_id: str)) -> None:
    """Remove a plugin from JSON cache."""

def clear((self)) -> None:
    """Clear JSON cache."""

def exists((self)) -> bool:
    """Check if JSON cache exists."""


# File: /Users/adam/Developer/vcs/github.twardoch/pub/pedalboard-pluginary/src/pedalboard_pluginary/cache/migration.py
# Language: python

import logging
from pathlib import Path
from ..models import PluginInfo
from .json_backend import JSONCacheBackend
from .sqlite_backend import SQLiteCacheBackend

def migrate_json_to_sqlite((json_path: Path, sqlite_path: Path)) -> int:
    """Migrate plugins from JSON cache to SQLite cache."""

def backup_json_cache((json_path: Path, backup_suffix: str = ".backup")) -> Path:
    """Create a backup of the JSON cache before migration."""


# File: /Users/adam/Developer/vcs/github.twardoch/pub/pedalboard-pluginary/src/pedalboard_pluginary/cache/sqlite_backend.py
# Language: python

import sqlite3
import json
import time
import logging
from typing import Dict, List, Set, Any
from pathlib import Path
from ..models import PluginInfo
from ..protocols import CacheBackend
from ..serialization import PluginSerializer
from ..exceptions import CacheError

class SQLiteCacheBackend(C, a, c, h, e, B, a, c, k, e, n, d):
    """High-performance SQLite cache with indexing and full-text search."""
    def __init__((self, db_path: Path)):
    def _connect((self)) -> sqlite3.Connection:
        """Create database connection with optimizations."""
    def _init_schema((self)) -> None:
        """Initialize optimized database schema."""
    def load((self)) -> Dict[str, PluginInfo]:
        """Load all cached plugins."""
    def save((self, plugins: Dict[str, PluginInfo])) -> None:
        """Save plugins to cache."""
    def add_plugins((self, plugins: List)) -> None:
        """Add multiple plugins to cache without clearing existing data."""
    def update((self, plugin_id: str, plugin: PluginInfo)) -> None:
        """Update a single plugin in cache."""
    def delete((self, plugin_id: str)) -> None:
        """Remove a plugin from cache."""
    def get_all_plugins((self)) -> List[Dict[str, Any]]:
        """Get all plugins from cache as a list of dictionaries."""
    def get_cached_paths((self)) -> Set[str]:
        """Get all cached plugin paths for quick existence checking."""
    def clear((self)) -> None:
        """Clear entire cache."""
    def exists((self)) -> bool:
        """Check if cache exists."""
    def search((self, query: str, limit: int = 50)) -> List[PluginInfo]:
        """Full-text search for plugins."""
    def filter_by_type((self, plugin_type: str)) -> List[PluginInfo]:
        """Filter plugins by type."""
    def get_stats((self)) -> Dict[str, int]:
        """Get cache statistics."""
    def _insert_plugin((self, conn: sqlite3.Connection, plugin_id: str, plugin: PluginInfo, current_time: float)) -> None:
        """Insert a plugin into the database."""
    def _update_plugin((self, conn: sqlite3.Connection, plugin_id: str, plugin: PluginInfo, current_time: float)) -> None:
        """Update an existing plugin in the database."""

def __init__((self, db_path: Path)):

def _connect((self)) -> sqlite3.Connection:
    """Create database connection with optimizations."""

def _init_schema((self)) -> None:
    """Initialize optimized database schema."""

def load((self)) -> Dict[str, PluginInfo]:
    """Load all cached plugins."""

def save((self, plugins: Dict[str, PluginInfo])) -> None:
    """Save plugins to cache."""

def add_plugins((self, plugins: List)) -> None:
    """Add multiple plugins to cache without clearing existing data."""

def update((self, plugin_id: str, plugin: PluginInfo)) -> None:
    """Update a single plugin in cache."""

def delete((self, plugin_id: str)) -> None:
    """Remove a plugin from cache."""

def get_all_plugins((self)) -> List[Dict[str, Any]]:
    """Get all plugins from cache as a list of dictionaries."""

def get_cached_paths((self)) -> Set[str]:
    """Get all cached plugin paths for quick existence checking."""

def clear((self)) -> None:
    """Clear entire cache."""

def exists((self)) -> bool:
    """Check if cache exists."""

def search((self, query: str, limit: int = 50)) -> List[PluginInfo]:
    """Full-text search for plugins."""

def filter_by_type((self, plugin_type: str)) -> List[PluginInfo]:
    """Filter plugins by type."""

def get_stats((self)) -> Dict[str, int]:
    """Get cache statistics."""

def _insert_plugin((self, conn: sqlite3.Connection, plugin_id: str, plugin: PluginInfo, current_time: float)) -> None:
    """Insert a plugin into the database."""

def _update_plugin((self, conn: sqlite3.Connection, plugin_id: str, plugin: PluginInfo, current_time: float)) -> None:
    """Update an existing plugin in the database."""


# File: /Users/adam/Developer/vcs/github.twardoch/pub/pedalboard-pluginary/src/pedalboard_pluginary/constants.py
# Language: python

from typing import Final


# File: /Users/adam/Developer/vcs/github.twardoch/pub/pedalboard-pluginary/src/pedalboard_pluginary/core.py
# Language: python

from .cache.sqlite_backend import SQLiteCacheBackend
from .data import get_cache_path
from .scanner_isolated import IsolatedPedalboardScanner

class PedalboardPluginary:
    """ Main class for interacting with the plugin library...."""
    def __init__((self, **scanner_kwargs)):
    def scan((self, rescan: bool = False, extra_folders: list[str] | None = None)):
        """ Initiates a plugin scan...."""
    def list_plugins((self, **filters)) -> list[dict]:
        """Lists plugins from the cache, optionally applying filters."""
    def get_plugin_details((self, plugin_id: str)) -> dict | None:
        """Retrieves detailed information for a single plugin."""

def __init__((self, **scanner_kwargs)):

def scan((self, rescan: bool = False, extra_folders: list[str] | None = None)):
    """ Initiates a plugin scan...."""

def list_plugins((self, **filters)) -> list[dict]:
    """Lists plugins from the cache, optionally applying filters."""

def get_plugin_details((self, plugin_id: str)) -> dict | None:
    """Retrieves detailed information for a single plugin."""


# File: /Users/adam/Developer/vcs/github.twardoch/pub/pedalboard-pluginary/src/pedalboard_pluginary/data.py
# Language: python

import json
import os
from pathlib import Path
from importlib import resources
from .utils import *

def get_cache_path((cache_name)):
    """Get the path to a cache file."""

def load_json_file((file_path)):
    """Load JSON data from a file."""

def save_json_file((data, file_path)):
    """Save JSON data to a file."""

def load_ignores((ignores_path)):
    """Load ignores data from the file."""

def save_ignores((ignores, ignores_path)):
    """Save ignores data to the file."""

def copy_default_ignores((destination_path)):
    """Copy the default ignores file to the destination if it does not exist."""


# File: /Users/adam/Developer/vcs/github.twardoch/pub/pedalboard-pluginary/src/pedalboard_pluginary/exceptions.py
# Language: python

from typing import Optional

class PluginaryError(E, x, c, e, p, t, i, o, n):
    """Base exception for all Pluginary errors."""
    def __init__((self, message: str, details: Optional[str] = None)):
        """Initialize the exception with a message and optional details."""
    def __str__((self)) -> str:
        """Return string representation of the error."""

class ScannerError(P, l, u, g, i, n, a, r, y, E, r, r, o, r):
    """Base exception for scanner-related errors."""

class PluginLoadError(S, c, a, n, n, e, r, E, r, r, o, r):
    """Raised when a plugin fails to load."""
    def __init__((self, plugin_path: str, reason: Optional[str] = None)):
        """Initialize the exception."""

class PluginScanError(S, c, a, n, n, e, r, E, r, r, o, r):
    """Raised when scanning a plugin fails."""
    def __init__((self, plugin_path: str, scanner_type: str, reason: Optional[str] = None)):
        """Initialize the exception."""

class CacheError(P, l, u, g, i, n, a, r, y, E, r, r, o, r):
    """Base exception for cache-related errors."""

class CacheCorruptedError(C, a, c, h, e, E, r, r, o, r):
    """Raised when cache file is corrupted."""
    def __init__((self, cache_path: str, reason: Optional[str] = None)):
        """Initialize the exception."""

class CacheVersionError(C, a, c, h, e, E, r, r, o, r):
    """Raised when cache version is incompatible."""
    def __init__((self, expected: str, actual: str, cache_path: str)):
        """Initialize the exception."""

class CacheWriteError(C, a, c, h, e, E, r, r, o, r):
    """Raised when writing to cache fails."""
    def __init__((self, cache_path: str, reason: Optional[str] = None)):
        """Initialize the exception."""

class ConfigError(P, l, u, g, i, n, a, r, y, E, r, r, o, r):
    """Base exception for configuration-related errors."""

class InvalidConfigError(C, o, n, f, i, g, E, r, r, o, r):
    """Raised when configuration is invalid."""
    def __init__((self, config_key: str, invalid_value: str, reason: Optional[str] = None)):
        """Initialize the exception."""

class PlatformError(P, l, u, g, i, n, a, r, y, E, r, r, o, r):
    """Raised when an operation is not supported on the current platform."""
    def __init__((self, operation: str, platform: str, supported_platforms: Optional[list[str]] = None)):
        """Initialize the exception."""

def __init__((self, message: str, details: Optional[str] = None)):
    """Initialize the exception with a message and optional details."""

def __str__((self)) -> str:
    """Return string representation of the error."""

def __init__((self, plugin_path: str, reason: Optional[str] = None)):
    """Initialize the exception."""

def __init__((self, plugin_path: str, scanner_type: str, reason: Optional[str] = None)):
    """Initialize the exception."""

def __init__((self, cache_path: str, reason: Optional[str] = None)):
    """Initialize the exception."""

def __init__((self, expected: str, actual: str, cache_path: str)):
    """Initialize the exception."""

def __init__((self, cache_path: str, reason: Optional[str] = None)):
    """Initialize the exception."""

def __init__((self, config_key: str, invalid_value: str, reason: Optional[str] = None)):
    """Initialize the exception."""

def __init__((self, operation: str, platform: str, supported_platforms: Optional[list[str]] = None)):
    """Initialize the exception."""


# File: /Users/adam/Developer/vcs/github.twardoch/pub/pedalboard-pluginary/src/pedalboard_pluginary/models.py
# Language: python

from dataclasses import dataclass, field
from typing import Dict, Optional
from .types import ParameterValue

class PluginParameter:
    """Represents a single parameter of a plugin."""

class PluginInfo:
    """Represents a scanned audio plugin."""


# File: /Users/adam/Developer/vcs/github.twardoch/pub/pedalboard-pluginary/src/pedalboard_pluginary/progress.py
# Language: python

import logging
from typing import Any, Callable, Optional
from tqdm import tqdm
from .protocols import ProgressReporter

class TqdmProgress(P, r, o, g, r, e, s, s, R, e, p, o, r, t, e, r):
    """Progress reporter using tqdm progress bars."""
    def __init__((self)) -> None:
        """Initialize the progress reporter."""
    def start((self, total: int, description: str = "")) -> None:
        """Start progress tracking."""
    def update((self, amount: int = 1, message: Optional[str] = None)) -> None:
        """Update progress. ..."""
    def finish((self, message: Optional[str] = None)) -> None:
        """Finish progress tracking."""

class NoOpProgress(P, r, o, g, r, e, s, s, R, e, p, o, r, t, e, r):
    """No-operation progress reporter for quiet mode."""
    def start((self, total: int, description: str = "")) -> None:
        """Start progress tracking (no-op)."""
    def update((self, amount: int = 1, message: Optional[str] = None)) -> None:
        """Update progress (no-op)."""
    def finish((self, message: Optional[str] = None)) -> None:
        """Finish progress tracking (no-op)."""

class LogProgress(P, r, o, g, r, e, s, s, R, e, p, o, r, t, e, r):
    """Progress reporter that logs to standard logging."""
    def __init__((self, log_level: int = logging.INFO)):
        """Initialize the progress reporter."""
    def start((self, total: int, description: str = "")) -> None:
        """Start progress tracking."""
    def update((self, amount: int = 1, message: Optional[str] = None)) -> None:
        """Update progress. ..."""
    def finish((self, message: Optional[str] = None)) -> None:
        """Finish progress tracking."""

class CallbackProgress(P, r, o, g, r, e, s, s, R, e, p, o, r, t, e, r):
    """Progress reporter that calls user-provided callbacks."""
    def __init__((
        self,
        on_start: Optional[Callable[[int, str], None]] = None,
        on_update: Optional[Callable[[int, int, Optional[str]], None]] = None,
        on_finish: Optional[Callable[[Optional[str]], None]] = None,
    )):
        """Initialize the progress reporter with callbacks."""
    def start((self, total: int, description: str = "")) -> None:
        """Start progress tracking."""
    def update((self, amount: int = 1, message: Optional[str] = None)) -> None:
        """Update progress. ..."""
    def finish((self, message: Optional[str] = None)) -> None:
        """Finish progress tracking."""

def __init__((self)) -> None:
    """Initialize the progress reporter."""

def start((self, total: int, description: str = "")) -> None:
    """Start progress tracking."""

def update((self, amount: int = 1, message: Optional[str] = None)) -> None:
    """Update progress. ..."""

def finish((self, message: Optional[str] = None)) -> None:
    """Finish progress tracking."""

def start((self, total: int, description: str = "")) -> None:
    """Start progress tracking (no-op)."""

def update((self, amount: int = 1, message: Optional[str] = None)) -> None:
    """Update progress (no-op)."""

def finish((self, message: Optional[str] = None)) -> None:
    """Finish progress tracking (no-op)."""

def __init__((self, log_level: int = logging.INFO)):
    """Initialize the progress reporter."""

def start((self, total: int, description: str = "")) -> None:
    """Start progress tracking."""

def update((self, amount: int = 1, message: Optional[str] = None)) -> None:
    """Update progress. ..."""

def finish((self, message: Optional[str] = None)) -> None:
    """Finish progress tracking."""

def __init__((
        self,
        on_start: Optional[Callable[[int, str], None]] = None,
        on_update: Optional[Callable[[int, int, Optional[str]], None]] = None,
        on_finish: Optional[Callable[[Optional[str]], None]] = None,
    )):
    """Initialize the progress reporter with callbacks."""

def start((self, total: int, description: str = "")) -> None:
    """Start progress tracking."""

def update((self, amount: int = 1, message: Optional[str] = None)) -> None:
    """Update progress. ..."""

def finish((self, message: Optional[str] = None)) -> None:
    """Finish progress tracking."""


# File: /Users/adam/Developer/vcs/github.twardoch/pub/pedalboard-pluginary/src/pedalboard_pluginary/protocols.py
# Language: python

from typing import Protocol, Optional, Dict, runtime_checkable
from .models import PluginInfo

class ProgressReporter(P, r, o, t, o, c, o, l):
    """Protocol for progress reporting implementations."""
    def start((self, total: int, description: str = "")) -> None:
        """Start progress tracking."""
    def update((self, amount: int = 1, message: Optional[str] = None)) -> None:
        """Update progress. ..."""
    def finish((self, message: Optional[str] = None)) -> None:
        """Finish progress tracking."""

class CacheBackend(P, r, o, t, o, c, o, l):
    """Protocol for cache backend implementations."""
    def load((self)) -> Dict[str, PluginInfo]:
        """Load all cached plugins."""
    def save((self, plugins: Dict[str, PluginInfo])) -> None:
        """Save plugins to cache."""
    def update((self, plugin_id: str, plugin: PluginInfo)) -> None:
        """Update a single plugin in cache."""
    def delete((self, plugin_id: str)) -> None:
        """Remove a plugin from cache."""
    def clear((self)) -> None:
        """Clear entire cache."""
    def exists((self)) -> bool:
        """Check if cache exists."""

def start((self, total: int, description: str = "")) -> None:
    """Start progress tracking."""

def update((self, amount: int = 1, message: Optional[str] = None)) -> None:
    """Update progress. ..."""

def finish((self, message: Optional[str] = None)) -> None:
    """Finish progress tracking."""

def load((self)) -> Dict[str, PluginInfo]:
    """Load all cached plugins."""

def save((self, plugins: Dict[str, PluginInfo])) -> None:
    """Save plugins to cache."""

def update((self, plugin_id: str, plugin: PluginInfo)) -> None:
    """Update a single plugin in cache."""

def delete((self, plugin_id: str)) -> None:
    """Remove a plugin from cache."""

def clear((self)) -> None:
    """Clear entire cache."""

def exists((self)) -> bool:
    """Check if cache exists."""


<document index="25">
<source>src/pedalboard_pluginary/resources/default_ignores.json</source>
<document_content>
[
    "aufx/ANIMATE",
    "aufx/AudioDSP",
    "aufx/CoreAudio",
    "aufx/Dynamics",
... (file content truncated to first 5 lines)
</document_content>
</document>

# File: /Users/adam/Developer/vcs/github.twardoch/pub/pedalboard-pluginary/src/pedalboard_pluginary/retry.py
# Language: python

import functools
import logging
import time
from typing import Any, Callable, Optional, Tuple, Type, TypeVar, Union
from .constants import MAX_SCAN_RETRIES, SCAN_RETRY_DELAY

def with_retry((
    exceptions: Union[Type[Exception], Tuple[Type[Exception], ...]],
    max_attempts: int = MAX_SCAN_RETRIES,
    delay: float = SCAN_RETRY_DELAY,
    backoff_factor: float = 2.0,
    max_delay: float = 60.0,
)) -> Callable[[F], F]:
    """Decorator that retries a function on specified exceptions."""

def decorator((func: F)) -> F:

def wrapper((*args: Any, **kwargs: Any)) -> Any:


# File: /Users/adam/Developer/vcs/github.twardoch/pub/pedalboard-pluginary/src/pedalboard_pluginary/scan_single.py
# Language: python

import argparse
import sys
import os
import warnings
import io
from pathlib import Path
from pedalboard_pluginary.scanner_isolated import ScanJournal
import pedalboard

def scan_single_plugin((
    plugin_path: str,
    plugin_name: str,
    plugin_type: str,
    journal_path: str,
)):
    """Scan a single plugin and write the result to the journal."""

def main(()):
    """Main entry point."""


# File: /Users/adam/Developer/vcs/github.twardoch/pub/pedalboard-pluginary/src/pedalboard_pluginary/scanner_clean.py
# Language: python

import os
import sys
from contextlib import contextmanager

def suppress_all_output(()):
    """Aggressively suppress all output including OS-level stderr."""

def clean_scan((scanner_class, *args, **kwargs)):
    """Run scanner with all output suppressed."""


# File: /Users/adam/Developer/vcs/github.twardoch/pub/pedalboard-pluginary/src/pedalboard_pluginary/scanner_isolated.py
# Language: python

import logging
import multiprocessing as mp
import os
import platform
import re
import sqlite3
import subprocess
import sys
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from pathlib import Path
from typing import Any, List, Literal, Optional, Tuple
from urllib.parse import unquote, urlparse
from rich.console import Console
from rich.progress import (
    BarColumn,
    MofNCompleteColumn,
    Progress,
    SpinnerColumn,
    TextColumn,
    TimeRemainingColumn,
)
from .cache.sqlite_backend import SQLiteCacheBackend
from .data import (
    copy_default_ignores,
    get_cache_path,
    load_ignores,
)
from .serialization import deserialize_plugin_info, serialize_plugin_info
from .utils import ensure_folder
import time

class JournalEntry:
    """Represents a single entry in the scan journal."""

class ScanJournal:
    """ Manages a SQLite-based journal for resumable, transactional plugin scanning...."""
    def __init__((self, journal_path: Path)):
    def _get_connection((self)) -> sqlite3.Connection:
        """Gets the database connection, creating if needed."""
    def _ensure_schema_for_connection((self, conn)):
        """Ensure the schema exists for a given connection."""
    def _create_schema((self)):
        """Creates the necessary tables and indexes if they don't exist."""
    def add_pending((self, plugin_paths: set[PluginId])):
        """ Adds a list of plugin paths to the journal with 'pending' status,..."""
    def get_pending_plugins((self)) -> set[PluginId]:
        """Returns a set of all plugin paths marked as 'pending'."""
    def update_status((
        self,
        plugin_id: PluginId,
        status: ScanStatus,
        result: dict[str, Any] | None = None,
    )):
        """Updates the status and result of a single plugin in the journal."""
    def get_all_successful((self)) -> list[JournalEntry]:
        """Retrieves all successful scan entries from the journal."""
    def get_summary((self)) -> dict[ScanStatus, int]:
        """Returns a summary of plugin counts for each status."""
    def delete_journal((self)):
        """Deletes the journal file."""
    def close((self)):
        """Closes the database connection."""

class IsolatedPedalboardScanner:
    """Scanner with complete process isolation and resumable journaling."""
    def __init__((self, max_workers: Optional[int] = None, timeout: int = 30, verbose: bool = False, cache_backend: Optional[Any] = None, journal_path: Optional[Path] = None)):
    def ensure_ignores((self)):
    def _list_aufx_plugins((self)) -> List[str]:
    def _find_plugins_to_scan((
        self,
        extra_folders: Optional[List[str]] = None,
    )) -> set[tuple[str, str, str]]:
        """Find all VST3 and AU plugins and return a set of (path, name, type)."""
    def scan((self, extra_folders: Optional[List[str]] = None, rescan: bool = False)):
        """Scan all plugins with journaling and process isolation."""
    def _execute_scan((self, tasks: List[Tuple[str, str, str]])):
        """Execute the scan using a ThreadPoolExecutor."""
    def _commit_journal((self)):
        """Commit successful results from the journal to the main cache."""
    def _get_vst3_folders((self, extra_folders=None)) -> List[Path]:

def __init__((self, journal_path: Path)):

def _get_connection((self)) -> sqlite3.Connection:
    """Gets the database connection, creating if needed."""

def _ensure_schema_for_connection((self, conn)):
    """Ensure the schema exists for a given connection."""

def _create_schema((self)):
    """Creates the necessary tables and indexes if they don't exist."""

def add_pending((self, plugin_paths: set[PluginId])):
    """ Adds a list of plugin paths to the journal with 'pending' status,..."""

def get_pending_plugins((self)) -> set[PluginId]:
    """Returns a set of all plugin paths marked as 'pending'."""

def update_status((
        self,
        plugin_id: PluginId,
        status: ScanStatus,
        result: dict[str, Any] | None = None,
    )):
    """Updates the status and result of a single plugin in the journal."""

def get_all_successful((self)) -> list[JournalEntry]:
    """Retrieves all successful scan entries from the journal."""

def get_summary((self)) -> dict[ScanStatus, int]:
    """Returns a summary of plugin counts for each status."""

def delete_journal((self)):
    """Deletes the journal file."""

def close((self)):
    """Closes the database connection."""

def run_scan_single((
    plugin_path: str,
    plugin_name: str,
    plugin_type: str,
    journal_path: str,
    timeout: int,
    verbose: bool,
)) -> None:
    """Wrapper to run scan_single.py in a subprocess."""

def __init__((self, max_workers: Optional[int] = None, timeout: int = 30, verbose: bool = False, cache_backend: Optional[Any] = None, journal_path: Optional[Path] = None)):

def ensure_ignores((self)):

def _list_aufx_plugins((self)) -> List[str]:

def _find_plugins_to_scan((
        self,
        extra_folders: Optional[List[str]] = None,
    )) -> set[tuple[str, str, str]]:
    """Find all VST3 and AU plugins and return a set of (path, name, type)."""

def scan((self, extra_folders: Optional[List[str]] = None, rescan: bool = False)):
    """Scan all plugins with journaling and process isolation."""

def _execute_scan((self, tasks: List[Tuple[str, str, str]])):
    """Execute the scan using a ThreadPoolExecutor."""

def _commit_journal((self)):
    """Commit successful results from the journal to the main cache."""

def _get_vst3_folders((self, extra_folders=None)) -> List[Path]:


# File: /Users/adam/Developer/vcs/github.twardoch/pub/pedalboard-pluginary/src/pedalboard_pluginary/serialization.py
# Language: python

import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, Optional
from .constants import APP_VERSION, CACHE_VERSION
from .exceptions import CacheCorruptedError, CacheVersionError, CacheWriteError
from .models import PluginInfo, PluginParameter
from .types import (
    CacheData,
    CacheMetadata,
    SerializedParameter,
    SerializedPlugin,
    is_serialized_parameter,
    is_serialized_plugin,
)
from .utils import ensure_folder

class PluginSerializer:
    """Handles serialization and deserialization of plugin data."""

def serialize_plugin_info((data: dict[str, Any])) -> str:
    """Serializes plugin data to a JSON string."""

def deserialize_plugin_info((json_str: str)) -> dict[str, Any]:
    """Deserializes a JSON string to plugin data."""

def parameter_to_dict((param: PluginParameter)) -> SerializedParameter:
    """Convert PluginParameter to serializable dictionary."""

def dict_to_parameter((data: Dict[str, Any])) -> Optional[PluginParameter]:
    """Convert dictionary to PluginParameter with validation."""

def plugin_to_dict((plugin: PluginInfo)) -> SerializedPlugin:
    """Convert PluginInfo to serializable dictionary."""

def dict_to_plugin((data: Dict[str, Any])) -> Optional[PluginInfo]:
    """Convert dictionary to PluginInfo with validation."""

def create_cache_metadata((cls, plugin_count: int)) -> CacheMetadata:
    """Create cache metadata."""

def save_plugins((cls, plugins: Dict[str, PluginInfo], path: Path)) -> None:
    """Save plugins to JSON file with metadata and error handling."""

def load_plugins((cls, path: Path)) -> Dict[str, PluginInfo]:
    """Load plugins from JSON file with validation."""

def migrate_cache((cls, old_data: Dict[str, Any], old_version: str, new_version: str)) -> Dict[str, Any]:
    """Migrate cache data from old version to new version."""


# File: /Users/adam/Developer/vcs/github.twardoch/pub/pedalboard-pluginary/src/pedalboard_pluginary/timeout.py
# Language: python

import asyncio
import concurrent.futures
import functools
import logging
from typing import Any, Awaitable, Callable, TypeVar
from .constants import PLUGIN_LOAD_TIMEOUT

class TimeoutError(E, x, c, e, p, t, i, o, n):
    """Raised when an operation times out."""
    def __init__((self, message: str, timeout: float)):

def __init__((self, message: str, timeout: float)):

def sync_timeout((func: Callable[..., T], timeout: float, *args: Any, **kwargs: Any)) -> T:
    """Execute synchronous function with timeout using ThreadPoolExecutor."""

def async_timeout((coro_func: Callable[..., Awaitable[T]], timeout: float, *args: Any, **kwargs: Any)) -> T:
    """Execute coroutine function with timeout."""

def with_sync_timeout((timeout: float = PLUGIN_LOAD_TIMEOUT)) -> Callable[[F], F]:
    """Decorator that adds timeout to synchronous functions."""

def decorator((func: F)) -> F:

def wrapper((*args: Any, **kwargs: Any)) -> Any:

def with_async_timeout((timeout: float = PLUGIN_LOAD_TIMEOUT)) -> Callable[[F], F]:
    """Decorator that adds timeout to async functions."""

def decorator((func: F)) -> F:

def async_wrapper((*args: Any, **kwargs: Any)) -> Any:


# File: /Users/adam/Developer/vcs/github.twardoch/pub/pedalboard-pluginary/src/pedalboard_pluginary/types.py
# Language: python

import sys
from typing import Union, Dict, Any, TypedDict, Optional
from typing import NotRequired
from typing_extensions import NotRequired

class SerializedParameter(T, y, p, e, d, D, i, c, t):
    """TypedDict for serialized plugin parameter."""

class SerializedPlugin(T, y, p, e, d, D, i, c, t):
    """TypedDict for serialized plugin data."""

class CacheMetadata(T, y, p, e, d, D, i, c, t):
    """TypedDict for cache metadata."""

class CacheData(T, y, p, e, d, D, i, c, t):
    """TypedDict for complete cache data structure."""

def is_parameter_value((value: Any)) -> bool:
    """Check if a value is a valid ParameterValue."""

def is_serialized_parameter((data: Any)) -> bool:
    """Check if data is a valid SerializedParameter."""

def is_serialized_plugin((data: Any)) -> bool:
    """Check if data is a valid SerializedPlugin."""


# File: /Users/adam/Developer/vcs/github.twardoch/pub/pedalboard-pluginary/src/pedalboard_pluginary/utils.py
# Language: python

def ensure_folder((path)):
    """Ensure that a folder exists. If path is a file, ensure its parent directory exists."""

def from_pb_param((data)):


# File: /Users/adam/Developer/vcs/github.twardoch/pub/pedalboard-pluginary/tests/scanners/__init__.py
# Language: python



# File: /Users/adam/Developer/vcs/github.twardoch/pub/pedalboard-pluginary/tests/scanners/test_au_scanner.py
# Language: python

import pytest
from pathlib import Path
from unittest.mock import patch, MagicMock
from pedalboard_pluginary.scanners.au_scanner import AUScanner

class TestAUScanner:

def au_scanner_instance(()):

def au_scanner_with_ignores_instance(()):

def test_list_aufx_plugins_raw_success((self, mock_subprocess_run, au_scanner_instance)):

def test_list_aufx_plugins_raw_auval_not_found((self, mock_subprocess_run, au_scanner_instance)):

def test_find_plugin_files_valid_output((self, mock_subprocess_run, au_scanner_instance)):

def side_effect_resolve((*args, **kwargs)):

def test_find_plugin_files_with_ignores((self, mock_subprocess_run, au_scanner_with_ignores_instance)):

def test_find_plugin_files_garbage_url((self, mock_subprocess_run, au_scanner_instance)):

def test_scanner_on_non_macos((self, mock_platform_system_linux, au_scanner_instance)):

def test_find_plugin_files_with_specific_paths_filter((self, mock_subprocess_run, au_scanner_instance)):

def test_bundle_path_resolution((self, mock_subprocess_run, au_scanner_instance)):


# File: /Users/adam/Developer/vcs/github.twardoch/pub/pedalboard-pluginary/tests/scanners/test_vst3_scanner.py
# Language: python

import os
from pathlib import Path
from unittest.mock import patch
import pytest
from pedalboard_pluginary.scanners.vst3_scanner import VST3Scanner

class TestVST3Scanner:
    def test_find_plugin_files_discovery((self, vst3_scanner_instance, tmp_path)):
    def test_find_plugin_files_with_extra_folders((
        self, vst3_scanner_instance, tmp_path
    )):
    def test_find_plugin_files_with_specific_paths((
        self, vst3_scanner_instance, tmp_path
    )):
    def test_find_plugin_files_with_ignores((
        self, vst3_scanner_with_ignores_instance, tmp_path
    )):
    def test_find_plugin_files_no_folders_exist((self, vst3_scanner_instance)):
    def test_find_plugin_files_skips_directories_with_vst3_suffix((
        self, vst3_scanner_instance, tmp_path
    )):

def create_dummy_vst3_structure((tmp_path, structure)):
    """ Creates a dummy VST3 plugin directory structure...."""

def vst3_scanner_instance(()):

def vst3_scanner_with_ignores_instance(()):

def test_get_default_vst3_folders_windows((
        self, mock_platform_system, vst3_scanner_instance, tmp_path
    )):

def mock_getenv_windows((var_name, default=None)):

def test_get_default_vst3_folders_macos((
        self, mock_platform_system, vst3_scanner_instance, tmp_path
    )):

def mocked_path_init((self, *args, **kwargs)):

def test_get_default_vst3_folders_linux((
        self, mock_platform_system, vst3_scanner_instance, tmp_path
    )):

def mocked_path_init((self, *args, **kwargs)):

def test_find_plugin_files_discovery((self, vst3_scanner_instance, tmp_path)):

def test_find_plugin_files_with_extra_folders((
        self, vst3_scanner_instance, tmp_path
    )):

def test_find_plugin_files_with_specific_paths((
        self, vst3_scanner_instance, tmp_path
    )):

def test_find_plugin_files_with_ignores((
        self, vst3_scanner_with_ignores_instance, tmp_path
    )):

def test_find_plugin_files_no_folders_exist((self, vst3_scanner_instance)):

def test_find_plugin_files_skips_directories_with_vst3_suffix((
        self, vst3_scanner_instance, tmp_path
    )):


# File: /Users/adam/Developer/vcs/github.twardoch/pub/pedalboard-pluginary/tests/test_core.py
# Language: python

import pytest
from unittest.mock import Mock, patch
import json
from pedalboard_pluginary.core import PedalboardPluginary
from pedalboard_pluginary.models import PluginInfo, PluginParameter
from pedalboard_pluginary.exceptions import PluginaryError

class TestPedalboardPluginary:
    """Test suite for PedalboardPluginary core class."""
    def test_init_default((self)):
        """Test PedalboardPluginary initialization with default parameters."""
    def test_init_custom_scanner((self)):
        """Test PedalboardPluginary initialization with custom scanner."""
    def test_full_scan_delegates_to_scanner((self)):
        """Test that full_scan delegates to scanner."""
    def test_update_scan_delegates_to_scanner((self)):
        """Test that update_scan delegates to scanner."""
    def test_get_plugin_existing((self)):
        """Test getting an existing plugin."""
    def test_get_plugin_non_existing((self)):
        """Test getting a non-existing plugin."""
    def test_list_plugins_empty((self)):
        """Test listing plugins when none exist."""
    def test_list_plugins_with_filter((self)):
        """Test listing plugins with type filter."""
    def test_list_plugins_with_manufacturer_filter((self)):
        """Test listing plugins with manufacturer filter."""
    def test_plugin_count((self)):
        """Test getting plugin count."""

def test_init_default((self)):
    """Test PedalboardPluginary initialization with default parameters."""

def test_init_custom_scanner((self)):
    """Test PedalboardPluginary initialization with custom scanner."""

def test_load_data_called_on_init((self, mock_load_data)):
    """Test that load_data is called during initialization."""

def test_load_data_success((self, mock_load_json)):
    """Test successful loading of plugin data."""

def test_load_data_file_not_found((self, mock_load_json)):
    """Test handling of missing cache file."""

def test_load_data_invalid_json((self, mock_load_json)):
    """Test handling of invalid JSON in cache file."""

def test_full_scan_delegates_to_scanner((self)):
    """Test that full_scan delegates to scanner."""

def test_update_scan_delegates_to_scanner((self)):
    """Test that update_scan delegates to scanner."""

def test_get_plugin_existing((self)):
    """Test getting an existing plugin."""

def test_get_plugin_non_existing((self)):
    """Test getting a non-existing plugin."""

def test_list_plugins_empty((self)):
    """Test listing plugins when none exist."""

def test_list_plugins_with_filter((self)):
    """Test listing plugins with type filter."""

def test_list_plugins_with_manufacturer_filter((self)):
    """Test listing plugins with manufacturer filter."""

def test_plugin_count((self)):
    """Test getting plugin count."""


# File: /Users/adam/Developer/vcs/github.twardoch/pub/pedalboard-pluginary/tests/test_data.py
# Language: python

import os
from unittest.mock import patch
from pedalboard_pluginary.data import get_cache_path

def test_get_cache_path_windows(()):

def test_get_cache_path_macos((mock_platform_system)):

def test_get_cache_path_linux_xdg_set((mock_platform_system)):

def test_get_cache_path_linux_xdg_not_set((mock_platform_system)):


# File: /Users/adam/Developer/vcs/github.twardoch/pub/pedalboard-pluginary/tests/test_exceptions.py
# Language: python

import pytest
from pedalboard_pluginary.exceptions import (
    PluginaryError,
    ScannerError,
    CacheError,
    PluginLoadError,
    TimeoutError,
    ConfigError
)

class TestPluginaryExceptions:
    """Test suite for custom exceptions."""
    def test_pluginary_error_basic((self)):
        """Test basic PluginaryError."""
    def test_pluginary_error_with_cause((self)):
        """Test PluginaryError with cause."""
    def test_scanner_error_inheritance((self)):
        """Test ScannerError inherits from PluginaryError."""
    def test_cache_error_inheritance((self)):
        """Test CacheError inherits from PluginaryError."""
    def test_plugin_load_error_inheritance((self)):
        """Test PluginLoadError inherits from ScannerError."""
    def test_timeout_error_inheritance((self)):
        """Test TimeoutError inherits from PluginaryError."""
    def test_config_error_inheritance((self)):
        """Test ConfigError inherits from PluginaryError."""
    def test_exception_with_details((self)):
        """Test exceptions with additional details."""
    def test_exception_chaining((self)):
        """Test exception chaining."""
    def test_multiple_error_types((self)):
        """Test creating multiple different error types."""
    def test_error_with_plugin_context((self)):
        """Test error with plugin context information."""
    def test_cache_error_scenarios((self)):
        """Test various cache error scenarios."""
    def test_timeout_error_with_duration((self)):
        """Test timeout error with duration information."""
    def test_scanner_error_with_scanner_type((self)):
        """Test scanner error with scanner type information."""

def test_pluginary_error_basic((self)):
    """Test basic PluginaryError."""

def test_pluginary_error_with_cause((self)):
    """Test PluginaryError with cause."""

def test_scanner_error_inheritance((self)):
    """Test ScannerError inherits from PluginaryError."""

def test_cache_error_inheritance((self)):
    """Test CacheError inherits from PluginaryError."""

def test_plugin_load_error_inheritance((self)):
    """Test PluginLoadError inherits from ScannerError."""

def test_timeout_error_inheritance((self)):
    """Test TimeoutError inherits from PluginaryError."""

def test_config_error_inheritance((self)):
    """Test ConfigError inherits from PluginaryError."""

def test_exception_with_details((self)):
    """Test exceptions with additional details."""

def test_exception_chaining((self)):
    """Test exception chaining."""

def test_multiple_error_types((self)):
    """Test creating multiple different error types."""

def test_error_with_plugin_context((self)):
    """Test error with plugin context information."""

def test_cache_error_scenarios((self)):
    """Test various cache error scenarios."""

def test_timeout_error_with_duration((self)):
    """Test timeout error with duration information."""

def test_scanner_error_with_scanner_type((self)):
    """Test scanner error with scanner type information."""


# File: /Users/adam/Developer/vcs/github.twardoch/pub/pedalboard-pluginary/tests/test_failsafe_integration.py
# Language: python

import subprocess
import sys
import threading
import time
from pathlib import Path
from unittest.mock import MagicMock, patch
import pytest
from pedalboard_pluginary.scanner_isolated import IsolatedPedalboardScanner, ScanJournal, run_scan_single
from pedalboard_pluginary.cache.sqlite_backend import SQLiteCacheBackend

class TestWorkerProcessCrash:
    """Test scenarios where worker processes crash during scanning."""
    def test_worker_crash_simulation((self, test_cache_dir, mock_plugin_discovery)):
        """Simulate a worker process crashing mid-scan."""
    def test_worker_timeout((self, test_cache_dir, mock_plugin_discovery)):
        """Test worker timeout handling."""

class TestMainProcessCrash:
    """Test scenarios where the main scanner process crashes."""
    def test_main_process_crash_and_resume((self, test_cache_dir, mock_plugin_discovery)):
        """Simulate main process crash and verify resume functionality."""

class TestCommitPhaseCrash:
    """Test scenarios where crashes occur during the commit phase."""
    def test_crash_during_commit((self, test_cache_dir, mock_plugin_discovery)):
        """Simulate a crash during the commit phase."""
    def test_atomic_commit_protection((self, test_cache_dir, mock_plugin_discovery)):
        """Test that main cache remains untouched if commit fails."""

class TestEdgeCases:
    """Test edge cases and boundary conditions."""
    def test_empty_journal((self, test_cache_dir)):
        """Test behavior with an empty journal."""
    def test_all_failed_journal((self, test_cache_dir, mock_plugin_discovery)):
        """Test journal with all plugins failed."""
    def test_mixed_status_journal((self, test_cache_dir, mock_plugin_discovery)):
        """Test journal with mixed success/failure/timeout statuses."""
    def test_concurrent_journal_access((self, test_cache_dir)):
        """Test concurrent access to journal from multiple threads."""

class TestRealProcessCrash:
    """Test with actual subprocess crashes (not just mocked)."""

def test_cache_dir((tmp_path: Path)) -> Path:
    """Create a temporary cache directory."""

def mock_plugin_discovery(()):
    """Mock plugin discovery to return test plugins."""

def mock_find_plugins((self, extra_folders=None)):

def test_worker_crash_simulation((self, test_cache_dir, mock_plugin_discovery)):
    """Simulate a worker process crashing mid-scan."""

def mock_run_scan_single_crash((plugin_path, plugin_name, plugin_type, 
                                           journal_path_str, timeout, verbose)):

def test_worker_timeout((self, test_cache_dir, mock_plugin_discovery)):
    """Test worker timeout handling."""

def mock_run_scan_single_timeout((plugin_path, plugin_name, plugin_type,
                                            journal_path_str, timeout, verbose)):

def test_main_process_crash_and_resume((self, test_cache_dir, mock_plugin_discovery)):
    """Simulate main process crash and verify resume functionality."""

def mock_run_scan_single_partial((plugin_path, plugin_name, plugin_type,
                                            journal_path_str, timeout, verbose)):

def mock_run_scan_single_resume((plugin_path, plugin_name, plugin_type,
                                           journal_path_str, timeout, verbose)):

def test_crash_during_commit((self, test_cache_dir, mock_plugin_discovery)):
    """Simulate a crash during the commit phase."""

def mock_run_scan_single_success((plugin_path, plugin_name, plugin_type,
                                            journal_path_str, timeout, verbose)):

def test_atomic_commit_protection((self, test_cache_dir, mock_plugin_discovery)):
    """Test that main cache remains untouched if commit fails."""

def mock_run_scan_single_success((plugin_path, plugin_name, plugin_type,
                                            journal_path_str, timeout, verbose)):

def test_empty_journal((self, test_cache_dir)):
    """Test behavior with an empty journal."""

def test_all_failed_journal((self, test_cache_dir, mock_plugin_discovery)):
    """Test journal with all plugins failed."""

def mock_run_scan_single_fail((plugin_path, plugin_name, plugin_type,
                                         journal_path_str, timeout, verbose)):

def test_mixed_status_journal((self, test_cache_dir, mock_plugin_discovery)):
    """Test journal with mixed success/failure/timeout statuses."""

def mock_run_scan_single_mixed((plugin_path, plugin_name, plugin_type,
                                          journal_path_str, timeout, verbose)):

def test_concurrent_journal_access((self, test_cache_dir)):
    """Test concurrent access to journal from multiple threads."""

def worker_thread((thread_id: int, plugin_ids: list)):

def test_real_subprocess_kill((self, test_cache_dir, tmp_path)):
    """Test killing an actual subprocess during scanning."""


# File: /Users/adam/Developer/vcs/github.twardoch/pub/pedalboard-pluginary/tests/test_journal.py
# Language: python

import sqlite3
from pathlib import Path
from unittest.mock import MagicMock, patch
import pytest
from pedalboard_pluginary.scanner_isolated import IsolatedPedalboardScanner, ScanJournal

def journal_path((tmp_path: Path)) -> Path:

def journal((journal_path: Path)) -> ScanJournal:

def test_journal_creation((journal: ScanJournal, journal_path: Path)):

def test_add_and_get_pending((journal: ScanJournal)):

def test_update_status((journal: ScanJournal)):

def test_get_summary((journal: ScanJournal)):

def test_scan_resume((mock_run_scan_single, tmp_path: Path)):
    """Simulate a crash and resume a scan."""

def side_effect_crash((*args, **kwargs)):


# File: /Users/adam/Developer/vcs/github.twardoch/pub/pedalboard-pluginary/tests/test_models.py
# Language: python

import pytest
from pedalboard_pluginary.models import PluginInfo, PluginParameter

class TestPluginParameter:
    """Test suite for PluginParameter model."""
    def test_init_basic((self)):
        """Test basic PluginParameter initialization."""
    def test_init_with_optional_fields((self)):
        """Test PluginParameter initialization with optional fields."""
    def test_equality((self)):
        """Test PluginParameter equality."""
    def test_str_representation((self)):
        """Test string representation of PluginParameter."""

class TestPluginInfo:
    """Test suite for PluginInfo model."""
    def test_init_basic((self)):
        """Test basic PluginInfo initialization."""
    def test_init_with_parameters((self)):
        """Test PluginInfo initialization with parameters."""
    def test_init_minimal((self)):
        """Test PluginInfo initialization with minimal required fields."""
    def test_equality((self)):
        """Test PluginInfo equality."""
    def test_str_representation((self)):
        """Test string representation of PluginInfo."""
    def test_parameter_count((self)):
        """Test getting parameter count."""
    def test_au_plugin_type((self)):
        """Test PluginInfo with AU plugin type."""
    def test_vst3_plugin_type((self)):
        """Test PluginInfo with VST3 plugin type."""

def test_init_basic((self)):
    """Test basic PluginParameter initialization."""

def test_init_with_optional_fields((self)):
    """Test PluginParameter initialization with optional fields."""

def test_equality((self)):
    """Test PluginParameter equality."""

def test_str_representation((self)):
    """Test string representation of PluginParameter."""

def test_init_basic((self)):
    """Test basic PluginInfo initialization."""

def test_init_with_parameters((self)):
    """Test PluginInfo initialization with parameters."""

def test_init_minimal((self)):
    """Test PluginInfo initialization with minimal required fields."""

def test_equality((self)):
    """Test PluginInfo equality."""

def test_str_representation((self)):
    """Test string representation of PluginInfo."""

def test_parameter_count((self)):
    """Test getting parameter count."""

def test_au_plugin_type((self)):
    """Test PluginInfo with AU plugin type."""

def test_vst3_plugin_type((self)):
    """Test PluginInfo with VST3 plugin type."""


# File: /Users/adam/Developer/vcs/github.twardoch/pub/pedalboard-pluginary/tests/test_serialization.py
# Language: python

import pytest
from pedalboard_pluginary.serialization import PluginSerializer
from pedalboard_pluginary.models import PluginInfo, PluginParameter

class TestPluginSerializer:
    """Test suite for PluginSerializer."""
    def test_serialize_plugin_parameter((self)):
        """Test serializing a PluginParameter."""
    def test_serialize_plugin_parameter_minimal((self)):
        """Test serializing a minimal PluginParameter."""
    def test_deserialize_plugin_parameter((self)):
        """Test deserializing a PluginParameter."""
    def test_deserialize_plugin_parameter_minimal((self)):
        """Test deserializing a minimal PluginParameter."""
    def test_serialize_plugin_info((self)):
        """Test serializing a PluginInfo."""
    def test_deserialize_plugin_info((self)):
        """Test deserializing a PluginInfo."""
    def test_serialize_plugins_dict((self)):
        """Test serializing a dictionary of plugins."""
    def test_deserialize_plugins_dict((self)):
        """Test deserializing a dictionary of plugins."""
    def test_round_trip_serialization((self)):
        """Test round-trip serialization/deserialization."""

def test_serialize_plugin_parameter((self)):
    """Test serializing a PluginParameter."""

def test_serialize_plugin_parameter_minimal((self)):
    """Test serializing a minimal PluginParameter."""

def test_deserialize_plugin_parameter((self)):
    """Test deserializing a PluginParameter."""

def test_deserialize_plugin_parameter_minimal((self)):
    """Test deserializing a minimal PluginParameter."""

def test_serialize_plugin_info((self)):
    """Test serializing a PluginInfo."""

def test_deserialize_plugin_info((self)):
    """Test deserializing a PluginInfo."""

def test_serialize_plugins_dict((self)):
    """Test serializing a dictionary of plugins."""

def test_deserialize_plugins_dict((self)):
    """Test deserializing a dictionary of plugins."""

def test_round_trip_serialization((self)):
    """Test round-trip serialization/deserialization."""


# File: /Users/adam/Developer/vcs/github.twardoch/pub/pedalboard-pluginary/tests/test_sqlite_performance.py
# Language: python

import time
import tempfile
import pytest
from pathlib import Path
from typing import Dict
from pedalboard_pluginary.cache.sqlite_backend import SQLiteCacheBackend
from pedalboard_pluginary.cache.json_backend import JSONCacheBackend
from pedalboard_pluginary.models import PluginInfo, PluginParameter
import psutil
import os

class TestSQLitePerformance:
    """Performance tests comparing SQLite vs JSON backends."""
    def test_sqlite_save_performance((self, sqlite_backend, medium_dataset)):
        """Test SQLite save performance."""
    def test_json_save_performance((self, json_backend, medium_dataset)):
        """Test JSON save performance."""
    def test_sqlite_load_performance((self, sqlite_backend, medium_dataset)):
        """Test SQLite load performance."""
    def test_json_load_performance((self, json_backend, medium_dataset)):
        """Test JSON load performance."""
    def test_sqlite_search_performance((self, sqlite_backend, medium_dataset)):
        """Test SQLite search performance."""
    def test_sqlite_filter_performance((self, sqlite_backend, medium_dataset)):
        """Test SQLite filter performance."""
    def test_sqlite_update_performance((self, sqlite_backend, small_dataset)):
        """Test SQLite update performance."""
    def test_scalability_comparison((self, sqlite_backend, json_backend, large_dataset)):
        """Compare scalability between SQLite and JSON backends."""
    def test_memory_efficiency((self, sqlite_backend, large_dataset)):
        """Test that SQLite backend is memory efficient."""

def create_test_plugin((plugin_id: str, name: str, manufacturer: str = "TestMfg")) -> PluginInfo:
    """Create a test plugin for benchmarking."""

def generate_test_plugins((count: int)) -> Dict[str, PluginInfo]:
    """Generate test plugins for benchmarking."""

def temp_dir((self)):
    """Create temporary directory for test files."""

def sqlite_backend((self, temp_dir)):
    """Create SQLite backend for testing."""

def json_backend((self, temp_dir)):
    """Create JSON backend for testing."""

def small_dataset((self)):
    """Small dataset for basic tests."""

def medium_dataset((self)):
    """Medium dataset for performance tests."""

def large_dataset((self)):
    """Large dataset for scalability tests."""

def test_sqlite_save_performance((self, sqlite_backend, medium_dataset)):
    """Test SQLite save performance."""

def test_json_save_performance((self, json_backend, medium_dataset)):
    """Test JSON save performance."""

def test_sqlite_load_performance((self, sqlite_backend, medium_dataset)):
    """Test SQLite load performance."""

def test_json_load_performance((self, json_backend, medium_dataset)):
    """Test JSON load performance."""

def test_sqlite_search_performance((self, sqlite_backend, medium_dataset)):
    """Test SQLite search performance."""

def test_sqlite_filter_performance((self, sqlite_backend, medium_dataset)):
    """Test SQLite filter performance."""

def test_sqlite_update_performance((self, sqlite_backend, small_dataset)):
    """Test SQLite update performance."""

def test_scalability_comparison((self, sqlite_backend, json_backend, large_dataset)):
    """Compare scalability between SQLite and JSON backends."""

def test_memory_efficiency((self, sqlite_backend, large_dataset)):
    """Test that SQLite backend is memory efficient."""


# File: /Users/adam/Developer/vcs/github.twardoch/pub/pedalboard-pluginary/tests/test_utils.py
# Language: python

from pedalboard_pluginary.utils import ensure_folder

def test_ensure_folder((tmp_path)):


</documents>