This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.github/
  workflows/
    ci.yml
src/
  pedalboard_pluginary/
    resources/
      default_ignores.json
    scanners/
      __init__.py
      au_scanner.py
      vst3_scanner.py
    __init__.py
    __main__.py
    base_scanner.py
    constants.py
    core.py
    data.py
    exceptions.py
    models.py
    progress.py
    protocols.py
    retry.py
    scanner.py
    serialization.py
    timeout.py
    types.py
    utils.py
  pedalboard-stubs/
    __init__.pyi
tests/
  scanners/
    __init__.py
    test_au_scanner.py
    test_vst3_scanner.py
  test_cli.py
  test_data.py
  test_utils.py
.coveragerc
.gitignore
.isort.cfg
.pre-commit-config.yaml
AUTHORS.md
build.sh
CHANGELOG.md
LICENSE.txt
PLAN.md
pyproject.toml
README.md
TODO.md
tox.ini
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="src/pedalboard_pluginary/timeout.py">
"""
Timeout handling for plugin operations.
"""

import asyncio
import concurrent.futures
import functools
import logging
from typing import Any, Awaitable, Callable, TypeVar, Union

from .constants import PLUGIN_LOAD_TIMEOUT

logger = logging.getLogger(__name__)

T = TypeVar('T')
F = TypeVar('F', bound=Callable[..., Any])


class TimeoutError(Exception):
    """Raised when an operation times out."""
    
    def __init__(self, message: str, timeout: float):
        super().__init__(message)
        self.timeout = timeout


def sync_timeout(func: Callable[..., T], timeout: float, *args: Any, **kwargs: Any) -> T:
    """Execute synchronous function with timeout using ThreadPoolExecutor.
    
    Args:
        func: Function to execute.
        timeout: Timeout in seconds.
        *args: Positional arguments for the function.
        **kwargs: Keyword arguments for the function.
        
    Returns:
        Function result.
        
    Raises:
        TimeoutError: If function execution exceeds timeout.
        Exception: Any exception raised by the function.
    """
    logger.debug(f"Executing {func.__name__} with {timeout}s timeout")
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
        future = executor.submit(func, *args, **kwargs)
        try:
            result = future.result(timeout=timeout)
            logger.debug(f"{func.__name__} completed successfully")
            return result
        except concurrent.futures.TimeoutError:
            logger.warning(f"{func.__name__} timed out after {timeout}s")
            # Cancel the future to prevent resource leaks
            future.cancel()
            raise TimeoutError(f"{func.__name__} timed out after {timeout}s", timeout)
        except Exception as e:
            logger.error(f"{func.__name__} failed: {e}")
            raise


async def async_timeout(coro_func: Callable[..., Awaitable[T]], timeout: float, *args: Any, **kwargs: Any) -> T:
    """Execute coroutine function with timeout.
    
    Args:
        coro_func: Coroutine function to execute.
        timeout: Timeout in seconds.
        *args: Positional arguments for the function.
        **kwargs: Keyword arguments for the function.
        
    Returns:
        Function result.
        
    Raises:
        TimeoutError: If function execution exceeds timeout.
        Exception: Any exception raised by the function.
    """
    logger.debug(f"Executing {coro_func.__name__} with {timeout}s timeout")
    
    try:
        result: T = await asyncio.wait_for(coro_func(*args, **kwargs), timeout=timeout)
        logger.debug(f"{coro_func.__name__} completed successfully")
        return result
    except asyncio.TimeoutError:
        logger.warning(f"{coro_func.__name__} timed out after {timeout}s")
        raise TimeoutError(f"{coro_func.__name__} timed out after {timeout}s", timeout)
    except Exception as e:
        logger.error(f"{coro_func.__name__} failed: {e}")
        raise


def with_sync_timeout(timeout: float = PLUGIN_LOAD_TIMEOUT) -> Callable[[F], F]:
    """Decorator that adds timeout to synchronous functions.
    
    Args:
        timeout: Timeout in seconds.
        
    Returns:
        Decorated function.
    """
    def decorator(func: F) -> F:
        @functools.wraps(func)
        def wrapper(*args: Any, **kwargs: Any) -> Any:
            return sync_timeout(func, timeout, *args, **kwargs)
        return wrapper  # type: ignore[return-value]
    return decorator


def with_async_timeout(timeout: float = PLUGIN_LOAD_TIMEOUT) -> Callable[[F], F]:
    """Decorator that adds timeout to async functions.
    
    Args:
        timeout: Timeout in seconds.
        
    Returns:
        Decorated function.
    """
    def decorator(func: F) -> F:
        @functools.wraps(func)
        async def async_wrapper(*args: Any, **kwargs: Any) -> Any:
            return await async_timeout(func, timeout, *args, **kwargs)
        return async_wrapper  # type: ignore[return-value]
    return decorator
</file>

<file path="src/pedalboard-stubs/__init__.pyi">
"""Type stubs for pedalboard library."""

from typing import Dict, Union, Any, Optional, TypeVar
from pathlib import Path

# Parameter value types that pedalboard can return
ParameterValue = Union[float, int, bool, str]

class Plugin:
    """Base plugin class."""
    
    # Core attributes that all plugins have
    parameters: Dict[str, ParameterValue]
    name: str
    manufacturer: Optional[str]
    
    def __init__(self, *args: Any, **kwargs: Any) -> None: ...

class AudioUnitPlugin(Plugin):
    """Audio Unit plugin class."""
    pass

class VST3Plugin(Plugin):
    """VST3 plugin class."""
    pass

# Plugin loading function
def load_plugin(
    path_or_name: Union[str, Path], 
    plugin_name: Optional[str] = None,
    disable_caching: bool = False,
    **kwargs: Any
) -> Plugin: ...

# Re-export common types
__all__ = [
    "Plugin",
    "AudioUnitPlugin", 
    "VST3Plugin",
    "load_plugin",
    "ParameterValue",
]
</file>

<file path="src/pedalboard_pluginary/resources/default_ignores.json">
[
    "aufx/ANIMATE",
    "aufx/AudioDSP",
    "aufx/CoreAudio",
    "aufx/Dynamics",
    "aufx/iZNectar4Auto-LevelAUHook",
    "aufx/iZNeutron4AUHook",
    "aufx/iZNeutron4CompressorAUHook",
    "aufx/iZNeutron4EqualizerAUHook",
    "aufx/iZNeutron4ExciterAUHook",
    "aufx/iZNeutron4GateAUHook",
    "aufx/iZNeutron4SculptorAUHook",
    "aufx/iZNeutron4TransientShaperAUHook",
    "aufx/iZNeutron4UnmaskAUHook",
    "aufx/iZRX10ConnectAUHook",
    "aufx/iZRelayAUHook",
    "aufx/smartEQ3",
    "aufx/smartcomp2",
    "aufx/smartgate",
    "aufx/unknown URL",
    "vst3/RX 10 Connect",
    "vst3/RX 10 Repair Assistant",
    "vst3/smartEQ3"
]
</file>

<file path="src/pedalboard_pluginary/scanners/__init__.py">
# pedalboard_pluginary/scanners/__init__.py

# This file makes Python treat the `scanners` directory as a package.

# Optionally, you can import specific classes or functions here to make them
# available at the package level, e.g.:
# from .au_scanner import AUScanner
# from .vst3_scanner import VST3Scanner

# For now, it will be kept empty.
</file>

<file path="src/pedalboard_pluginary/base_scanner.py">
"""
Base scanner class implementing common functionality for all plugin scanners.
"""

import logging
import re
from abc import ABC, abstractmethod
from pathlib import Path
from typing import List, Optional

from .models import PluginInfo
from .protocols import PluginScanner

logger = logging.getLogger(__name__)


class BaseScanner(ABC):
    """Base class for plugin scanner implementations."""
    
    def __init__(
        self,
        ignore_paths: Optional[List[str]] = None,
        specific_paths: Optional[List[str]] = None,
    ):
        """Initialize the scanner with optional ignore paths and specific paths.
        
        Args:
            ignore_paths: List of regex patterns for paths to ignore.
            specific_paths: List of specific paths to scan (if provided, only these are scanned).
        """
        self.ignore_paths = ignore_paths or []
        self.specific_paths = specific_paths or []
        self._compiled_ignore_patterns = [re.compile(pattern) for pattern in self.ignore_paths]
    
    @property
    @abstractmethod
    def plugin_type(self) -> str:
        """Return the plugin type this scanner handles (e.g., 'vst3', 'aufx')."""
        ...
    
    @property
    @abstractmethod
    def supported_extensions(self) -> List[str]:
        """Return list of file extensions this scanner supports."""
        ...
    
    @abstractmethod
    def find_plugin_files(self, paths: Optional[List[Path]] = None) -> List[Path]:
        """Find all plugin files of this scanner's type.
        
        Args:
            paths: Optional list of specific paths to check.
            
        Returns:
            List of paths to plugin files found.
        """
        ...
    
    @abstractmethod
    def scan_plugin(self, path: Path) -> Optional[PluginInfo]:
        """Scan a single plugin file and return its information.
        
        Args:
            path: Path to the plugin file to scan.
            
        Returns:
            PluginInfo object if successful, None if scanning failed.
        """
        ...
    
    def validate_plugin_path(self, path: Path) -> bool:
        """Validate if a path is a valid plugin for this scanner.
        
        Args:
            path: Path to validate.
            
        Returns:
            True if the path is a valid plugin file, False otherwise.
        """
        if not path.exists():
            return False
        
        # Check extension
        if path.suffix not in self.supported_extensions:
            return False
        
        # Check against ignore patterns
        if self._should_ignore_path(path):
            return False
        
        # Check if specific paths are set and this path is in them
        if self.specific_paths and str(path) not in self.specific_paths:
            return False
        
        return True
    
    def _should_ignore_path(self, path: Path) -> bool:
        """Check if a path should be ignored based on ignore patterns.
        
        Args:
            path: Path to check.
            
        Returns:
            True if the path should be ignored, False otherwise.
        """
        path_str = str(path)
        for pattern in self._compiled_ignore_patterns:
            if pattern.search(path_str):
                logger.debug(f"Ignoring path {path} due to pattern {pattern.pattern}")
                return True
        return False
    
    def _filter_plugin_paths(self, paths: List[Path]) -> List[Path]:
        """Filter plugin paths based on validation criteria.
        
        Args:
            paths: List of paths to filter.
            
        Returns:
            Filtered list of valid plugin paths.
        """
        valid_paths = []
        for path in paths:
            if self.validate_plugin_path(path):
                valid_paths.append(path)
            else:
                logger.debug(f"Filtered out invalid plugin path: {path}")
        
        return valid_paths
    
    def _create_plugin_id(self, path: Path) -> str:
        """Create a unique plugin ID from its path.
        
        Args:
            path: Path to the plugin.
            
        Returns:
            Unique plugin ID string.
        """
        return f"{self.plugin_type}/{path.stem}"
</file>

<file path="src/pedalboard_pluginary/constants.py">
"""
Constants and configuration values for pedalboard_pluginary.
"""

from typing import Final

# Application metadata
APP_NAME: Final[str] = "com.twardoch.pedalboard-pluginary"
APP_VERSION: Final[str] = "0.1.0"  # TODO: Get from package metadata

# Cache configuration
CACHE_VERSION: Final[str] = "2.0.0"
PLUGINS_CACHE_FILENAME: Final[str] = "plugins"
IGNORES_CACHE_FILENAME: Final[str] = "ignores"

# Scanner configuration
DEFAULT_SCAN_TIMEOUT: Final[int] = 10  # seconds
PLUGIN_LOAD_TIMEOUT: Final[float] = 10.0  # seconds for individual plugin loading
MAX_SCAN_RETRIES: Final[int] = 3
SCAN_RETRY_DELAY: Final[float] = 1.0  # seconds

# Plugin types
PLUGIN_TYPE_VST3: Final[str] = "vst3"
PLUGIN_TYPE_AU: Final[str] = "aufx"
SUPPORTED_PLUGIN_TYPES: Final[list[str]] = [PLUGIN_TYPE_VST3, PLUGIN_TYPE_AU]

# File extensions
VST3_EXTENSION: Final[str] = ".vst3"
AU_EXTENSION: Final[str] = ".component"

# Platform names
PLATFORM_WINDOWS: Final[str] = "Windows"
PLATFORM_MACOS: Final[str] = "Darwin"
PLATFORM_LINUX: Final[str] = "Linux"

# Progress reporting
DEFAULT_PROGRESS_BAR_WIDTH: Final[int] = 80
PROGRESS_UPDATE_INTERVAL: Final[float] = 0.1  # seconds

# Logging configuration
LOG_FORMAT: Final[str] = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
LOG_DATE_FORMAT: Final[str] = "%Y-%m-%d %H:%M:%S"

# CLI configuration
DEFAULT_OUTPUT_FORMAT: Final[str] = "json"
SUPPORTED_OUTPUT_FORMATS: Final[list[str]] = ["json", "yaml", "table", "csv"]

# Resource paths
RESOURCES_PACKAGE: Final[str] = "pedalboard_pluginary.resources"
DEFAULT_IGNORES_FILENAME: Final[str] = "default_ignores.json"
</file>

<file path="src/pedalboard_pluginary/exceptions.py">
"""
Custom exception hierarchy for pedalboard_pluginary.
"""

from typing import Optional


class PluginaryError(Exception):
    """Base exception for all Pluginary errors."""
    
    def __init__(self, message: str, details: Optional[str] = None):
        """Initialize the exception with a message and optional details.
        
        Args:
            message: Main error message.
            details: Optional additional details about the error.
        """
        super().__init__(message)
        self.message = message
        self.details = details
    
    def __str__(self) -> str:
        """Return string representation of the error."""
        if self.details:
            return f"{self.message} - {self.details}"
        return self.message


class ScannerError(PluginaryError):
    """Base exception for scanner-related errors."""
    pass


class PluginLoadError(ScannerError):
    """Raised when a plugin fails to load."""
    
    def __init__(self, plugin_path: str, reason: Optional[str] = None):
        """Initialize the exception.
        
        Args:
            plugin_path: Path to the plugin that failed to load.
            reason: Optional reason for the failure.
        """
        message = f"Failed to load plugin: {plugin_path}"
        super().__init__(message, reason)
        self.plugin_path = plugin_path


class PluginScanError(ScannerError):
    """Raised when scanning a plugin fails."""
    
    def __init__(self, plugin_path: str, scanner_type: str, reason: Optional[str] = None):
        """Initialize the exception.
        
        Args:
            plugin_path: Path to the plugin that failed to scan.
            scanner_type: Type of scanner that failed (e.g., 'vst3', 'aufx').
            reason: Optional reason for the failure.
        """
        message = f"Failed to scan {scanner_type} plugin: {plugin_path}"
        super().__init__(message, reason)
        self.plugin_path = plugin_path
        self.scanner_type = scanner_type


class CacheError(PluginaryError):
    """Base exception for cache-related errors."""
    pass


class CacheCorruptedError(CacheError):
    """Raised when cache file is corrupted."""
    
    def __init__(self, cache_path: str, reason: Optional[str] = None):
        """Initialize the exception.
        
        Args:
            cache_path: Path to the corrupted cache file.
            reason: Optional reason or details about the corruption.
        """
        message = f"Cache file is corrupted: {cache_path}"
        super().__init__(message, reason)
        self.cache_path = cache_path


class CacheVersionError(CacheError):
    """Raised when cache version is incompatible."""
    
    def __init__(self, expected: str, actual: str, cache_path: str):
        """Initialize the exception.
        
        Args:
            expected: Expected cache version.
            actual: Actual cache version found.
            cache_path: Path to the cache file.
        """
        message = f"Cache version mismatch: expected {expected}, got {actual}"
        details = f"Cache file: {cache_path}"
        super().__init__(message, details)
        self.expected_version = expected
        self.actual_version = actual
        self.cache_path = cache_path


class CacheWriteError(CacheError):
    """Raised when writing to cache fails."""
    
    def __init__(self, cache_path: str, reason: Optional[str] = None):
        """Initialize the exception.
        
        Args:
            cache_path: Path to the cache file.
            reason: Optional reason for the write failure.
        """
        message = f"Failed to write cache: {cache_path}"
        super().__init__(message, reason)
        self.cache_path = cache_path


class ConfigError(PluginaryError):
    """Base exception for configuration-related errors."""
    pass


class InvalidConfigError(ConfigError):
    """Raised when configuration is invalid."""
    
    def __init__(self, config_key: str, invalid_value: str, reason: Optional[str] = None):
        """Initialize the exception.
        
        Args:
            config_key: Configuration key that has invalid value.
            invalid_value: The invalid value.
            reason: Optional reason why the value is invalid.
        """
        message = f"Invalid configuration value for '{config_key}': {invalid_value}"
        super().__init__(message, reason)
        self.config_key = config_key
        self.invalid_value = invalid_value


class PlatformError(PluginaryError):
    """Raised when an operation is not supported on the current platform."""
    
    def __init__(self, operation: str, platform: str, supported_platforms: Optional[list[str]] = None):
        """Initialize the exception.
        
        Args:
            operation: Operation that is not supported.
            platform: Current platform.
            supported_platforms: Optional list of supported platforms.
        """
        message = f"Operation '{operation}' is not supported on {platform}"
        if supported_platforms:
            details = f"Supported platforms: {', '.join(supported_platforms)}"
        else:
            details = None
        super().__init__(message, details)
        self.operation = operation
        self.platform = platform
        self.supported_platforms = supported_platforms or []
</file>

<file path="src/pedalboard_pluginary/progress.py">
"""
Progress reporting implementations.
"""

import logging
from typing import Any, Callable, Optional

from tqdm import tqdm

from .protocols import ProgressReporter

logger = logging.getLogger(__name__)


class TqdmProgress(ProgressReporter):
    """Progress reporter using tqdm progress bars."""
    
    def __init__(self) -> None:
        """Initialize the progress reporter."""
        self._pbar: Optional[tqdm[Any]] = None
        self._total: int = 0
        self._current: int = 0
        self._description: str = ""
    
    def start(self, total: int, description: str = "") -> None:
        """Start progress tracking.
        
        Args:
            total: Total number of items to process.
            description: Optional description of the operation.
        """
        self._total = total
        self._current = 0
        self._description = description
        self._pbar = tqdm(total=total, desc=description)
    
    def update(self, amount: int = 1, message: Optional[str] = None) -> None:
        """Update progress.
        
        Args:
            amount: Number of items completed (default: 1).
            message: Optional status message.
        """
        if self._pbar is None:
            return
        
        self._current += amount
        self._pbar.update(amount)
        
        if message and hasattr(self._pbar, 'set_description'):
            # Update description with message
            self._pbar.set_description(f"{self._description} - {message}")
    
    def finish(self, message: Optional[str] = None) -> None:
        """Finish progress tracking.
        
        Args:
            message: Optional completion message.
        """
        if self._pbar is None:
            return
        
        # Ensure we reach 100%
        if self._current < self._total:
            self._pbar.update(self._total - self._current)
        
        if message and hasattr(self._pbar, 'set_description'):
            # Update description with message
            self._pbar.set_description(f"{self._description} - {message}")
        
        self._pbar.close()
        self._pbar = None


class NoOpProgress(ProgressReporter):
    """No-operation progress reporter for quiet mode."""
    
    def start(self, total: int, description: str = "") -> None:
        """Start progress tracking (no-op)."""
        pass
    
    def update(self, amount: int = 1, message: Optional[str] = None) -> None:
        """Update progress (no-op)."""
        pass
    
    def finish(self, message: Optional[str] = None) -> None:
        """Finish progress tracking (no-op)."""
        pass


class LogProgress(ProgressReporter):
    """Progress reporter that logs to standard logging."""
    
    def __init__(self, log_level: int = logging.INFO):
        """Initialize the progress reporter.
        
        Args:
            log_level: Logging level to use for progress messages.
        """
        self._log_level = log_level
        self._total: int = 0
        self._current: int = 0
        self._description: str = ""
    
    def start(self, total: int, description: str = "") -> None:
        """Start progress tracking.
        
        Args:
            total: Total number of items to process.
            description: Optional description of the operation.
        """
        self._total = total
        self._current = 0
        self._description = description
        
        logger.log(
            self._log_level,
            f"Starting: {description} (0/{total})"
        )
    
    def update(self, amount: int = 1, message: Optional[str] = None) -> None:
        """Update progress.
        
        Args:
            amount: Number of items completed (default: 1).
            message: Optional status message.
        """
        self._current += amount
        
        progress_pct = (self._current / self._total * 100) if self._total > 0 else 0
        status = f"{self._description}: {self._current}/{self._total} ({progress_pct:.1f}%)"
        
        if message:
            status += f" - {message}"
        
        logger.log(self._log_level, status)
    
    def finish(self, message: Optional[str] = None) -> None:
        """Finish progress tracking.
        
        Args:
            message: Optional completion message.
        """
        status = f"Completed: {self._description}"
        if message:
            status += f" - {message}"
        
        logger.log(self._log_level, status)


class CallbackProgress(ProgressReporter):
    """Progress reporter that calls user-provided callbacks."""
    
    def __init__(
        self,
        on_start: Optional[Callable[[int, str], None]] = None,
        on_update: Optional[Callable[[int, int, Optional[str]], None]] = None,
        on_finish: Optional[Callable[[Optional[str]], None]] = None,
    ):
        """Initialize the progress reporter with callbacks.
        
        Args:
            on_start: Callback for start(total, description).
            on_update: Callback for update(current, total, message).
            on_finish: Callback for finish(message).
        """
        self._on_start = on_start
        self._on_update = on_update
        self._on_finish = on_finish
        self._total: int = 0
        self._current: int = 0
    
    def start(self, total: int, description: str = "") -> None:
        """Start progress tracking.
        
        Args:
            total: Total number of items to process.
            description: Optional description of the operation.
        """
        self._total = total
        self._current = 0
        
        if self._on_start:
            self._on_start(total, description)
    
    def update(self, amount: int = 1, message: Optional[str] = None) -> None:
        """Update progress.
        
        Args:
            amount: Number of items completed (default: 1).
            message: Optional status message.
        """
        self._current += amount
        
        if self._on_update:
            self._on_update(self._current, self._total, message)
    
    def finish(self, message: Optional[str] = None) -> None:
        """Finish progress tracking.
        
        Args:
            message: Optional completion message.
        """
        if self._on_finish:
            self._on_finish(message)
</file>

<file path="src/pedalboard_pluginary/protocols.py">
"""
Protocol definitions for plugin scanner implementations.
"""

from typing import Protocol, List, Optional, Dict, runtime_checkable
from pathlib import Path

from .models import PluginInfo


@runtime_checkable
class PluginScanner(Protocol):
    """Protocol defining the interface for plugin scanners."""
    
    plugin_type: str
    supported_extensions: List[str]
    
    def find_plugin_files(self, paths: Optional[List[Path]] = None) -> List[Path]:
        """Find all plugin files of this scanner's type.
        
        Args:
            paths: Optional list of specific paths to check. If None, searches default locations.
            
        Returns:
            List of paths to plugin files found.
        """
        ...
    
    def scan_plugin(self, path: Path) -> Optional[PluginInfo]:
        """Scan a single plugin file and return its information.
        
        Args:
            path: Path to the plugin file to scan.
            
        Returns:
            PluginInfo object if successful, None if scanning failed.
        """
        ...
    
    def validate_plugin_path(self, path: Path) -> bool:
        """Validate if a path is a valid plugin for this scanner.
        
        Args:
            path: Path to validate.
            
        Returns:
            True if the path is a valid plugin file, False otherwise.
        """
        ...


@runtime_checkable
class ProgressReporter(Protocol):
    """Protocol for progress reporting implementations."""
    
    def start(self, total: int, description: str = "") -> None:
        """Start progress tracking.
        
        Args:
            total: Total number of items to process.
            description: Optional description of the operation.
        """
        ...
    
    def update(self, amount: int = 1, message: Optional[str] = None) -> None:
        """Update progress.
        
        Args:
            amount: Number of items completed (default: 1).
            message: Optional status message.
        """
        ...
    
    def finish(self, message: Optional[str] = None) -> None:
        """Finish progress tracking.
        
        Args:
            message: Optional completion message.
        """
        ...


@runtime_checkable
class CacheBackend(Protocol):
    """Protocol for cache backend implementations."""
    
    def load(self) -> Dict[str, PluginInfo]:
        """Load all cached plugins.
        
        Returns:
            Dictionary mapping plugin IDs to PluginInfo objects.
        """
        ...
    
    def save(self, plugins: Dict[str, PluginInfo]) -> None:
        """Save plugins to cache.
        
        Args:
            plugins: Dictionary mapping plugin IDs to PluginInfo objects.
        """
        ...
    
    def update(self, plugin_id: str, plugin: PluginInfo) -> None:
        """Update a single plugin in cache.
        
        Args:
            plugin_id: ID of the plugin to update.
            plugin: Updated PluginInfo object.
        """
        ...
    
    def delete(self, plugin_id: str) -> None:
        """Remove a plugin from cache.
        
        Args:
            plugin_id: ID of the plugin to remove.
        """
        ...
    
    def clear(self) -> None:
        """Clear entire cache."""
        ...
    
    def exists(self) -> bool:
        """Check if cache exists.
        
        Returns:
            True if cache exists, False otherwise.
        """
        ...
</file>

<file path="src/pedalboard_pluginary/retry.py">
"""
Retry logic for handling transient failures.
"""

import functools
import logging
import time
from typing import Any, Callable, Optional, Tuple, Type, TypeVar, Union

from .constants import MAX_SCAN_RETRIES, SCAN_RETRY_DELAY

logger = logging.getLogger(__name__)

F = TypeVar('F', bound=Callable[..., Any])


def with_retry(
    exceptions: Union[Type[Exception], Tuple[Type[Exception], ...]],
    max_attempts: int = MAX_SCAN_RETRIES,
    delay: float = SCAN_RETRY_DELAY,
    backoff_factor: float = 2.0,
    max_delay: float = 60.0,
) -> Callable[[F], F]:
    """Decorator that retries a function on specified exceptions.
    
    Args:
        exceptions: Exception or tuple of exceptions to catch and retry on.
        max_attempts: Maximum number of attempts (including the first).
        delay: Initial delay between retries in seconds.
        backoff_factor: Factor to multiply delay by after each failure.
        max_delay: Maximum delay between retries in seconds.
        
    Returns:
        Decorated function that will retry on failure.
    """
    def decorator(func: F) -> F:
        @functools.wraps(func)
        def wrapper(*args: Any, **kwargs: Any) -> Any:
            current_delay = delay
            last_exception: Optional[Exception] = None
            
            for attempt in range(max_attempts):
                try:
                    return func(*args, **kwargs)
                except exceptions as e:
                    last_exception = e
                    if attempt == max_attempts - 1:
                        # Last attempt, re-raise
                        logger.warning(
                            f"{func.__name__} failed after {max_attempts} attempts: {e}"
                        )
                        raise
                    
                    logger.info(
                        f"{func.__name__} failed (attempt {attempt + 1}/{max_attempts}): {e}. "
                        f"Retrying in {current_delay:.1f}s..."
                    )
                    time.sleep(current_delay)
                    
                    # Exponential backoff with max delay
                    current_delay = min(current_delay * backoff_factor, max_delay)
            
            # This should never be reached, but just in case
            if last_exception:
                raise last_exception
            else:
                raise RuntimeError(f"{func.__name__} failed with unknown error")
        
        return wrapper  # type: ignore[return-value]
    
    return decorator


def with_timeout(timeout: float) -> Callable[[F], F]:
    """Decorator that adds a timeout to a function.
    
    Note: This is a placeholder for future implementation.
    Proper timeout handling requires different approaches for
    synchronous vs asynchronous functions.
    
    Args:
        timeout: Timeout in seconds.
        
    Returns:
        Decorated function.
    """
    def decorator(func: F) -> F:
        @functools.wraps(func)
        def wrapper(*args: Any, **kwargs: Any) -> Any:
            # TODO: Implement proper timeout handling
            # For now, just pass through
            return func(*args, **kwargs)
        
        return wrapper  # type: ignore[return-value]
    
    return decorator
</file>

<file path="tests/scanners/__init__.py">
# tests/scanners/__init__.py
# This file makes Python treat the `tests/scanners` directory as a package.
</file>

<file path="tests/scanners/test_au_scanner.py">
# tests/scanners/test_au_scanner.py
import os
import platform
import pytest
from pathlib import Path
from unittest.mock import patch, MagicMock

from pedalboard_pluginary.scanners.au_scanner import AUScanner

# Sample auval output
AUVAL_OUTPUT_VALID = """
 Westwood AU Test
--------------------------------------------------
AUVALTOOL Discount AU
--------------------------------------------------
PLAYER version 2.0.13 (build 17)
--------------------------------------------------
VALIDATING AUDIO UNIT: 'aufx' - 'dely' - 'appl'
--------------------------------------------------
Manufacturer String: Apple
AudioUnit Name: AUDelay
Component Version: 1.7.0
Component Bundle Path: /Library/Audio/Plug-Ins/Components/AUDelay.component
Component AU Path: /Library/Audio/Plug-Ins/Components/AUDelay.component/Contents/MacOS/AUDelay

* * PASS
--------------------------------------------------
VALIDATING AUDIO UNIT: 'aufx' - 'mcmp' - 'appl'
--------------------------------------------------
Manufacturer String: Apple
AudioUnit Name: AUMultibandCompressor
Component Version: 1.7.0
Component Bundle Path: /Library/Audio/Plug-Ins/Components/AUMultibandCompressor.component
Component AU Path: /Library/Audio/Plug-Ins/Components/AUMultibandCompressor.component/Contents/MacOS/AUMultibandCompressor

* * PASS
--------------------------------------------------
VALIDATING AUDIO UNIT: 'aumf' - 'dls ' - 'appl'
--------------------------------------------------
Manufacturer String: Apple
AudioUnit Name: DLSMusicDevice
Component Version: 1.7.0
Component Bundle Path: /Library/Audio/Plug-Ins/Components/DLSMusicDevice.component
Component AU Path: /Library/Audio/Plug-Ins/Components/DLSMusicDevice.component/Contents/MacOS/DLSMusicDevice

* * PASS
--------------------------------------------------
TESTING OPEN TIMES:
COLD:
Time to open AudioUnit:      21.112 ms
WARM:
Time to open AudioUnit:      0.042  ms
This AudioUnit is a version 3 implementation.
FIRST TIME:
FATAL ERROR: Initialize: result: -50


--------------------------------------------------
AU VALIDATION SUCCEEDED.
--------------------------------------------------
"""

AUVAL_OUTPUT_GARBAGE_URL = """
 Westwood AU Test
--------------------------------------------------
VALIDATING AUDIO UNIT: 'aufx' - 'xxxx' - 'test'
--------------------------------------------------
Manufacturer String: Test Inc
AudioUnit Name: BadURLPlugin
Component Version: 1.0.0
Component Bundle Path: /path/to/plugin with spaces.component
Component AU Path: (null)

* * PASS
--------------------------------------------------
AU VALIDATION SUCCEEDED.
--------------------------------------------------
"""


@pytest.fixture
def au_scanner_instance():
    return AUScanner(ignores=set())

@pytest.fixture
def au_scanner_with_ignores_instance():
    return AUScanner(ignores={"aufx/DLSMusicDevice"}) # Key is type/stem

@patch('platform.system', return_value='Darwin') # Assume macOS for these tests
class TestAUScanner:

    @patch('subprocess.run')
    def test_list_aufx_plugins_raw_success(self, mock_subprocess_run, au_scanner_instance):
        mock_process = MagicMock()
        mock_process.stdout = AUVAL_OUTPUT_VALID
        mock_subprocess_run.return_value = mock_process

        lines = au_scanner_instance._list_aufx_plugins_raw()
        assert len(lines) > 0
        assert "AUDelay" in AUVAL_OUTPUT_VALID
        mock_subprocess_run.assert_called_once_with(
            ["auval", "-l"],
            stdout=subprocess.PIPE,
            stderr=subprocess.DEVNULL,
            text=True,
            check=True,
        )

    @patch('subprocess.run', side_effect=FileNotFoundError("auval not found"))
    def test_list_aufx_plugins_raw_auval_not_found(self, mock_subprocess_run, au_scanner_instance):
        lines = au_scanner_instance._list_aufx_plugins_raw()
        assert lines == []

    @patch('subprocess.run')
    def test_find_plugin_files_valid_output(self, mock_subprocess_run, au_scanner_instance):
        mock_process = MagicMock()
        mock_process.stdout = AUVAL_OUTPUT_VALID
        mock_subprocess_run.return_value = mock_process

        # Mock Path.resolve() and Path.exists() for paths found by auval
        with patch.object(Path, 'resolve') as mock_resolve, \
             patch.object(Path, 'exists', return_value=True) as mock_exists:

            # Make resolve return a Path object that can be further manipulated if needed
            # and also has an 'exists' method.
            def side_effect_resolve(*args, **kwargs):
                # The input to resolve is the path string from auval output
                # e.g., Path("/Library/Audio/Plug-Ins/Components/AUDelay.component")
                # We want it to return itself basically, but as a mock if needed for exists()
                p = Path(*args) # Reconstruct the original path
                # Mock the exists for this specific path if needed, though global mock_exists might cover it
                # For bundle path logic, ensure suffix is checked on original path.
                return p
            mock_resolve.side_effect = side_effect_resolve

            plugin_files = au_scanner_instance.find_plugin_files()

            assert len(plugin_files) == 3 # AUDelay, AUMultibandCompressor, DLSMusicDevice
            expected_paths = [
                Path("/Library/Audio/Plug-Ins/Components/AUDelay.component"),
                Path("/Library/Audio/Plug-Ins/Components/AUMultibandCompressor.component"),
                Path("/Library/Audio/Plug-Ins/Components/DLSMusicDevice.component"),
            ]
            for p in expected_paths:
                assert p.resolve() in plugin_files # Comparing resolved paths

    @patch('subprocess.run')
    def test_find_plugin_files_with_ignores(self, mock_subprocess_run, au_scanner_with_ignores_instance):
        mock_process = MagicMock()
        mock_process.stdout = AUVAL_OUTPUT_VALID
        mock_subprocess_run.return_value = mock_process

        with patch.object(Path, 'resolve', side_effect=lambda p: Path(p)), \
             patch.object(Path, 'exists', return_value=True):
            plugin_files = au_scanner_with_ignores_instance.find_plugin_files()

            # DLSMusicDevice should be ignored
            assert len(plugin_files) == 2
            ignored_path = Path("/Library/Audio/Plug-Ins/Components/DLSMusicDevice.component").resolve()
            assert ignored_path not in plugin_files
            delay_path = Path("/Library/Audio/Plug-Ins/Components/AUDelay.component").resolve()
            assert delay_path in plugin_files


    @patch('subprocess.run')
    def test_find_plugin_files_garbage_url(self, mock_subprocess_run, au_scanner_instance):
        mock_process = MagicMock()
        mock_process.stdout = AUVAL_OUTPUT_GARBAGE_URL # Contains (null) URL
        mock_subprocess_run.return_value = mock_process

        with patch.object(Path, 'resolve', side_effect=lambda p: Path(p) if p else None), \
             patch.object(Path, 'exists', return_value=True):
            plugin_files = au_scanner_instance.find_plugin_files()
            assert len(plugin_files) == 0 # Should skip the one with (null) URL

    @patch('platform.system', return_value='Linux') # Test non-Darwin platform
    def test_scanner_on_non_macos(self, mock_platform_system_linux, au_scanner_instance):
        assert au_scanner_instance._list_aufx_plugins_raw() == []
        assert au_scanner_instance.find_plugin_files() == []

    @patch('subprocess.run')
    def test_find_plugin_files_with_specific_paths_filter(self, mock_subprocess_run, au_scanner_instance):
        mock_process = MagicMock()
        mock_process.stdout = AUVAL_OUTPUT_VALID
        mock_subprocess_run.return_value = mock_process

        # User wants to check only AUDelay
        specific_paths_to_check = [Path("/Library/Audio/Plug-Ins/Components/AUDelay.component")]

        with patch.object(Path, 'resolve', side_effect=lambda p: Path(p)), \
             patch.object(Path, 'exists', return_value=True):
            plugin_files = au_scanner_instance.find_plugin_files(plugin_paths=specific_paths_to_check)

            assert len(plugin_files) == 1
            assert Path("/Library/Audio/Plug-Ins/Components/AUDelay.component").resolve() in plugin_files

    # Test for bundle path resolution logic
    # This requires more intricate mocking of Path objects if we don't want to rely on filesystem
    @patch('subprocess.run')
    def test_bundle_path_resolution(self, mock_subprocess_run, au_scanner_instance):
        # Simulate auval output where path is deep inside the bundle
        deep_path_auval_output = """
        VALIDATING AUDIO UNIT: 'aufx' - 'test' - 'tstc'
        --------------------------------------------------
        Manufacturer String: TestCompany
        AudioUnit Name: DeepTestPlugin
        Component Version: 1.0.0
        Component Bundle Path: /Some/Path/DeepTestPlugin.component/Contents/MacOS/DeepTestPlugin
        Component AU Path: /Some/Path/DeepTestPlugin.component/Contents/MacOS/DeepTestPlugin
        * * PASS
        --------------------------------------------------
        AU VALIDATION SUCCEEDED.
        --------------------------------------------------
        """
        mock_process = MagicMock()
        mock_process.stdout = deep_path_auval_output
        mock_subprocess_run.return_value = mock_process

        # We need to mock Path behavior for suffix and parent
        # The Path object created from the string should behave as expected.
        # No complex mocking needed if Path objects work as standard for these attributes.
        # We only need to ensure Path.resolve and Path.exists are controlled.

        with patch.object(Path, 'resolve', side_effect=lambda p: Path(p)), \
             patch.object(Path, 'exists', return_value=True):

            plugin_files = au_scanner_instance.find_plugin_files()

            assert len(plugin_files) == 1
            # The scanner should correctly identify the .component bundle path
            expected_bundle_path = Path("/Some/Path/DeepTestPlugin.component").resolve()
            assert expected_bundle_path in plugin_files

# TODO: Add tests for error conditions in auval (e.g., CalledProcessError)
# TODO: Add tests for when Path.resolve() or other Path operations raise exceptions
# (though these are less likely for valid path strings)
</file>

<file path="tests/test_cli.py">
# tests/test_cli.py
import os
import subprocess
import json
import yaml
from pathlib import Path
from unittest.mock import patch, MagicMock
import pytest

from pedalboard_pluginary.data import APP_NAME, PLUGINS_CACHE_FILENAME_BASE, get_cache_path

# Helper to get the cache file path for plugins
def get_plugins_cache_file():
    return get_cache_path(PLUGINS_CACHE_FILENAME_BASE)

@pytest.fixture(autouse=True)
def manage_plugin_cache():
    """Fixture to ensure plugin cache is handled before and after tests."""
    cache_file = get_plugins_cache_file()
    original_content = None

    if cache_file.exists():
        original_content = cache_file.read_text()
        cache_file.unlink() # Remove before test

    yield # Test runs here

    # Cleanup: remove cache file created by test, or restore original
    if cache_file.exists():
        cache_file.unlink()
    if original_content:
        # Ensure parent directory exists before writing back
        cache_file.parent.mkdir(parents=True, exist_ok=True)
        cache_file.write_text(original_content)


# Mocked data for PedalboardScanner.scan_all_plugins and load_json_file
# This data will be "written" by the mocked scan and "read" by list/json/yaml
MOCK_PLUGIN_DATA = {
    "vst3/MockSynth": {
        "id": "vst3/MockSynth",
        "name": "MockSynth",
        "path": "/fake/path/to/MockSynth.vst3",
        "filename": "MockSynth.vst3",
        "plugin_type": "vst3",
        "parameters": {
            "Volume": {"name": "Volume", "value": 0.75},
            "Pan": {"name": "Pan", "value": 0.0}
        },
        "manufacturer": "FakePlugins",
        "name_in_file": "MockSynth"
    },
    "aufx/MockEffect": {
        "id": "aufx/MockEffect",
        "name": "MockEffect",
        "path": "/fake/path/to/MockEffect.component",
        "filename": "MockEffect.component",
        "plugin_type": "aufx",
        "parameters": {
            "Wet/Dry": {"name": "Wet/Dry", "value": 0.5}
        },
        "manufacturer": "FakeAudio",
        "name_in_file": "MockEffect"
    }
}

# This mock will replace the actual PedalboardScanner instance or its methods
@patch('pedalboard_pluginary.scanner.PedalboardScanner.scan_all_plugins')
@patch('pedalboard_pluginary.scanner.PedalboardScanner.update_scan') # Also mock update_scan
@patch('pedalboard_pluginary.scanner.PedalboardScanner.save_plugins') # Mock save_plugins
@patch('pedalboard_pluginary.core.PedalboardPluginary.load_data') # Mock load_data in core
def run_cli_command(
    cli_args_list,
    mock_core_load_data,
    mock_scanner_save_plugins,
    mock_scanner_update_scan,
    mock_scanner_scan_all,
    expected_exit_code=0
):
    """Helper to run CLI commands and capture output."""

    # If scan or update is called, make them "create" the mock cache file
    def side_effect_scan_or_update(*args, **kwargs):
        cache_file = get_plugins_cache_file()
        cache_file.parent.mkdir(parents=True, exist_ok=True)
        with open(cache_file, 'w') as f:
            json.dump(MOCK_PLUGIN_DATA, f, indent=4)
        # The actual scan methods in PedalboardScanner don't return anything.
        # They modify self.plugins and then call self.save_plugins.
        # We've mocked save_plugins separately.

    mock_scanner_scan_all.side_effect = side_effect_scan_or_update
    mock_scanner_update_scan.side_effect = side_effect_scan_or_update

    # Mock load_data to set the plugins attribute on an instance if needed,
    # or simply prevent it from trying to load a real file during list commands
    # if scan hasn't run.
    # For 'list', 'json', 'yaml', the PedalboardPluginary instance will try to load.
    # We can patch load_json_file used by PedalboardPluginary.load_data

    base_command = ["pbpluginary"]
    full_command = base_command + cli_args_list

    try:
        result = subprocess.run(full_command, capture_output=True, text=True, check=False)
        if result.returncode != expected_exit_code:
            print("STDOUT:", result.stdout)
            print("STDERR:", result.stderr)
        assert result.returncode == expected_exit_code
        return result
    except FileNotFoundError:
        pytest.fail("pbpluginary command not found. Ensure it's installed and in PATH for testing.")


# Test 'scan' command
# Patching at the source of where PedalboardScanner is instantiated or used by CLI
@patch('pedalboard_pluginary.__main__.PedalboardScanner')
def test_cli_scan(MockScannerConstructor):
    # Mock the instance methods that would be called
    mock_scanner_instance = MockScannerConstructor.return_value
    mock_scanner_instance.rescan.return_value = None # rescan calls full_scan which calls scan_all_plugins

    # We need rescan (which is an alias for full_scan) to effectively create the cache
    # by having its underlying scan_all_plugins call write the MOCK_PLUGIN_DATA
    def mock_rescan_writes_cache(*args, **kwargs):
        cache_file = get_plugins_cache_file()
        cache_file.parent.mkdir(parents=True, exist_ok=True)
        with open(cache_file, 'w') as f:
            json.dump(MOCK_PLUGIN_DATA, f, indent=4)
    mock_scanner_instance.rescan.side_effect = mock_rescan_writes_cache

    result = run_cli_command(["scan"]) # Uses the patches from run_cli_command's decorators

    # Check that the cache file was created with mock data
    cache_file = get_plugins_cache_file()
    assert cache_file.exists()
    with open(cache_file, 'r') as f:
        data_from_cache = json.load(f)
    assert data_from_cache == MOCK_PLUGIN_DATA

    # Check if scan method on the instance was called
    mock_scanner_instance.rescan.assert_called_once()


# Test 'list' command (implicitly tests JSON output)
# For list, we need to ensure that the cache exists or that PedalboardPluginary can load it.
# The manage_plugin_cache fixture helps here.
# We also need to control what PedalboardPluginary.load_data does.
@patch('pedalboard_pluginary.data.load_json_file') # Patch where load_json_file is defined
def test_cli_list(mock_load_json, capsys):
    # Setup: Ensure a cache file with MOCK_PLUGIN_DATA exists for 'list' to read
    cache_file = get_plugins_cache_file()
    cache_file.parent.mkdir(parents=True, exist_ok=True)
    with open(cache_file, 'w') as f:
        json.dump(MOCK_PLUGIN_DATA, f, indent=4)

    # Configure the mock for load_json_file used by PedalboardPluginary
    # It should return the MOCK_PLUGIN_DATA when the specific plugins cache path is requested
    def side_effect_load_json(path_arg):
        if path_arg == cache_file:
            # Return raw dict, PedalboardPluginary.load_data will handle reconstruction
            return MOCK_PLUGIN_DATA
        return {} # Default for other calls
    mock_load_json.side_effect = side_effect_load_json

    # Run the 'list' command
    # Using direct function call to avoid subprocess complexity with stdout/stderr and fire's display hook
    from pedalboard_pluginary.__main__ import list_json_cli

    # Fire's Display hook is tricky to test with subprocess.run, so call directly.
    # list_json_cli returns a string.
    # We need to ensure that when `pbpluginary list` is run, this function is called
    # and its output (which is JSON string) is printed.
    # For simplicity here, just test the function that `fire` would call.

    # To test the actual CLI output, we need to let pbpluginary run as subprocess
    # and capture stdout. This means not mocking PedalboardPluginary or its load_data directly here
    # but ensuring the underlying data.load_json_file behaves as expected due to the patch.

    result = subprocess.run(["pbpluginary", "list"], capture_output=True, text=True, check=True)

    # The output should be the MOCK_PLUGIN_DATA formatted as JSON
    # Fire wraps output, so it might not be exact JSON string if printed line-by-line.
    # The default 'list' command in __main__.py calls bdict().to_json() and fire prints it.
    # Let's parse the stdout.
    try:
        output_data = json.loads(result.stdout)
        assert output_data == MOCK_PLUGIN_DATA
    except json.JSONDecodeError:
        pytest.fail(f"CLI output was not valid JSON. Output:\n{result.stdout}")


# Test 'json' command (should be identical to 'list')
@patch('pedalboard_pluginary.data.load_json_file')
def test_cli_json_output(mock_load_json_for_json_cmd, capsys):
    cache_file = get_plugins_cache_file()
    cache_file.parent.mkdir(parents=True, exist_ok=True)
    with open(cache_file, 'w') as f:
        json.dump(MOCK_PLUGIN_DATA, f, indent=4)

    def side_effect_load_json(path_arg):
        if path_arg == cache_file:
            return MOCK_PLUGIN_DATA
        return {}
    mock_load_json_for_json_cmd.side_effect = side_effect_load_json

    result = subprocess.run(["pbpluginary", "json"], capture_output=True, text=True, check=True)
    try:
        output_data = json.loads(result.stdout)
        assert output_data == MOCK_PLUGIN_DATA
    except json.JSONDecodeError:
        pytest.fail(f"CLI output for 'json' was not valid JSON. Output:\n{result.stdout}")


# Test 'yaml' command
@patch('pedalboard_pluginary.data.load_json_file')
def test_cli_yaml_output(mock_load_json_for_yaml_cmd, capsys):
    cache_file = get_plugins_cache_file()
    cache_file.parent.mkdir(parents=True, exist_ok=True)
    with open(cache_file, 'w') as f:
        json.dump(MOCK_PLUGIN_DATA, f, indent=4)

    def side_effect_load_json(path_arg):
        if path_arg == cache_file:
            return MOCK_PLUGIN_DATA
        return {}
    mock_load_json_for_yaml_cmd.side_effect = side_effect_load_json

    result = subprocess.run(["pbpluginary", "yaml"], capture_output=True, text=True, check=True)
    try:
        # python-benedict's to_yaml output might have specific formatting.
        # For robustness, parse it back and compare with original data.
        output_data = yaml.safe_load(result.stdout)
        # YAML load might produce slightly different types (e.g. list for dict items sometimes)
        # A direct comparison MOCK_PLUGIN_DATA might be tricky if numbers are float vs int.
        # For now, let's assume benedict produces standard YAML that converts back cleanly.
        assert json.dumps(output_data, sort_keys=True) == json.dumps(MOCK_PLUGIN_DATA, sort_keys=True)
    except yaml.YAMLError:
        pytest.fail(f"CLI output for 'yaml' was not valid YAML. Output:\n{result.stdout}")
    except Exception as e:
        pytest.fail(f"Error comparing YAML output: {e}. Output:\n{result.stdout}")


# Test 'update' command
@patch('pedalboard_pluginary.__main__.PedalboardScanner')
def test_cli_update(MockScannerConstructorForUpdate):
    mock_scanner_instance = MockScannerConstructorForUpdate.return_value

    # Simulate that update_scan effectively writes the cache
    def mock_update_scan_writes_cache(*args, **kwargs):
        cache_file = get_plugins_cache_file()
        cache_file.parent.mkdir(parents=True, exist_ok=True)
        # Update might add to existing data or rescan if no cache.
        # For this test, assume it behaves like scan if no cache.
        with open(cache_file, 'w') as f:
            json.dump(MOCK_PLUGIN_DATA, f, indent=4) # For simplicity, same as scan
    mock_scanner_instance.update_scan.side_effect = mock_update_scan_writes_cache

    result = run_cli_command(["update"]) # Uses patches from run_cli_command

    cache_file = get_plugins_cache_file()
    assert cache_file.exists()
    with open(cache_file, 'r') as f:
        data_from_cache = json.load(f)
    assert data_from_cache == MOCK_PLUGIN_DATA # Assuming update wrote this

    mock_scanner_instance.update_scan.assert_called_once()


# TODO: Test for verbose logging options (--verbose=1, --verbose=2)
# TODO: Test for --extra-folders option with scan and update
# TODO: Test scan/update when cache already exists (for update's diff logic, though that's scanner internal)
# TODO: Test error conditions (e.g., unparseable cache, permissions issues - harder to mock)

# Note: The run_cli_command helper and its patches are quite broad.
# For more targeted tests, especially for 'list', 'json', 'yaml',
# it might be better to directly call the CLI functions from __main__.py
# and mock their dependencies (like PedalboardPluginary instance) instead of using subprocess.
# However, subprocess tests the actual command-line invocation.
# The current `test_cli_list` and `test_cli_json_output`, `test_cli_yaml_output`
# have been changed to use subprocess.run directly.
</file>

<file path="tests/test_utils.py">
import pytest
from pedalboard_pluginary.utils import ensure_folder
from pathlib import Path

def test_ensure_folder(tmp_path):
    test_folder = tmp_path / "test_folder"
    ensure_folder(test_folder)
    assert test_folder.exists()
</file>

<file path=".coveragerc">
# .coveragerc to control coverage.py
[run]
branch = True
source = pedalboard_pluginary
# omit = bad_file.py

[paths]
source =
    src/
    */site-packages/

[report]
# Regexes for lines to exclude from consideration
exclude_lines =
    # Have to re-enable the standard pragma
    pragma: no cover

    # Don't complain about missing debug-only code:
    def __repr__
    if self\.debug

    # Don't complain if tests don't hit defensive assertion code:
    raise AssertionError
    raise NotImplementedError

    # Don't complain if non-runnable code isn't run:
    if 0:
    if __name__ == .__main__.:
</file>

<file path=".isort.cfg">
[settings]
profile = black
known_first_party = pedalboard_pluginary
</file>

<file path="build.sh">
#!/usr/bin/env bash
# this_file: build.sh

set -e # Exit on error

echo "🧹 Cleaning up previous builds..."
rm -rf build/ dist/ *.egg-info .eggs/ .pytest_cache/ .coverage .tox/ .mypy_cache/

echo "🔍 Running type checks with mypy..."
python -m mypy src/pedalboard_pluginary

echo "�� Running tests..."
PYTHONPATH=src pytest tests/ -p no:flake8 -p no:briefcase

echo "📦 Building package..."
python -m build

echo "🚀 Installing locally..."
pip install -e .

echo "✨ Build and installation complete!"
</file>

<file path="LICENSE.txt">
Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "{}"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright {yyyy} {name of copyright owner}

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
</file>

<file path="src/pedalboard_pluginary/models.py">
# pedalboard_pluginary/models.py
"""
Dataclasses for representing plugin information.
"""
from dataclasses import dataclass, field
from pathlib import Path
from typing import Union, Dict, Optional, Any

# ParameterValue is what we store (after conversion from pedalboard's raw param value)
ParameterValue = Union[float, bool, str]

@dataclass
class PluginParameter:
    """Represents a single parameter of a plugin."""
    name: str
    value: ParameterValue
    # Optional: Add other attributes like min_value, max_value, string_value, etc.
    # if Pedalboard consistently provides them and they are useful to store.
    # For now, keeping it simple with just name and current (default) value.
    # raw_pedalboard_value: Any # Could store the original pedalboard value if needed for debugging

@dataclass
class PluginInfo:
    """Represents a scanned audio plugin."""
    # Unique key for this plugin, e.g., "vst3/FabFilter Pro-Q 3" or "aufx/ChannelEQ"
    # This key might be different from `name` if a file contains multiple plugins or
    # if the user-facing name has characters not suitable for a key.
    # This will be the key in the main dictionary of plugins.
    id: str

    name: str # The display name of the plugin
    path: str # Path to the plugin file or bundle (as string for JSON serialization)
    filename: str # Filename of the plugin (e.g., "FabFilter Pro-Q 3.vst3")
    plugin_type: str # "vst3" or "aufx"

    # Parameters: dict where key is param name, value is PluginParameter object
    parameters: Dict[str, PluginParameter] = field(default_factory=dict)

    manufacturer: Optional[str] = None # Optional: Plugin manufacturer name

    # Optional: If a plugin file (e.g. VST3) can contain multiple uniquely identifiable
    # plugins, this field could store the specific name used to load this plugin
    # from the file, if different from the main `name`.
    # E.g. `pedalboard.load_plugin(path, plugin_name=name_in_file)`
    name_in_file: Optional[str] = None

    def __post_init__(self) -> None:
        # Ensure path is stored as a string for easier JSON serialization
        # Note: self.path is already typed as str, so this check is defensive
        pass

    # Consider adding methods for to_dict/from_dict if needed for complex serialization,
    # though dataclasses.asdict and direct instantiation usually suffice.

# Example usage:
# if __name__ == "__main__":
#     eq_param = PluginParameter(name="Frequency", value=1000.0)
#     gain_param = PluginParameter(name="Gain", value=0.0)
#     bypass_param = PluginParameter(name="Bypass", value=False)

#     example_plugin = PluginInfo(
#         id="vst3/AwesomeEQ",
#         name="Awesome EQ",
#         path="/path/to/AwesomeEQ.vst3",
#         filename="AwesomeEQ.vst3",
#         plugin_type="vst3",
#         parameters={
#             "Frequency": eq_param,
#             "Gain": gain_param,
#             "Bypass": bypass_param
#         },
#         manufacturer="MyPluginCompany"
#     )
#     import json
#     from dataclasses import asdict
#     print(json.dumps(asdict(example_plugin), indent=2))
</file>

<file path="src/pedalboard_pluginary/serialization.py">
"""
Unified serialization module for plugin data.
"""

import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, Optional

from .constants import APP_VERSION, CACHE_VERSION
from .exceptions import CacheCorruptedError, CacheVersionError, CacheWriteError
from .models import PluginInfo, PluginParameter
from .types import (
    CacheData,
    CacheMetadata,
    SerializedParameter,
    SerializedPlugin,
    is_serialized_parameter,
    is_serialized_plugin,
)
from .utils import ensure_folder

logger = logging.getLogger(__name__)


class PluginSerializer:
    """Handles serialization and deserialization of plugin data."""
    
    @staticmethod
    def parameter_to_dict(param: PluginParameter) -> SerializedParameter:
        """Convert PluginParameter to serializable dictionary.
        
        Args:
            param: PluginParameter object to serialize.
            
        Returns:
            SerializedParameter dictionary.
        """
        return {
            "name": param.name,
            "value": param.value,
        }
    
    @staticmethod
    def dict_to_parameter(data: Dict[str, Any]) -> Optional[PluginParameter]:
        """Convert dictionary to PluginParameter with validation.
        
        Args:
            data: Dictionary containing parameter data.
            
        Returns:
            PluginParameter object if valid, None otherwise.
        """
        if not is_serialized_parameter(data):
            logger.warning(f"Invalid parameter data: {data}")
            return None
        
        return PluginParameter(
            name=data["name"],
            value=data["value"],
        )
    
    @staticmethod
    def plugin_to_dict(plugin: PluginInfo) -> SerializedPlugin:
        """Convert PluginInfo to serializable dictionary.
        
        Args:
            plugin: PluginInfo object to serialize.
            
        Returns:
            SerializedPlugin dictionary.
        """
        # Convert parameters
        params_dict: Dict[str, SerializedParameter] = {}
        for param_name, param in plugin.parameters.items():
            params_dict[param_name] = PluginSerializer.parameter_to_dict(param)
        
        result: SerializedPlugin = {
            "id": plugin.id,
            "name": plugin.name,
            "path": plugin.path,
            "filename": plugin.filename,
            "plugin_type": plugin.plugin_type,
            "parameters": params_dict,
            "manufacturer": plugin.manufacturer,
            "name_in_file": plugin.name_in_file,
        }
        
        return result
    
    @staticmethod
    def dict_to_plugin(data: Dict[str, Any]) -> Optional[PluginInfo]:
        """Convert dictionary to PluginInfo with validation.
        
        Args:
            data: Dictionary containing plugin data.
            
        Returns:
            PluginInfo object if valid, None otherwise.
        """
        if not is_serialized_plugin(data):
            logger.warning(f"Invalid plugin data for ID: {data.get('id', 'unknown')}")
            return None
        
        # Convert parameters
        params: Dict[str, PluginParameter] = {}
        for param_name, param_data in data.get("parameters", {}).items():
            param = PluginSerializer.dict_to_parameter(param_data)
            if param:
                params[param_name] = param
        
        return PluginInfo(
            id=data["id"],
            name=data["name"],
            path=data["path"],
            filename=data["filename"],
            plugin_type=data["plugin_type"],
            parameters=params,
            manufacturer=data.get("manufacturer"),
            name_in_file=data.get("name_in_file"),
        )
    
    @classmethod
    def create_cache_metadata(cls, plugin_count: int) -> CacheMetadata:
        """Create cache metadata.
        
        Args:
            plugin_count: Number of plugins in the cache.
            
        Returns:
            CacheMetadata dictionary.
        """
        now = datetime.utcnow().isoformat()
        return {
            "version": CACHE_VERSION,
            "created_at": now,
            "updated_at": now,
            "plugin_count": plugin_count,
            "scanner_version": APP_VERSION,
        }
    
    @classmethod
    def save_plugins(cls, plugins: Dict[str, PluginInfo], path: Path) -> None:
        """Save plugins to JSON file with metadata and error handling.
        
        Args:
            plugins: Dictionary mapping plugin IDs to PluginInfo objects.
            path: Path to the cache file.
        """
        ensure_folder(path.parent)
        
        # Convert plugins to serializable format
        plugins_dict: Dict[str, SerializedPlugin] = {}
        for plugin_id, plugin in plugins.items():
            try:
                plugins_dict[plugin_id] = cls.plugin_to_dict(plugin)
            except Exception as e:
                logger.error(f"Failed to serialize plugin {plugin_id}: {e}")
                continue
        
        # Create cache data with metadata
        cache_data: CacheData = {
            "metadata": cls.create_cache_metadata(len(plugins_dict)),
            "plugins": plugins_dict,
        }
        
        # Write to file with error handling
        try:
            with open(path, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, indent=2)
            logger.info(f"Saved {len(plugins_dict)} plugins to {path}")
        except Exception as e:
            logger.error(f"Failed to save plugins to {path}: {e}")
            raise CacheWriteError(str(path), str(e))
    
    @classmethod
    def load_plugins(cls, path: Path) -> Dict[str, PluginInfo]:
        """Load plugins from JSON file with validation.
        
        Args:
            path: Path to the cache file.
            
        Returns:
            Dictionary mapping plugin IDs to PluginInfo objects.
        """
        if not path.exists():
            logger.info(f"Cache file not found: {path}")
            return {}
        
        try:
            with open(path, 'r', encoding='utf-8') as f:
                data = json.load(f)
        except json.JSONDecodeError as e:
            logger.error(f"Invalid JSON in cache file {path}: {e}")
            raise CacheCorruptedError(str(path), f"JSON decode error: {e}")
        except Exception as e:
            logger.error(f"Failed to read cache file {path}: {e}")
            raise CacheCorruptedError(str(path), str(e))
        
        # Handle both old format (direct plugin dict) and new format (with metadata)
        if isinstance(data, dict) and "metadata" in data and "plugins" in data:
            # New format with metadata
            metadata = data.get("metadata", {})
            cache_version = metadata.get("version", "1.0.0")
            
            if cache_version != CACHE_VERSION:
                logger.warning(f"Cache version mismatch: expected {CACHE_VERSION}, got {cache_version}")
                raise CacheVersionError(CACHE_VERSION, cache_version, str(path))
            
            plugins_data = data.get("plugins", {})
        else:
            # Old format - direct plugin dictionary
            logger.info("Loading cache in legacy format")
            plugins_data = data
        
        # Convert to PluginInfo objects
        plugins: Dict[str, PluginInfo] = {}
        for plugin_id, plugin_data in plugins_data.items():
            if not isinstance(plugin_data, dict):
                logger.warning(f"Invalid plugin data for ID {plugin_id}")
                continue
            
            plugin = cls.dict_to_plugin(plugin_data)
            if plugin:
                plugins[plugin_id] = plugin
            else:
                logger.warning(f"Failed to deserialize plugin {plugin_id}")
        
        logger.info(f"Loaded {len(plugins)} plugins from {path}")
        return plugins
    
    @classmethod
    def migrate_cache(cls, old_data: Dict[str, Any], old_version: str, new_version: str) -> Dict[str, Any]:
        """Migrate cache data from old version to new version.
        
        Args:
            old_data: Cache data in old format.
            old_version: Version of the old cache format.
            new_version: Target version to migrate to.
            
        Returns:
            Migrated cache data.
        """
        # TODO: Implement cache migration logic as needed
        logger.info(f"Migrating cache from version {old_version} to {new_version}")
        return old_data
</file>

<file path="src/pedalboard_pluginary/types.py">
"""
Type definitions and aliases for the pedalboard_pluginary package.
"""

from typing import Union, Dict, Any, TypedDict, Optional
import sys

if sys.version_info >= (3, 11):
    from typing import NotRequired
else:
    from typing_extensions import NotRequired

# Basic type aliases
ParameterValue = Union[float, bool, str]
PluginID = str
PluginType = str  # "vst3" or "aufx"
PluginPath = str  # String representation of path for JSON serialization


class SerializedParameter(TypedDict):
    """TypedDict for serialized plugin parameter."""
    name: str
    value: ParameterValue


class SerializedPlugin(TypedDict):
    """TypedDict for serialized plugin data."""
    id: str
    name: str
    path: str
    filename: str
    plugin_type: str
    parameters: Dict[str, SerializedParameter]
    manufacturer: NotRequired[Optional[str]]
    name_in_file: NotRequired[Optional[str]]


class CacheMetadata(TypedDict):
    """TypedDict for cache metadata."""
    version: str
    created_at: str
    updated_at: str
    plugin_count: int
    scanner_version: str


class CacheData(TypedDict):
    """TypedDict for complete cache data structure."""
    metadata: CacheMetadata
    plugins: Dict[str, SerializedPlugin]


# Type guards
def is_parameter_value(value: Any) -> bool:
    """Check if a value is a valid ParameterValue."""
    return isinstance(value, (float, bool, str))


def is_serialized_parameter(data: Any) -> bool:
    """Check if data is a valid SerializedParameter."""
    return (
        isinstance(data, dict) and
        "name" in data and
        "value" in data and
        isinstance(data["name"], str) and
        is_parameter_value(data["value"])
    )


def is_serialized_plugin(data: Any) -> bool:
    """Check if data is a valid SerializedPlugin."""
    if not isinstance(data, dict):
        return False
    
    required_fields = ["id", "name", "path", "filename", "plugin_type", "parameters"]
    for field in required_fields:
        if field not in data:
            return False
    
    # Check types of required fields
    if not all(isinstance(data[field], str) for field in ["id", "name", "path", "filename", "plugin_type"]):
        return False
    
    # Check parameters
    if not isinstance(data["parameters"], dict):
        return False
    
    for param_name, param_data in data["parameters"].items():
        if not isinstance(param_name, str) or not is_serialized_parameter(param_data):
            return False
    
    # Check optional fields
    if "manufacturer" in data and data["manufacturer"] is not None:
        if not isinstance(data["manufacturer"], str):
            return False
    
    if "name_in_file" in data and data["name_in_file"] is not None:
        if not isinstance(data["name_in_file"], str):
            return False
    
    return True
</file>

<file path="tests/scanners/test_vst3_scanner.py">
# tests/scanners/test_vst3_scanner.py
import os
import platform
from pathlib import Path
from unittest.mock import MagicMock, mock_open, patch

import pytest

from pedalboard_pluginary.scanners.vst3_scanner import VST3Scanner


# Helper to create dummy VST3 files and folders
def create_dummy_vst3_structure(tmp_path, structure):
    """
    Creates a dummy VST3 plugin directory structure.
    structure is a dict like:
    {
        "folder_name": ["plugin1.vst3", "plugin2.vst3", {"subfolder": ["plugin3.vst3"]}]
    }
    """
    for name, contents in structure.items():
        current_path = tmp_path / name
        current_path.mkdir(parents=True, exist_ok=True)
        for item in contents:
            if isinstance(item, str):  # It's a file
                (current_path / item).touch()
            elif isinstance(item, dict):  # It's a sub-structure
                create_dummy_vst3_structure(current_path, item)


@pytest.fixture
def vst3_scanner_instance():
    return VST3Scanner()


@pytest.fixture
def vst3_scanner_with_ignores_instance():
    return VST3Scanner(ignore_paths=["vst3/IgnoredPlugin"])


class TestVST3Scanner:
    @patch("platform.system", return_value="Windows")
    @patch.dict(
        os.environ,
        {
            "ProgramFiles": "C:\\Program Files",
            "ProgramFiles(x86)": "C:\\Program Files (x86)",
        },
    )
    def test_get_default_vst3_folders_windows(
        self, mock_platform_system, vst3_scanner_instance, tmp_path
    ):
        # Create dummy common VST3 folders for Windows
        win_vst3_path1 = tmp_path / "Program Files" / "Common Files" / "VST3"
        win_vst3_path1.mkdir(parents=True, exist_ok=True)
        win_vst3_path2 = tmp_path / "Program Files (x86)" / "Common Files" / "VST3"
        win_vst3_path2.mkdir(parents=True, exist_ok=True)

        # Patch os.getenv to return mocked ProgramFiles paths relative to tmp_path
        def mock_getenv_windows(var_name, default=None):
            if var_name == "ProgramFiles":
                return str(tmp_path / "Program Files")
            if var_name == "ProgramFiles(x86)":
                return str(tmp_path / "Program Files (x86)")
            return default

        with patch("os.getenv", side_effect=mock_getenv_windows):
            folders = vst3_scanner_instance._get_default_vst3_folders()
            assert Path(win_vst3_path1).resolve() in folders
            assert Path(win_vst3_path2).resolve() in folders

    @patch("platform.system", return_value="Darwin")
    def test_get_default_vst3_folders_macos(
        self, mock_platform_system, vst3_scanner_instance, tmp_path
    ):
        mac_vst3_path1 = tmp_path / "Library" / "Audio" / "Plug-Ins" / "VST3"  # System
        mac_vst3_path1.mkdir(parents=True, exist_ok=True)
        # User path needs to be mocked for expanduser
        user_home_vst3_path = (
            tmp_path / "Users" / "testuser" / "Library" / "Audio" / "Plug-Ins" / "VST3"
        )
        user_home_vst3_path.mkdir(parents=True, exist_ok=True)

        with (
            patch("pathlib.Path.home", return_value=tmp_path / "Users" / "testuser"),
            patch(
                "pathlib.Path.expanduser",
                side_effect=lambda p: p
                if not str(p).startswith("~")
                else user_home_vst3_path,
            ),
        ):
            # Mock /Library path to point to our tmp_path version
            original_path_init = Path.__init__

            def mocked_path_init(self, *args, **kwargs):
                if args and args[0] == "/Library/Audio/Plug-Ins/VST3":
                    args = (str(mac_vst3_path1),) + args[1:]
                original_path_init(self, *args, **kwargs)

            with patch("pathlib.Path.__init__", mocked_path_init):
                folders = vst3_scanner_instance._get_default_vst3_folders()
                assert user_home_vst3_path.resolve() in folders
                assert mac_vst3_path1.resolve() in folders

    @patch("platform.system", return_value="Linux")
    def test_get_default_vst3_folders_linux(
        self, mock_platform_system, vst3_scanner_instance, tmp_path
    ):
        linux_vst3_path1 = tmp_path / ".vst3"  # User
        linux_vst3_path1.mkdir(parents=True, exist_ok=True)
        linux_vst3_path2 = tmp_path / "usr" / "lib" / "vst3"  # System
        linux_vst3_path2.mkdir(parents=True, exist_ok=True)

        with (
            patch("pathlib.Path.home", return_value=tmp_path),
            patch(
                "pathlib.Path.expanduser",
                side_effect=lambda p: p
                if not str(p).startswith("~")
                else linux_vst3_path1,
            ),
        ):
            # Mock /usr/lib/vst3 to point to our tmp_path version
            original_path_init = Path.__init__

            def mocked_path_init(self, *args, **kwargs):
                if args and args[0] == "/usr/lib/vst3":
                    args = (str(linux_vst3_path2),) + args[1:]
                elif (
                    args and args[0] == "/usr/local/lib/vst3"
                ):  # Also mock this common path
                    args = (str(tmp_path / "usr" / "local" / "lib" / "vst3"),) + args[
                        1:
                    ]
                    (tmp_path / "usr" / "local" / "lib" / "vst3").mkdir(
                        parents=True, exist_ok=True
                    )

                original_path_init(self, *args, **kwargs)

            with patch("pathlib.Path.__init__", mocked_path_init):
                folders = vst3_scanner_instance._get_default_vst3_folders()
                assert linux_vst3_path1.resolve() in folders
                assert linux_vst3_path2.resolve() in folders

    def test_find_plugin_files_discovery(self, vst3_scanner_instance, tmp_path):
        # Create a dummy default folder and put some plugins in it
        default_folder = tmp_path / "DefaultVST3s"
        default_folder.mkdir()
        (default_folder / "PluginA.vst3").touch()
        (default_folder / "PluginB.vst3").touch()

        with patch.object(
            VST3Scanner, "_get_default_vst3_folders", return_value=[default_folder]
        ):
            found_plugins = vst3_scanner_instance.find_plugin_files()
            assert len(found_plugins) == 2
            assert default_folder / "PluginA.vst3" in found_plugins
            assert default_folder / "PluginB.vst3" in found_plugins

    def test_find_plugin_files_with_extra_folders(
        self, vst3_scanner_instance, tmp_path
    ):
        extra_folder1 = tmp_path / "ExtraVST3s1"
        extra_folder1.mkdir()
        (extra_folder1 / "PluginC.vst3").touch()

        extra_folder2 = tmp_path / "ExtraVST3s2"  # Non-existent

        # Mock default folders to be empty to isolate test to extra_folders
        with patch.object(VST3Scanner, "_get_default_vst3_folders", return_value=[]):
            found_plugins = vst3_scanner_instance.find_plugin_files(
                extra_folders=[str(extra_folder1), str(extra_folder2)]
            )
            assert len(found_plugins) == 1
            assert extra_folder1 / "PluginC.vst3" in found_plugins

    def test_find_plugin_files_with_specific_paths(
        self, vst3_scanner_instance, tmp_path
    ):
        plugin_path1 = tmp_path / "SpecificPlugin1.vst3"
        plugin_path1.touch()
        plugin_path2 = tmp_path / "SpecificPlugin2.vst3"  # Non-existent for this call

        found_plugins = vst3_scanner_instance.find_plugin_files(
            plugin_paths=[plugin_path1, plugin_path2]
        )
        assert len(found_plugins) == 1
        assert (
            plugin_path1 in found_plugins
        )  # plugin_path2 should not be found as it doesn't exist yet

    def test_find_plugin_files_with_ignores(
        self, vst3_scanner_with_ignores_instance, tmp_path
    ):
        default_folder = tmp_path / "VST3WithIgnores"
        default_folder.mkdir()
        (default_folder / "NormalPlugin.vst3").touch()
        (
            default_folder / "IgnoredPlugin.vst3"
        ).touch()  # This one has stem "IgnoredPlugin"

        with patch.object(
            VST3Scanner, "_get_default_vst3_folders", return_value=[default_folder]
        ):
            found_plugins = vst3_scanner_with_ignores_instance.find_plugin_files()
            assert len(found_plugins) == 1
            assert default_folder / "NormalPlugin.vst3" in found_plugins
            assert default_folder / "IgnoredPlugin.vst3" not in found_plugins

    def test_find_plugin_files_no_folders_exist(self, vst3_scanner_instance):
        with patch.object(VST3Scanner, "_get_default_vst3_folders", return_value=[]):
            found_plugins = vst3_scanner_instance.find_plugin_files()
            assert len(found_plugins) == 0

    def test_find_plugin_files_skips_directories_with_vst3_suffix(
        self, vst3_scanner_instance, tmp_path
    ):
        default_folder = tmp_path / "VST3WithDirs"
        default_folder.mkdir()
        (default_folder / "RealPlugin.vst3").touch()
        (default_folder / "FakePlugin.vst3").mkdir()  # A directory named like a plugin

        with patch.object(
            VST3Scanner, "_get_default_vst3_folders", return_value=[default_folder]
        ):
            found_plugins = vst3_scanner_instance.find_plugin_files()
            assert len(found_plugins) == 1
            assert default_folder / "RealPlugin.vst3" in found_plugins
            assert default_folder / "FakePlugin.vst3" not in found_plugins


# TODO: Test case where a plugin_path provided to find_plugin_files is a directory (should be ignored)
# TODO: Test case with symlinks if relevant (Path.resolve() should handle them, but good to be aware)
# TODO: Test case for duplicate plugin paths from overlapping folder definitions (should be unique)
#       (find_plugin_files uses a set internally for discovery before sorting, so this should be handled)
</file>

<file path="tests/test_data.py">
import os
from pedalboard_pluginary.data import get_cache_path
from unittest.mock import patch

def test_get_cache_path_windows():
    with patch.dict(os.environ, {"APPDATA": "C:\\Users\\TestUser\\AppData"}):
        path = get_cache_path("test_cache")
        assert str(path) == "C:\\Users\\TestUser\\AppData\\com.twardoch.pedalboard-pluginary\\test_cache.json"

@patch('platform.system', return_value='Darwin')
def test_get_cache_path_macos(mock_platform_system):
    # Test for macOS when APPDATA is not set (should not be used)
    # and XDG_CACHE_HOME is not set (should not be used)
    with patch.dict(os.environ, {}, clear=True):
        path = get_cache_path("test_cache")
        home = os.path.expanduser("~")
        expected_path = f"{home}/Library/Application Support/com.twardoch.pedalboard-pluginary/test_cache.json"
        assert str(path) == expected_path

@patch('platform.system', return_value='Linux')
def test_get_cache_path_linux_xdg_set(mock_platform_system):
    xdg_cache_dir = "/custom/xdg/cache"
    with patch.dict(os.environ, {"XDG_CACHE_HOME": xdg_cache_dir}, clear=True):
        path = get_cache_path("test_cache")
        expected_path = f"{xdg_cache_dir}/com.twardoch.pedalboard-pluginary/test_cache.json"
        assert str(path) == expected_path

@patch('platform.system', return_value='Linux')
def test_get_cache_path_linux_xdg_not_set(mock_platform_system):
    # Test when XDG_CACHE_HOME is not set
    with patch.dict(os.environ, {}, clear=True): # Ensure XDG_CACHE_HOME is not set
        path = get_cache_path("test_cache")
        home = os.path.expanduser("~")
        expected_path = f"{home}/.cache/com.twardoch.pedalboard-pluginary/test_cache.json"
        assert str(path) == expected_path
</file>

<file path=".gitignore">
temp/

# Temporary and binary files
*~
*.py[cod]
*.so
*.cfg
!.isort.cfg
!setup.cfg
*.orig
*.log
*.pot
__pycache__/*
.cache/*
.*.swp
*/.ipynb_checkpoints/*
.DS_Store

# Project files
.ropeproject
.project
.pydevproject
.settings
.idea
.vscode
tags

# Package files
*.egg
*.eggs/
.installed.cfg
*.egg-info

# Unittest and coverage
htmlcov/*
.coverage
.coverage.*
.tox
junit*.xml
coverage.xml
.pytest_cache/

# Build and docs folder/files
build/*
dist/*
sdist/*
docs/api/*
docs/_rst/*
docs/_build/*
cover/*
MANIFEST

# Per-project virtualenvs
.venv*/
.conda*/
.python-version
</file>

<file path=".pre-commit-config.yaml">
exclude: '^docs/conf.py'

repos:
- repo: https://github.com/pre-commit/pre-commit-hooks
  rev: v4.5.0
  hooks:
  - id: trailing-whitespace
  - id: check-added-large-files
  - id: check-ast
  - id: check-json
  - id: check-merge-conflict
  - id: check-xml
  - id: check-yaml
  - id: debug-statements
  - id: end-of-file-fixer
  - id: requirements-txt-fixer
  - id: mixed-line-ending
    args: ['--fix=auto']  # replace 'auto' with 'lf' to enforce Linux/Mac line endings or 'crlf' for Windows

## If you want to automatically "modernize" your Python code:
# - repo: https://github.com/asottile/pyupgrade
#   rev: v3.7.0
#   hooks:
#   - id: pyupgrade
#     args: ['--py37-plus']

## If you want to avoid flake8 errors due to unused vars or imports:
# - repo: https://github.com/PyCQA/autoflake
#   rev: v2.1.1
#   hooks:
#   - id: autoflake
#     args: [
#       --in-place,
#       --remove-all-unused-imports,
#       --remove-unused-variables,
#     ]

- repo: https://github.com/PyCQA/isort
  rev: 5.12.0
  hooks:
  - id: isort

- repo: https://github.com/psf/black
  rev: 23.11.0
  hooks:
  - id: black
    language_version: python3

## If like to embrace black styles even in the docs:
# - repo: https://github.com/asottile/blacken-docs
#   rev: v1.13.0
#   hooks:
#   - id: blacken-docs
#     additional_dependencies: [black]

- repo: https://github.com/PyCQA/flake8
  rev: 6.1.0
  hooks:
  - id: flake8
  ## You can add flake8 plugins via `additional_dependencies`:
  #  additional_dependencies: [flake8-bugbear]

- repo: https://github.com/pre-commit/mirrors-mypy
  rev: v1.7.0 # Or choose the latest version
  hooks:
  - id: mypy
    # You might need to specify `additional_dependencies` for mypy to find your project's dependencies
    # e.g., additional_dependencies: [types-setuptools, types-requests]
    # For this project:
    additional_dependencies: [
      types-setuptools, # For pkg_resources, etc.
      # Add stubs for other dependencies if mypy complains and they exist
      # types-fire, types-tqdm, types-python-benedict might not exist or be mature.
      # For now, we'll rely on inline # type: ignore for problematic libs
      # and the mypy config in pyproject.toml for global settings.
      "pedalboard", # To make mypy aware of pedalboard, even if it has no stubs
      "fire",
      "tqdm",
      "python-benedict"
    ]
    # It's good practice to also configure mypy via pyproject.toml or mypy.ini
    # For example, to specify the Python version, follow imports, etc.
    args: [--config-file=pyproject.toml] # Point to pyproject.toml for config

## Check for misspells in documentation files:
# - repo: https://github.com/codespell-project/codespell
#   rev: v2.2.5
#   hooks:
#   - id: codespell
</file>

<file path="AUTHORS.md">
# Contributors

* Adam Twardoch <adam+github@twardoch.com>
</file>

<file path="PLAN.md">
# Pedalboard Pluginary - Streamlined Implementation Plan

## Executive Summary

This document outlines the remaining work needed to transform Pedalboard Pluginary into a production-ready, high-performance plugin scanner. Based on comprehensive analysis, we've identified critical gaps in performance, testing, and user experience that must be addressed.

## Current State Assessment

### Completed ✅
- Scanner abstraction with protocols and base classes
- Type safety infrastructure with TypedDict and type guards
- Unified serialization layer
- Custom exception hierarchy
- Progress reporting abstraction
- Basic error handling and retry logic
- Constants module for configuration

### Critical Gaps ❌
- No async/concurrent scanning (major performance bottleneck)
- Limited test coverage (~40%)
- Type stubs missing for pedalboard library
- CLI using outdated Fire library
- No timeout handling for hanging plugins
- Single-platform CI/CD pipeline

## Phase 1: Critical Fixes and Type Safety (Immediate - Week 1)

### 1.1 Create Pedalboard Type Stubs

**Problem**: The pedalboard library lacks type annotations, causing numerous mypy errors and requiring type: ignore comments.

**Solution**: Create comprehensive type stubs package.

```python
# src/pedalboard-stubs/__init__.pyi
from typing import Dict, Union, Any, Optional

class Plugin:
    parameters: Dict[str, Union[float, bool, str]]
    name: str
    manufacturer: str
    
class AudioUnitPlugin(Plugin): ...
class VST3Plugin(Plugin): ...

def load_plugin(path: str, plugin_name: Optional[str] = None) -> Plugin: ...
```

**Implementation Steps**:
1. Create `pedalboard-stubs` directory in src
2. Define interfaces for all pedalboard classes we use
3. Add stubs to mypy configuration
4. Remove all type: ignore comments

### 1.2 Implement Timeout Handling

**Problem**: Plugin loading can hang indefinitely on corrupted or incompatible plugins.

**Solution**: Add configurable timeouts using threading or asyncio.

```python
# src/pedalboard_pluginary/timeout.py
import asyncio
import concurrent.futures
from typing import TypeVar, Callable, Any

T = TypeVar('T')

async def with_timeout(coro: Callable[..., T], timeout: float, *args, **kwargs) -> T:
    """Execute coroutine with timeout."""
    return await asyncio.wait_for(coro(*args, **kwargs), timeout)

def sync_timeout(func: Callable[..., T], timeout: float, *args, **kwargs) -> T:
    """Execute synchronous function with timeout."""
    with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
        future = executor.submit(func, *args, **kwargs)
        return future.result(timeout=timeout)
```

### 1.3 Fix Remaining Type Issues

**Tasks**:
1. Replace all `Dict[Any, Any]` with specific types
2. Add return type annotations to all functions
3. Fix SerializedPlugin TypedDict to properly handle optional fields
4. Ensure 100% type coverage with mypy strict mode

## Phase 2: Performance Revolution (Week 2)

### 2.1 Async Scanner Implementation

**Problem**: Sequential scanning is extremely slow for large plugin libraries.

**Solution**: Implement fully async scanner architecture.

```python
# src/pedalboard_pluginary/async_scanner.py
import asyncio
from typing import List, Optional, AsyncIterator
from .protocols import PluginScanner
from .models import PluginInfo

class AsyncScannerMixin:
    """Mixin to add async capabilities to scanners."""
    
    async def scan_plugin_async(self, path: Path) -> Optional[PluginInfo]:
        """Async wrapper for plugin scanning."""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(None, self.scan_plugin, path)
    
    async def scan_plugins_batch(
        self, 
        paths: List[Path], 
        max_concurrent: int = 10
    ) -> AsyncIterator[PluginInfo]:
        """Scan multiple plugins concurrently."""
        semaphore = asyncio.Semaphore(max_concurrent)
        
        async def scan_with_semaphore(path: Path) -> Optional[PluginInfo]:
            async with semaphore:
                return await self.scan_plugin_async(path)
        
        tasks = [scan_with_semaphore(path) for path in paths]
        for coro in asyncio.as_completed(tasks):
            result = await coro
            if result:
                yield result
```

**Implementation Steps**:
1. Create AsyncVST3Scanner and AsyncAUScanner
2. Implement connection pooling for plugin processes
3. Add configurable concurrency limits
4. Update PedalboardScanner to support async mode
5. Benchmark performance improvements (target: 5-10x speedup)

### 2.2 Efficient Cache Management

**Problem**: Loading entire cache into memory is inefficient for large libraries.

**Solution**: Implement lazy loading and indexed access.

```python
# src/pedalboard_pluginary/cache/sqlite_backend.py
import sqlite3
from typing import Dict, Optional, Iterator
from ..models import PluginInfo

class SQLiteCacheBackend:
    """SQLite-based cache with indexed access."""
    
    def __init__(self, db_path: Path):
        self.db_path = db_path
        self._init_db()
    
    def get(self, plugin_id: str) -> Optional[PluginInfo]:
        """Get single plugin without loading entire cache."""
        with self._connect() as conn:
            row = conn.execute(
                "SELECT data FROM plugins WHERE id = ?", 
                (plugin_id,)
            ).fetchone()
            return self._deserialize(row[0]) if row else None
    
    def search(self, query: str) -> Iterator[PluginInfo]:
        """Search plugins without loading all data."""
        with self._connect() as conn:
            for row in conn.execute(
                "SELECT data FROM plugins WHERE name LIKE ? OR manufacturer LIKE ?",
                (f"%{query}%", f"%{query}%")
            ):
                yield self._deserialize(row[0])
```

## Phase 3: CLI Revolution (Week 3)

### 3.1 Migrate to Click

**Problem**: Fire library lacks features needed for professional CLI.

**Solution**: Complete rewrite using Click with rich features.

```python
# src/pedalboard_pluginary/cli.py
import click
from rich.console import Console
from rich.table import Table
from .core import PedalboardPluginary

console = Console()

@click.group()
@click.version_option()
def cli():
    """Pedalboard Pluginary - Audio plugin scanner and manager."""
    pass

@cli.command()
@click.option('--async/--sync', default=True, help='Use async scanning')
@click.option('--concurrency', default=10, help='Max concurrent scans')
@click.option('--timeout', default=10.0, help='Plugin load timeout')
@click.option('--format', type=click.Choice(['json', 'yaml', 'table', 'csv']))
def scan(async_, concurrency, timeout, format):
    """Scan system for audio plugins."""
    with console.status("Scanning plugins..."):
        scanner = PedalboardPluginary(
            async_mode=async_,
            max_concurrent=concurrency,
            timeout=timeout
        )
        plugins = scanner.scan()
    
    _output_plugins(plugins, format)

@cli.command()
@click.argument('plugin_id')
@click.option('--params/--no-params', default=True)
def info(plugin_id, params):
    """Show detailed information about a plugin."""
    # Implementation
```

### 3.2 Interactive TUI Mode

**Solution**: Add textual-based TUI for plugin browsing.

```python
# src/pedalboard_pluginary/tui.py
from textual.app import App
from textual.widgets import ListView, DataTable

class PluginBrowser(App):
    """Interactive plugin browser."""
    
    async def on_mount(self):
        # Load plugins
        # Setup UI
        # Handle events
```

## Phase 4: Testing Excellence (Week 4)

### 4.1 Comprehensive Test Suite

**Target**: 90%+ coverage with real-world scenarios.

```python
# tests/integration/test_full_workflow.py
import pytest
from pathlib import Path
from pedalboard_pluginary import PedalboardPluginary

@pytest.fixture
def test_plugins_dir():
    """Directory with test plugin files."""
    return Path(__file__).parent / "fixtures" / "plugins"

async def test_async_scanning_performance(test_plugins_dir, benchmark):
    """Test async scanning is faster than sync."""
    scanner = PedalboardPluginary(async_mode=True)
    
    async def scan_async():
        return await scanner.scan_directory_async(test_plugins_dir)
    
    result = benchmark(asyncio.run, scan_async)
    assert len(result) > 0

def test_timeout_handling(mock_hanging_plugin):
    """Test that hanging plugins are handled gracefully."""
    scanner = PedalboardPluginary(timeout=1.0)
    result = scanner.scan_plugin(mock_hanging_plugin)
    assert result is None
```

### 4.2 Cross-Platform CI/CD

```yaml
# .github/workflows/test.yml
name: Test
on: [push, pull_request]

jobs:
  test:
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python: ['3.9', '3.10', '3.11', '3.12']
    runs-on: ${{ matrix.os }}
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
      - run: pip install -e .[dev]
      - run: pytest --cov=pedalboard_pluginary --cov-report=xml
      - uses: codecov/codecov-action@v3
```

## Phase 5: Developer Experience (Week 5)

### 5.1 Pre-commit Configuration

```yaml
# .pre-commit-config.yaml
repos:
  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.1.0
    hooks:
      - id: ruff
      - id: ruff-format
  
  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.7.0
    hooks:
      - id: mypy
        additional_dependencies: [types-all]
```

### 5.2 Documentation System

```python
# docs/conf.py
extensions = [
    'sphinx.ext.autodoc',
    'sphinx.ext.napoleon',
    'sphinx_rtd_theme',
    'sphinx_click',
]

# Auto-generate API docs from docstrings
```

## Phase 6: Advanced Features (Week 6)

### 6.1 Plugin Categorization

```python
# src/pedalboard_pluginary/categorizer.py
from enum import Enum
from typing import List

class PluginCategory(Enum):
    EQUALIZER = "eq"
    COMPRESSOR = "comp"
    REVERB = "reverb"
    DELAY = "delay"
    MODULATION = "mod"
    DISTORTION = "dist"
    UTILITY = "util"

def categorize_plugin(plugin: PluginInfo) -> List[PluginCategory]:
    """Auto-categorize plugin based on name and parameters."""
    categories = []
    
    # Rule-based categorization
    if any(word in plugin.name.lower() for word in ['eq', 'equalizer']):
        categories.append(PluginCategory.EQUALIZER)
    
    # Parameter-based categorization
    param_names = {p.name.lower() for p in plugin.parameters.values()}
    if 'threshold' in param_names and 'ratio' in param_names:
        categories.append(PluginCategory.COMPRESSOR)
    
    return categories
```

### 6.2 Export Formats

```python
# src/pedalboard_pluginary/exporters.py
import csv
from typing import List
from .models import PluginInfo

class CSVExporter:
    """Export plugins to CSV format."""
    
    def export(self, plugins: List[PluginInfo], output_path: Path):
        with open(output_path, 'w', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=[
                'id', 'name', 'type', 'manufacturer', 'path', 'category'
            ])
            writer.writeheader()
            for plugin in plugins:
                writer.writerow(self._plugin_to_row(plugin))
```

## Implementation Timeline

### Week 1: Foundation
- [ ] Create pedalboard type stubs
- [ ] Implement timeout handling
- [ ] Fix all remaining type issues
- [ ] Achieve 100% mypy compliance

### Week 2: Performance
- [ ] Implement async scanner architecture
- [ ] Add concurrent scanning support
- [ ] Create SQLite cache backend
- [ ] Benchmark performance improvements

### Week 3: User Experience
- [ ] Migrate from Fire to Click
- [ ] Add rich output formatting
- [ ] Implement interactive TUI
- [ ] Add command completion

### Week 4: Quality Assurance
- [ ] Write comprehensive test suite
- [ ] Set up cross-platform CI/CD
- [ ] Add coverage reporting
- [ ] Create integration tests

### Week 5: Developer Experience
- [ ] Configure pre-commit hooks
- [ ] Set up Sphinx documentation
- [ ] Write API documentation
- [ ] Create contributor guide

### Week 6: Advanced Features
- [ ] Implement plugin categorization
- [ ] Add export formats
- [ ] Create plugin presets
- [ ] Add search functionality

## Success Metrics

### Performance
- Async scanning: 5-10x faster than sync
- Memory usage: < 50MB for 1000 plugins
- Timeout handling: 100% of hanging plugins handled

### Quality
- Test coverage: > 90%
- Type coverage: 100%
- Documentation: 100% of public APIs

### Usability
- CLI response time: < 100ms
- Clear error messages
- Intuitive command structure

## Risk Mitigation

### Technical Risks
1. **Pedalboard API changes**: Version pin and test against multiple versions
2. **Platform differences**: Extensive cross-platform testing
3. **Performance regression**: Automated benchmarks in CI

### Implementation Risks
1. **Scope creep**: Strict phase boundaries
2. **Breaking changes**: Deprecation warnings and migration guides
3. **Complexity growth**: Regular refactoring sessions

## Conclusion

This streamlined plan focuses on the most critical improvements needed to make Pedalboard Pluginary production-ready. By addressing performance through async implementation, improving the user experience with a modern CLI, and ensuring quality through comprehensive testing, we can deliver a professional-grade tool that meets the needs of audio professionals and developers alike.
</file>

<file path="tox.ini">
# Tox configuration file
# Read more under https://tox.wiki/
# THIS SCRIPT IS SUPPOSED TO BE AN EXAMPLE. MODIFY IT ACCORDING TO YOUR NEEDS!

[tox]
minversion = 3.24
envlist = default
isolated_build = True

[testenv]
description = Invoke pytest to run automated tests
setenv =
    TOXINIDIR = {toxinidir}
passenv =
    HOME
    SETUPTOOLS_*
extras =
    testing
commands =
    pytest {posargs}

# To run `tox -e lint` you need to make sure you have a
# `.pre-commit-config.yaml` file. See https://pre-commit.com
# [testenv:lint]
# description = Perform static analysis and style checks
# skip_install = True
# deps = pre-commit
# passenv =
#     HOMEPATH
#     PROGRAMDATA
#     SETUPTOOLS_*
# commands =
#     pre-commit run --all-files {posargs:--show-diff-on-failure}

[testenv:{build,clean}]
description =
    build: Build the package in isolation according to PEP517, see https://github.com/pypa/build
    clean: Remove old distribution files and temporary build artifacts (./build and ./dist)
skip_install = True
changedir = {toxinidir}
deps =
    build: build[virtualenv]
passenv =
    SETUPTOOLS_*
commands =
    clean: python -c 'import shutil; [shutil.rmtree(p, True) for p in ("build", "dist")]'
    clean: python -c 'import pathlib, shutil; [shutil.rmtree(p, True) for p in pathlib.Path("src").glob("*.egg-info")]'
    build: python -m build {posargs}

[testenv:publish]
description =
    Publish the package you have been developing to a package index server.
    By default, it uses testpypi. If you really want to publish your package
    to be publicly accessible in PyPI, use the `-- --repository pypi` option.
skip_install = True
changedir = {toxinidir}
passenv =
    TWINE_USERNAME
    TWINE_PASSWORD
    TWINE_REPOSITORY
    TWINE_REPOSITORY_URL
deps = twine
commands =
    python -m twine check dist/*
    python -m twine upload {posargs:--repository {env:TWINE_REPOSITORY:testpypi}} dist/*
</file>

<file path=".github/workflows/ci.yml">
name: Python package CI

on:
  push:
    branches: [main]
    tags: ['v*']
  pull_request:
  workflow_dispatch:

jobs:
  build-and-test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.9', '3.10', '3.11']
    steps:
    - uses: actions/checkout@v3
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install fire pytest pytest-cov # Added pytest-cov for coverage
    - name: Run tests with coverage
      run: |
        python -m pip install -e .
        # Pytest is configured in pyproject.toml to run with --cov
        # and output to term-missing. It also creates .coverage file.
        pytest
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        # token: ${{ secrets.CODECOV_TOKEN }} # Only if needed for private repos or specific cases
        fail_ci_if_error: true # Optional: fail CI if coverage upload fails

  publish:
    needs: build-and-test
    if: startsWith(github.ref, 'refs/tags/')
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    - name: Build and publish
      env:
        TWINE_USERNAME: __token__
        TWINE_PASSWORD: ${{ secrets.PYPI_TOKEN }}
      run: |
        python -m pip install --upgrade build twine
        python -m build
        twine upload dist/*
</file>

<file path="src/pedalboard_pluginary/__init__.py">
from importlib.metadata import PackageNotFoundError, version

try:
    # Change here if project is renamed and does not equal the package name
    dist_name = __name__
    __version__ = version(dist_name)
except PackageNotFoundError:  # pragma: no cover
    __version__ = "unknown"
finally:
    del version, PackageNotFoundError

from .core import PedalboardPluginary
</file>

<file path="src/pedalboard_pluginary/utils.py">
from pathlib import Path
from typing import Any, Union

def ensure_folder(path: Path) -> None:
    """ Ensure that a folder exists. """
    path.parent.mkdir(parents=True, exist_ok=True)

def from_pb_param(data: Any) -> Union[float, bool, str]:
    """
    Converts a pedalboard parameter value to a Python native type.
    Pedalboard parameter values can be string representations of floats, booleans, or just strings.
    """
    drep = str(data)
    try:
        return float(drep)
    except ValueError:
        pass
    if drep.lower() == "true":
        return True
    if drep.lower() == "false":
        return False
    return drep
</file>

<file path="src/pedalboard_pluginary/core.py">
import json
from pathlib import Path
from typing import Dict

from .data import get_cache_path
from .models import PluginInfo
from .scanner import PedalboardScanner
from .serialization import PluginSerializer


class PedalboardPluginary:
    """Main class for the Pedalboard Pluginary application."""
    
    plugins_path: Path
    plugins: Dict[str, PluginInfo]

    def __init__(self) -> None:
        """Initialize the Pedalboard Pluginary instance."""
        self.plugins_path = get_cache_path("plugins")
        self.plugins = {}
        self.load_data()

    def load_data(self) -> None:
        """Load plugin data from cache or perform a scan if cache doesn't exist."""
        if not self.plugins_path.exists():
            scanner = PedalboardScanner()
            scanner.full_scan()

        # Load plugins using the serializer
        self.plugins = PluginSerializer.load_plugins(self.plugins_path)

    def list_plugins(self) -> str:
        """Returns a JSON string representation of the plugins."""
        # Convert PluginInfo objects to dictionaries for JSON serialization
        plugins_dict = {}
        for plugin_id, plugin in self.plugins.items():
            plugins_dict[plugin_id] = PluginSerializer.plugin_to_dict(plugin)
        
        return json.dumps(plugins_dict, indent=4)
</file>

<file path="src/pedalboard_pluginary/data.py">
import json
import os
import platform
import shutil
from importlib import resources
from pathlib import Path
from typing import Any, Dict, List, Set, Union

# JSON-serializable types
JSONValue = Union[str, int, float, bool, None, Dict[str, Any], List[Any]]
JSONDict = Dict[str, JSONValue]

from .utils import ensure_folder

APP_NAME: str = "com.twardoch.pedalboard-pluginary"
PLUGINS_CACHE_FILENAME_BASE: str = "plugins"  # To identify the plugins cache file


def get_cache_path(cache_name: str) -> Path:
    """Get the path to a cache file."""
    os_name = platform.system()
    if os_name == "Windows":
        app_data_env = os.getenv("APPDATA")
        if app_data_env is None:
            app_data_dir = (
                Path(os.path.expanduser("~")) / "AppData" / "Roaming" / APP_NAME
            )
        else:
            app_data_dir = Path(app_data_env) / APP_NAME
    elif os_name == "Darwin":  # macOS
        app_data_dir = Path.home() / "Library" / "Application Support" / APP_NAME
    else:  # Linux and other Unix-like systems
        xdg_cache_home_env = os.getenv("XDG_CACHE_HOME")
        if xdg_cache_home_env:
            app_data_dir = Path(xdg_cache_home_env) / APP_NAME
        else:
            app_data_dir = Path.home() / ".cache" / APP_NAME

    app_data_dir.mkdir(parents=True, exist_ok=True)  # Ensure base app dir exists
    return app_data_dir / f"{cache_name}.json"


def load_json_file(file_path: Path) -> Any:
    """Load JSON data from a file."""
    if not file_path.exists():
        return {}

    with open(file_path, "r", encoding="utf-8") as file:
        try:
            raw_data = json.load(file)
        except json.JSONDecodeError:
            return {}  # Return empty dict if JSON is corrupted

    return raw_data


def save_json_file(data: Any, file_path: Path) -> None:
    """Save JSON data to a file."""
    ensure_folder(file_path.parent)
    with open(file_path, "w", encoding="utf-8") as file:
        json.dump(data, file, indent=4)


def load_ignores(ignores_path: Path) -> Set[str]:
    """Load ignores data (list of strings) from the file."""
    content = load_json_file(ignores_path)
    if isinstance(content, list):  # Expects a list of strings
        return set(item for item in content if isinstance(item, str))
    return set()


def save_ignores(ignores: Set[str], ignores_path: Path) -> None:
    """Save ignores data to the file."""
    save_json_file(sorted(list(ignores)), ignores_path)


def copy_default_ignores(destination_path: Path) -> None:
    """Copy the default ignores file to the destination if it does not exist."""
    try:
        import importlib.resources

        default_ignores_src_path = importlib.resources.files(
            "pedalboard_pluginary.resources"
        ).joinpath("default_ignores.json")

        if not destination_path.exists():
            ensure_folder(destination_path.parent)
            with importlib.resources.as_file(
                default_ignores_src_path
            ) as src_file_on_fs:
                if src_file_on_fs.exists():
                    shutil.copy(src_file_on_fs, destination_path)
                else:
                    save_json_file([], destination_path)
    except (ImportError, FileNotFoundError, TypeError) as e:
        print(
            f"Warning: Could not copy default ignores using importlib.resources: {e}. Creating empty ignores file."
        )
        if not destination_path.exists():
            ensure_folder(destination_path.parent)
            save_json_file([], destination_path)
</file>

<file path="pyproject.toml">
[build-system]
requires = ["hatchling", "hatch-vcs"]
build-backend = "hatchling.build"

[tool.setuptools_scm]
version_scheme = "no-guess-dev"

[project]
name = "pedalboard-pluginary"
version = "0.1.0"
description = "A plugin scanner for Pedalboard"
readme = "README.md"
requires-python = ">=3.9"
license = { text = "Apache-2.0" }
authors = [
    { name = "Adam Twardoch", email = "adam@twardoch.com" }
]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: Apache Software License",
    "Operating System :: OS Independent",
    "Programming Language :: Python",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Topic :: Multimedia :: Sound/Audio",
    "Topic :: Software Development :: Libraries :: Python Modules",
]
dependencies = [
    "pedalboard>=0.8.7",
    "fire>=0.5.0",
    "python-benedict>=0.33.0",
    "pyyaml>=6.0.1",
    "typing-extensions>=4.0.0; python_version < '3.11'",
    "tqdm>=4.60.0",
]

[project.urls]
Documentation = "https://github.com/twardoch/pedalboard-pluginary#readme"
Source = "https://github.com/twardoch/pedalboard-pluginary"
Tracker = "https://github.com/twardoch/pedalboard-pluginary/issues"

[project.optional-dependencies]
dev = [
    "pytest>=7.4.4",
    "pytest-cov>=4.1.0",
    "mypy>=1.8.0",
    "flake8>=7.0.0",
    "black>=24.1.1",
    "isort>=5.13.2",
]

[project.scripts]
pbpluginary = "pedalboard_pluginary.__main__:main"

[tool.setuptools]
packages = ["pedalboard_pluginary"]
package-dir = {"" = "src"}

[tool.pytest.ini_options]
addopts = "--cov=pedalboard_pluginary --cov-report=term-missing"
testpaths = ["tests"]

[tool.flake8]
max_line_length = 88
extend_ignore = "E203,W503"
exclude = [
    ".tox",
    "build",
    "dist",
    ".eggs",
    "docs/conf.py",
]

[tool.mypy]
python_version = "3.9"
mypy_path = "src"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_incomplete_defs = true
check_untyped_defs = true
disallow_untyped_decorators = true
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_no_return = true
warn_unreachable = true

[[tool.mypy.overrides]]
module = ["fire", "benedict"]
ignore_missing_imports = true

[tool.black]
line-length = 88
target-version = ['py39']
include = '\.pyi?$'

[tool.isort]
profile = "black"
multi_line_output = 3
</file>

<file path="src/pedalboard_pluginary/scanners/vst3_scanner.py">
"""
Handles scanning of VST3 plugins.
"""

import logging
import os
import platform
from pathlib import Path
from typing import Dict, List, Optional

import pedalboard

from ..base_scanner import BaseScanner
from ..constants import PLUGIN_TYPE_VST3, VST3_EXTENSION, PLUGIN_LOAD_TIMEOUT
from ..exceptions import PluginLoadError, PluginScanError
from ..models import PluginInfo, PluginParameter
from ..timeout import sync_timeout, TimeoutError
from ..utils import from_pb_param

logger = logging.getLogger(__name__)


class VST3Scanner(BaseScanner):
    """Scanner for VST3 plugins."""
    
    @property
    def plugin_type(self) -> str:
        """Return the plugin type this scanner handles."""
        return PLUGIN_TYPE_VST3
    
    @property
    def supported_extensions(self) -> List[str]:
        """Return list of file extensions this scanner supports."""
        return [VST3_EXTENSION]
    
    def _get_default_vst3_folders(self) -> List[Path]:
        """Get standard VST3 plugin folders for the current OS."""
        os_name = platform.system()
        folders: List[Path] = []
        
        if os_name == "Windows":
            program_files = os.getenv("ProgramFiles", "C:\\Program Files")
            program_files_x86 = os.getenv("ProgramFiles(x86)", "C:\\Program Files (x86)")
            folders = [
                Path(program_files) / "Common Files" / "VST3",
                Path(program_files_x86) / "Common Files" / "VST3",
            ]
        elif os_name == "Darwin":  # macOS
            folders = [
                Path("~/Library/Audio/Plug-Ins/VST3").expanduser(),
                Path("/Library/Audio/Plug-Ins/VST3"),
            ]
        elif os_name == "Linux":
            folders = [
                Path("~/.vst3").expanduser(),
                Path("/usr/lib/vst3"),
                Path("/usr/local/lib/vst3"),
            ]
        
        return [f for f in folders if f.exists()]
    
    def find_plugin_files(self, paths: Optional[List[Path]] = None) -> List[Path]:
        """Find all VST3 plugin files in standard and custom folders.
        
        Args:
            paths: Optional list of specific paths to check.
            
        Returns:
            List of paths to VST3 plugin files found.
        """
        if paths:
            # Filter specific paths to only VST3 files
            vst3_paths = [p for p in paths if p.suffix in self.supported_extensions]
            return self._filter_plugin_paths(vst3_paths)
        
        # Search default VST3 folders
        search_folders = self._get_default_vst3_folders()
        
        if not search_folders:
            logger.warning("No VST3 folders to search.")
            return []
        
        logger.info(f"Searching for VST3 plugins in: {search_folders}")
        
        # Find all VST3 files
        discovered_plugins = set()
        for folder in search_folders:
            try:
                for vst3_file in folder.glob("*.vst3"):
                    if vst3_file.is_file():
                        discovered_plugins.add(vst3_file.resolve())
            except Exception as e:
                logger.error(f"Error searching folder {folder}: {e}")
        
        # Apply filtering
        plugin_list = sorted(list(discovered_plugins))
        filtered_list = self._filter_plugin_paths(plugin_list)
        
        logger.info(f"Found {len(filtered_list)} VST3 plugins after filtering.")
        return filtered_list
    
    def scan_plugin(self, path: Path) -> Optional[PluginInfo]:
        """Scan a VST3 plugin and return its information.
        
        Args:
            path: Path to the VST3 plugin file.
            
        Returns:
            PluginInfo object if successful, None if scanning failed.
        """
        if not self.validate_plugin_path(path):
            logger.warning(f"Invalid plugin path: {path}")
            return None
        
        try:
            # Load the plugin to get its parameters with timeout
            logger.debug(f"Loading VST3 plugin: {path}")
            plugin = sync_timeout(pedalboard.load_plugin, PLUGIN_LOAD_TIMEOUT, str(path))
            
            # Extract parameters
            params: Dict[str, PluginParameter] = {}
            if hasattr(plugin, 'parameters'):
                for param_name, param_value in plugin.parameters.items():
                    # Convert the parameter value to our expected type
                    converted_value = from_pb_param(param_value)
                    params[param_name] = PluginParameter(
                        name=param_name,
                        value=converted_value,
                    )
            
            # Try to get manufacturer info if available
            manufacturer = None
            if hasattr(plugin, 'manufacturer'):
                manufacturer = str(plugin.manufacturer)
            
            # Get the plugin's display name if available
            display_name = path.stem
            if hasattr(plugin, 'name'):
                display_name = str(plugin.name)
            
            plugin_info = PluginInfo(
                id=self._create_plugin_id(path),
                name=display_name,
                path=str(path),
                filename=path.name,
                plugin_type=self.plugin_type,
                parameters=params,
                manufacturer=manufacturer,
            )
            
            logger.info(f"Successfully scanned VST3 plugin: {display_name}")
            return plugin_info
            
        except TimeoutError as e:
            logger.warning(f"VST3 plugin {path} timed out during loading: {e}")
            raise PluginLoadError(
                plugin_path=str(path),
                reason=f"Plugin loading timed out after {e.timeout}s"
            )
        except PluginLoadError:
            # Re-raise our custom exceptions
            raise
        except Exception as e:
            logger.error(f"Error scanning VST3 plugin {path}: {e}")
            raise PluginScanError(
                plugin_path=str(path),
                scanner_type=self.plugin_type,
                reason=str(e)
            )
</file>

<file path="src/pedalboard_pluginary/__main__.py">
#!/usr/bin/env python3
# benedict might also lack stubs.
import json
import logging  # For basicConfig
import sys  # For sys.stdout in Display lambda
from pathlib import Path
from typing import Any, Callable, Dict, List, Optional

import fire
import yaml

# fire library might not have complete type stubs, common to ignore if problematic for mypy.
# Consider adding types-fire if available and it resolves issues.
from benedict import benedict as bdict

from .core import PedalboardPluginary
from .data import (
    PLUGINS_CACHE_FILENAME_BASE,
    get_cache_path,
    load_json_file,
    save_json_file,
)
from .models import PluginInfo
from .types import SerializedPlugin
from .scanner import PedalboardScanner

# Define a more specific type for extra_folders if it's always List[str] after split
ExtraFoldersType = Optional[List[str]]


def setup_logging(verbose_level: int = 0) -> None:
    """Configures basic logging for CLI output."""
    # verbose_level: 0 = WARNING, 1 = INFO, 2 = DEBUG
    log_level = logging.WARNING
    if verbose_level == 1:
        log_level = logging.INFO
    elif verbose_level >= 2:
        log_level = logging.DEBUG

    # Only configure if no handlers are already set (e.g., by tests or other imports)
    # This basicConfig will go to stderr by default for WARNING and above.
    # For INFO, let's direct to stdout for better CLI experience.
    if not logging.getLogger().hasHandlers():
        if log_level <= logging.INFO:
            # For INFO and DEBUG, use a more verbose format and stdout
            logging.basicConfig(
                stream=sys.stdout,
                level=log_level,
                format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
            )
        else:
            # For WARNING, ERROR, CRITICAL, use stderr and simpler format
            logging.basicConfig(
                level=log_level, format="%(levelname)s: %(name)s: %(message)s"
            )


def scan_plugins_cli(extra_folders: Optional[str] = None, verbose: int = 0) -> None:
    """Scans all plugins, optionally including extra folders (comma-separated string)."""
    folders_list: List[str] = extra_folders.split(",") if extra_folders else []
    scanner = PedalboardScanner(specific_paths=folders_list)
    scanner.full_scan()  # This updates scanner.plugins
    if scanner.plugins:  # Only save if we found plugins
        cache_file = get_cache_path(PLUGINS_CACHE_FILENAME_BASE)
        save_json_file(scanner.plugins, cache_file)


def update_plugins_cli(extra_folders: Optional[str] = None, verbose: int = 0) -> None:
    """Updates the plugin cache, optionally including extra folders (comma-separated string)."""
    scan_plugins_cli(extra_folders, verbose)


def list_json_cli() -> Dict[str, SerializedPlugin]:
    """Lists all plugins in JSON format."""
    cache_file = get_cache_path(PLUGINS_CACHE_FILENAME_BASE)
    if not cache_file.exists():
        return {}
    data = load_json_file(cache_file)
    return data if isinstance(data, dict) else {}


def list_yaml_cli() -> str:
    """Lists all plugins in YAML format."""
    plugins = list_json_cli()
    return yaml.dump(plugins, sort_keys=False, indent=2)


def main() -> None:
    """Main entry point for the CLI."""
    fire.Fire({
        "scan": scan_plugins_cli,
        "list": list_json_cli,
        "json": list_json_cli,
        "yaml": list_yaml_cli,
        "update": update_plugins_cli,
    })


if __name__ == "__main__":
    main()
</file>

<file path="CHANGELOG.md">
# Changelog

All notable changes to this project will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [Unreleased]

### Added
- Created PLAN.md for implementation roadmap
- Created TODO.md for task tracking
- Created CHANGELOG.md for version history

### Changed
- Refactored scanner architecture to use modular scanner classes
- Improved type annotations throughout the codebase

### Fixed
- Fixed duplicate imports in scanner.py
- Fixed duplicate full_scan method definitions
- Fixed missing attributes in PedalboardScanner class (ignores, ignores_path)
- Fixed incorrect method calls to scanner instances
- Fixed parameter order in save_json_file calls
- Fixed VST3Scanner inheritance issue (removed BaseScanner dependency)
- Fixed missing scan_plugin method implementations in scanner classes
- Implemented proper plugin parameter extraction using pedalboard API
- Added progress bars using tqdm for plugin scanning
- Enhanced AU scanner with fallback to auval for metadata extraction
- Improved VST3 scanner with manufacturer and display name extraction

### Removed
- Removed obsolete scan_aufx_plugins and scan_vst3_plugins methods
- Removed redundant BaseScanner class definition in scanner.py
- Removed unnecessary type aliases in scanner modules

### Enhanced
- Rewrote VST3Scanner to properly load plugins and extract parameters
- Rewrote AUScanner to properly load plugins with fallback to auval
- Added proper plugin metadata extraction (manufacturer, display name)
- Improved plugin path discovery for both VST3 and AU formats
- Created scanner abstraction layer with BaseScanner class
- Added Protocol definitions for scanner interfaces
- Implemented type safety improvements with types.py
- Refactored scanners to use common base class functionality
- Created unified serialization layer with PluginSerializer
- Added cache versioning and metadata support
- Improved type safety with TypedDict definitions
- Centralized all JSON operations in serialization module
- Created custom exception hierarchy for better error handling
- Added constants module for configuration values
- Implemented progress reporting abstraction with multiple backends
- Added retry decorator for transient failures
- Enhanced error handling throughout the codebase
- Added py.typed marker for type checking support
- Fixed most mypy type errors
- Added typing-extensions dependency for Python 3.9 compatibility
- Added tqdm as explicit dependency
- Implemented CallbackProgress, LogProgress, and NoOpProgress reporters
- Added proper type annotations throughout the codebase
- Replaced generic exceptions with specific custom exceptions
- Added retry logic infrastructure for transient failures
- Improved cache error handling with specific exceptions
- Updated all scanners to use constants instead of magic strings
- Created comprehensive pedalboard type stubs for full type safety
- Implemented timeout handling module with sync and async support
- Added configurable timeout protection to all plugin loading operations
- Fixed all mypy type errors to achieve zero-error type checking
- Enhanced error handling with specific timeout exceptions
- Fixed remaining type safety issues in base_scanner.py and __main__.py
- Achieved 100% mypy compliance in strict mode with zero errors
- Completed Phase 1: Critical Fixes and Type Safety implementation

## [1.1.0] - Previous Release

### Added
- Added `update` CLI command which only scans plugins that aren't cached yet
- Added `json` and `yaml` CLI commands

### Changed
- Additional refactorings

## [1.0.0] - Initial Release

### Added
- Initial release with basic scanning and listing of both VST-3 and AU plugins
- Command-line interface for easy interaction
- Support for macOS and Windows (Windows untested)
- Plugin parameter extraction with default values
- JSON cache file for plugin information
- Blacklist functionality for problematic plugins
</file>

<file path="TODO.md">
# Pedalboard Pluginary - Production Readiness TODO

## Phase 1: Critical Fixes and Type Safety

### Pedalboard Type Stubs
- [ ] Create pedalboard-stubs directory structure
- [ ] Define Plugin, AudioUnitPlugin, VST3Plugin interfaces
- [ ] Add load_plugin function signature
- [ ] Configure mypy to use stubs
- [ ] Remove all type: ignore comments

### Timeout Handling
- [ ] Create timeout.py module
- [ ] Implement sync_timeout function with ThreadPoolExecutor
- [ ] Implement async with_timeout function
- [ ] Add timeout support to all plugin loading operations
- [ ] Add timeout configuration to constants

### Type Safety Completion
- [ ] Replace all Dict[Any, Any] with specific types
- [ ] Add return type annotations to all functions
- [ ] Fix SerializedPlugin TypedDict optional field handling
- [ ] Run mypy in strict mode with zero errors
- [ ] Update utils.py and data.py type annotations

## Phase 2: Performance Revolution

### Async Scanner Architecture
- [ ] Create AsyncScannerMixin class
- [ ] Implement scan_plugin_async method
- [ ] Add scan_plugins_batch with semaphore
- [ ] Create AsyncVST3Scanner class
- [ ] Create AsyncAUScanner class
- [ ] Update PedalboardScanner for async support
- [ ] Add configurable concurrency limits
- [ ] Benchmark performance improvements

### Efficient Cache Management
- [ ] Create cache/ package
- [ ] Implement SQLiteCacheBackend class
- [ ] Add indexed search capabilities
- [ ] Implement lazy loading for large caches
- [ ] Create MemoryCacheBackend for testing
- [ ] Add cache backend selection configuration

## Phase 3: CLI Revolution

### Migrate to Click
- [ ] Install click and rich dependencies
- [ ] Create new cli.py module
- [ ] Implement scan command with options
- [ ] Add list command with filtering
- [ ] Create info command for plugin details
- [ ] Add cache management commands
- [ ] Implement config get/set commands
- [ ] Add rich console output formatting

### Enhanced CLI Features
- [ ] Add table output format
- [ ] Implement CSV export
- [ ] Add search functionality
- [ ] Create plugin filtering options
- [ ] Add command completion support
- [ ] Implement verbose/quiet modes

### Interactive TUI (Optional)
- [ ] Install textual dependency
- [ ] Create tui.py module
- [ ] Implement plugin browser interface
- [ ] Add search and filter widgets
- [ ] Create plugin detail view

## Phase 4: Testing Excellence

### Comprehensive Test Suite
- [ ] Create test fixtures with mock plugins
- [ ] Write unit tests for serialization
- [ ] Test error handling scenarios
- [ ] Add timeout handling tests
- [ ] Create integration tests
- [ ] Add performance benchmarks
- [ ] Test async scanning functionality

### Cross-Platform CI/CD
- [ ] Create .github/workflows/test.yml
- [ ] Add matrix testing for Python 3.9-3.12
- [ ] Test on Ubuntu, Windows, macOS
- [ ] Add coverage reporting with codecov
- [ ] Set up automated benchmark comparisons

## Phase 5: Developer Experience

### Pre-commit Configuration
- [ ] Create .pre-commit-config.yaml
- [ ] Configure ruff for linting and formatting
- [ ] Set up mypy pre-commit hook
- [ ] Add pytest pre-commit hook
- [ ] Install and configure pre-commit hooks

### Documentation System
- [ ] Install sphinx and dependencies
- [ ] Create docs/ directory structure
- [ ] Configure sphinx for API documentation
- [ ] Write comprehensive docstrings
- [ ] Create user guide with examples
- [ ] Add troubleshooting documentation

### Build and Release
- [ ] Configure setuptools_scm for version management
- [ ] Set up automated PyPI releases
- [ ] Create GitHub release workflow
- [ ] Add release notes automation

## Phase 6: Advanced Features

### Plugin Categorization
- [ ] Create categorizer.py module
- [ ] Define PluginCategory enum
- [ ] Implement rule-based categorization
- [ ] Add parameter-based classification
- [ ] Create category-based filtering

### Export and Import
- [ ] Create exporters.py module
- [ ] Implement CSV export
- [ ] Add JSON export with metadata
- [ ] Create plugin preset system
- [ ] Add bulk import capabilities

### Search and Discovery
- [ ] Implement full-text search
- [ ] Add fuzzy matching
- [ ] Create tag-based organization
- [ ] Add plugin recommendations
- [ ] Implement plugin dependency tracking

## Quality Gates

### Phase 1 Completion Criteria
- [ ] Zero mypy errors in strict mode
- [ ] All plugins load with timeout protection
- [ ] 100% type annotation coverage

### Phase 2 Completion Criteria
- [ ] Async scanning 5x faster than sync
- [ ] SQLite cache working for 1000+ plugins
- [ ] Memory usage < 50MB baseline

### Phase 3 Completion Criteria
- [ ] New CLI fully replaces Fire-based interface
- [ ] Rich output formatting working
- [ ] All commands have comprehensive help

### Phase 4 Completion Criteria
- [ ] >90% test coverage
- [ ] CI passing on all platforms
- [ ] Performance benchmarks in place

### Phase 5 Completion Criteria
- [ ] Pre-commit hooks enforcing quality
- [ ] Complete API documentation
- [ ] Automated release process

### Phase 6 Completion Criteria
- [ ] Plugin categorization working
- [ ] Export formats functional
- [ ] Search capabilities implemented

## Dependencies to Add

### Core Dependencies
- [ ] click>=8.0.0 (CLI framework)
- [ ] rich>=13.0.0 (output formatting)
- [ ] textual>=0.40.0 (TUI - optional)

### Development Dependencies
- [ ] sphinx>=7.0.0 (documentation)
- [ ] sphinx-rtd-theme (documentation theme)
- [ ] sphinx-click (CLI documentation)
- [ ] pre-commit>=3.0.0 (quality hooks)
- [ ] pytest-benchmark (performance testing)
- [ ] pytest-asyncio (async testing)

## Current Status

### Completed ✅
- Scanner abstraction with protocols
- Type safety infrastructure
- Unified serialization layer
- Custom exception hierarchy
- Progress reporting abstraction
- Constants module
- Retry logic infrastructure

### In Progress 🚧
- Type stub creation
- Timeout handling implementation

### Next Priority 📋
1. Complete type stubs for pedalboard
2. Implement timeout handling
3. Begin async scanner architecture
4. Migrate CLI to Click framework

## Notes

- Maintain backward compatibility where possible
- Use deprecation warnings for breaking changes
- Keep dependencies minimal and well-maintained
- Focus on reliability over features
- Ensure cross-platform compatibility
</file>

<file path="src/pedalboard_pluginary/scanners/au_scanner.py">
"""
Handles scanning of Audio Unit (AU) plugins on macOS.
"""

import logging
import platform
import subprocess
from pathlib import Path
from typing import Dict, List, Optional

import pedalboard

from ..base_scanner import BaseScanner
from ..constants import AU_EXTENSION, PLATFORM_MACOS, PLUGIN_TYPE_AU, PLUGIN_LOAD_TIMEOUT
from ..exceptions import PlatformError, PluginLoadError, PluginScanError
from ..models import PluginInfo, PluginParameter
from ..timeout import sync_timeout, TimeoutError
from ..utils import from_pb_param

logger = logging.getLogger(__name__)


class AUScanner(BaseScanner):
    """Scanner for Audio Unit plugins."""
    
    def __init__(
        self,
        ignore_paths: Optional[List[str]] = None,
        specific_paths: Optional[List[str]] = None,
    ):
        """Initialize the AU scanner with optional ignore paths and specific paths."""
        super().__init__(ignore_paths, specific_paths)
        self._is_macos = platform.system() == PLATFORM_MACOS
        if not self._is_macos:
            logger.info("AU scanning is only available on macOS.")
    
    @property
    def plugin_type(self) -> str:
        """Return the plugin type this scanner handles."""
        return PLUGIN_TYPE_AU
    
    @property
    def supported_extensions(self) -> List[str]:
        """Return list of file extensions this scanner supports."""
        return [AU_EXTENSION]
    
    def _get_au_plugin_locations(self) -> List[Path]:
        """Get standard AU plugin locations on macOS."""
        return [
            Path("/Library/Audio/Plug-Ins/Components"),
            Path("~/Library/Audio/Plug-Ins/Components").expanduser(),
            Path("/System/Library/Components"),
        ]
    
    def _list_aufx_plugins_raw(self) -> List[str]:
        """List all Audio Unit effects plugins using auval."""
        if not self._is_macos:
            return []
        
        try:
            result = subprocess.run(
                ["auval", "-a"], 
                capture_output=True, 
                text=True, 
                check=True,
                timeout=30
            )
            return result.stdout.splitlines()
        except (subprocess.CalledProcessError, subprocess.TimeoutExpired, FileNotFoundError) as e:
            logger.warning(f"Failed to run auval command: {e}")
            return []
    
    def _parse_aufx_path_from_auval(self, plugin_str: str) -> Optional[Path]:
        """Parse the AU plugin path from auval output."""
        parts = plugin_str.strip().split()
        if len(parts) >= 3 and parts[0] == "aufx":
            bundle_id = parts[2]
            
            # Search in standard locations
            for location in self._get_au_plugin_locations():
                if location.exists():
                    # First try exact match
                    component_path = location / f"{bundle_id}.component"
                    if component_path.exists():
                        return component_path
                    
                    # Then search for partial match
                    for component in location.glob("*.component"):
                        if bundle_id in str(component):
                            return component
        
        return None
    
    def find_plugin_files(self, paths: Optional[List[Path]] = None) -> List[Path]:
        """Find all AU plugin files.
        
        Args:
            paths: Optional list of specific paths to check.
            
        Returns:
            List of paths to AU plugin files found.
        """
        if not self._is_macos:
            return []
        
        if paths:
            # Filter specific paths to only AU component files
            au_paths = [p for p in paths if p.suffix in self.supported_extensions]
            return self._filter_plugin_paths(au_paths)
        
        # Use auval to discover plugins
        discovered_plugins = []
        auval_output = self._list_aufx_plugins_raw()
        
        for line in auval_output:
            if line.strip().startswith("aufx"):
                plugin_path = self._parse_aufx_path_from_auval(line)
                if plugin_path:
                    discovered_plugins.append(plugin_path)
        
        # Also scan standard directories for any missed plugins
        for location in self._get_au_plugin_locations():
            if location.exists():
                try:
                    for component in location.glob("*.component"):
                        if component not in discovered_plugins:
                            discovered_plugins.append(component)
                except Exception as e:
                    logger.error(f"Error scanning directory {location}: {e}")
        
        # Apply filtering
        filtered_list = self._filter_plugin_paths(discovered_plugins)
        logger.info(f"Found {len(filtered_list)} AU plugins after filtering.")
        return filtered_list
    
    def scan_plugin(self, path: Path) -> Optional[PluginInfo]:
        """Scan an AU plugin and return its information.
        
        Args:
            path: Path to the AU plugin file.
            
        Returns:
            PluginInfo object if successful, None if scanning failed.
        """
        if not self.validate_plugin_path(path):
            logger.warning(f"Invalid plugin path: {path}")
            return None
        
        try:
            # Try to load the plugin using pedalboard with timeout
            logger.debug(f"Loading AU plugin: {path}")
            plugin = sync_timeout(pedalboard.load_plugin, PLUGIN_LOAD_TIMEOUT, str(path))
            
            # Extract parameters
            params: Dict[str, PluginParameter] = {}
            if hasattr(plugin, 'parameters'):
                for param_name, param_value in plugin.parameters.items():
                    # Convert the parameter value to our expected type
                    converted_value = from_pb_param(param_value)
                    params[param_name] = PluginParameter(
                        name=param_name,
                        value=converted_value,
                    )
            
            # Try to get manufacturer info
            manufacturer = None
            if hasattr(plugin, 'manufacturer'):
                manufacturer = str(plugin.manufacturer)
            
            # Get the plugin's display name
            display_name = path.stem
            if hasattr(plugin, 'name'):
                display_name = str(plugin.name)
            
            plugin_info = PluginInfo(
                id=self._create_plugin_id(path),
                name=display_name,
                path=str(path),
                filename=path.name,
                plugin_type=self.plugin_type,
                parameters=params,
                manufacturer=manufacturer,
            )
            
            logger.info(f"Successfully scanned AU plugin: {display_name}")
            return plugin_info
            
        except TimeoutError as e:
            logger.warning(f"AU plugin {path} timed out during loading: {e}")
            # Fall back to basic info extraction from auval
            return self._scan_with_auval(path)
        except PluginLoadError:
            # Re-raise our custom exceptions
            raise
        except Exception as e:
            logger.error(f"Failed to scan AU plugin {path} with pedalboard: {e}")
            # Fall back to basic info extraction from auval
            return self._scan_with_auval(path)
    
    def _scan_with_auval(self, path: Path) -> Optional[PluginInfo]:
        """Scan plugin using auval as fallback method."""
        try:
            result = subprocess.run(
                ["auval", "-v", str(path)],
                capture_output=True,
                text=True,
                timeout=10,
            )
            
            # Parse basic info from auval output
            name = path.stem
            manufacturer = None
            
            for line in result.stdout.splitlines():
                if "NAME:" in line:
                    name = line.split("NAME:", 1)[1].strip()
                elif "MANUFACTURER:" in line:
                    manufacturer = line.split("MANUFACTURER:", 1)[1].strip()
            
            if name:
                plugin_info = PluginInfo(
                    id=self._create_plugin_id(path),
                    name=name,
                    path=str(path),
                    filename=path.name,
                    plugin_type=self.plugin_type,
                    manufacturer=manufacturer,
                    parameters={},  # No parameters from auval
                )
                logger.info(f"Scanned AU plugin with auval: {name}")
                return plugin_info
                
        except (subprocess.CalledProcessError, subprocess.TimeoutExpired, FileNotFoundError) as e:
            logger.error(f"Failed to scan {path} with auval: {e}")
        
        return None
</file>

<file path="src/pedalboard_pluginary/scanner.py">
import json
import logging
from pathlib import Path
from typing import Any, Dict, List, Optional

import pedalboard

from .data import (
    copy_default_ignores,
    get_cache_path,
    load_ignores,
    save_json_file,
)
from .exceptions import CacheCorruptedError, PluginScanError
from .models import PluginInfo, PluginParameter
from .progress import TqdmProgress
from .protocols import ProgressReporter
from .scanners.au_scanner import AUScanner
from .scanners.vst3_scanner import VST3Scanner
from .serialization import PluginSerializer
from .utils import ensure_folder, from_pb_param

logger: logging.Logger = logging.getLogger(__name__)


class PedalboardScanner:
    """Main scanner class that coordinates scanning of all plugin types."""

    def __init__(
        self,
        ignore_paths: Optional[List[str]] = None,
        specific_paths: Optional[List[str]] = None,
        progress_reporter: Optional[ProgressReporter] = None,
    ):
        """Initialize the scanner with optional ignore paths and specific paths.
        
        Args:
            ignore_paths: List of regex patterns for paths to ignore.
            specific_paths: List of specific paths to scan.
            progress_reporter: Optional progress reporter instance.
        """
        self.ignore_paths = ignore_paths or []
        self.specific_paths = specific_paths or []
        self.plugins: Dict[str, PluginInfo] = {}
        self.plugins_path = get_cache_path("plugins")
        self.ignores_path = get_cache_path("ignores")
        self.progress_reporter = progress_reporter or TqdmProgress()
        
        # Initialize ignores
        copy_default_ignores(self.ignores_path)
        self.ignores = load_ignores(self.ignores_path)
        
        # Initialize scanners
        self.scanners = [
            AUScanner(
                ignore_paths=self.ignore_paths, specific_paths=self.specific_paths
            ),
            VST3Scanner(
                ignore_paths=self.ignore_paths, specific_paths=self.specific_paths
            ),
        ]
        
        # Load existing plugin data if available
        self.load_data()

    def load_data(self) -> None:
        """Load existing plugin data from cache."""
        try:
            self.plugins = PluginSerializer.load_plugins(self.plugins_path)
        except CacheCorruptedError as e:
            logger.warning(f"Cache corrupted, will perform full scan: {e}")
            self.plugins = {}

    def save_data(self) -> None:
        """Save plugin data to cache."""
        PluginSerializer.save_plugins(self.plugins, self.plugins_path)
        
        # Save updated ignores
        save_json_file(list(self.ignores), self.ignores_path)

    def full_scan(self) -> Dict[str, PluginInfo]:
        """Perform a full scan of all plugin types."""
        self.plugins = {}
        total_files = 0
        
        # First, count all plugin files
        all_plugin_files = []
        for scanner in self.scanners:
            plugin_files = scanner.find_plugin_files()
            all_plugin_files.extend([(scanner, pf) for pf in plugin_files])
            total_files += len(plugin_files)
        
        # Scan all plugins with progress reporting
        self.progress_reporter.start(total_files, "Scanning plugins")
        
        for scanner, plugin_file in all_plugin_files:
            plugin_key = f"{scanner.__class__.__name__.replace('Scanner', '').lower()}:{plugin_file}"
            
            # Skip ignored plugins
            if plugin_key in self.ignores:
                logger.info(f"Skipping ignored plugin: {plugin_file}")
                self.progress_reporter.update(1, f"Skipped: {plugin_file.name}")
                continue
            
            try:
                plugin_info = scanner.scan_plugin(plugin_file)
                if plugin_info:
                    self.plugins[plugin_info.id] = plugin_info
                    logger.info(f"Scanned plugin: {plugin_file}")
                    self.progress_reporter.update(1, f"Scanned: {plugin_info.name}")
                else:
                    self.progress_reporter.update(1)
            except PluginScanError as e:
                logger.error(f"Failed to scan plugin {plugin_file}: {e}")
                self.ignores.add(plugin_key)
                self.progress_reporter.update(1, f"Failed: {plugin_file.name}")
            except Exception as e:
                logger.error(f"Unexpected error scanning {plugin_file}: {e}")
                self.ignores.add(plugin_key)
                self.progress_reporter.update(1, f"Error: {plugin_file.name}")
        
        self.progress_reporter.finish(f"Scanned {len(self.plugins)} plugins")
        
        # Save the results
        self.save_data()
        return self.plugins

    def update_scan(self) -> Dict[str, PluginInfo]:
        """Update the scan with new plugins while preserving existing data."""
        # Keep track of existing plugins
        existing_plugins = set(self.plugins.keys())
        new_plugins = {}
        
        # Find all plugin files
        all_plugin_files = []
        for scanner in self.scanners:
            plugin_files = scanner.find_plugin_files()
            all_plugin_files.extend([(scanner, pf) for pf in plugin_files])
        
        # Only scan plugins that aren't already in the cache
        plugins_to_scan = []
        for scanner, plugin_file in all_plugin_files:
            plugin_type = scanner.__class__.__name__.replace('Scanner', '').lower()
            plugin_key = f"{plugin_type}:{plugin_file}"
            
            if plugin_key not in existing_plugins and plugin_key not in self.ignores:
                plugins_to_scan.append((scanner, plugin_file, plugin_key))
        
        # Scan new plugins with progress reporting
        if plugins_to_scan:
            self.progress_reporter.start(len(plugins_to_scan), "Scanning new plugins")
            
            for scanner, plugin_file, plugin_key in plugins_to_scan:
                try:
                    plugin_info = scanner.scan_plugin(plugin_file)
                    if plugin_info:
                        self.plugins[plugin_info.id] = plugin_info
                        new_plugins[plugin_info.id] = plugin_info
                        logger.info(f"Scanned new plugin: {plugin_file}")
                        self.progress_reporter.update(1, f"Scanned: {plugin_info.name}")
                    else:
                        self.progress_reporter.update(1)
                except PluginScanError as e:
                    logger.error(f"Failed to scan plugin {plugin_file}: {e}")
                    self.ignores.add(plugin_key)
                    self.progress_reporter.update(1, f"Failed: {plugin_file.name}")
                except Exception as e:
                    logger.error(f"Unexpected error scanning {plugin_file}: {e}")
                    self.ignores.add(plugin_key)
                    self.progress_reporter.update(1, f"Error: {plugin_file.name}")
            
            self.progress_reporter.finish(f"Found {len(new_plugins)} new plugins")
            
            # Save updated data
            self.save_data()
        
        return new_plugins

    def get_json(self) -> str:
        """Return the plugins data as a JSON string."""
        # Use the serializer to convert plugins to dict format
        plugins_dict = {}
        for key, plugin_info in self.plugins.items():
            plugins_dict[key] = PluginSerializer.plugin_to_dict(plugin_info)
        
        return json.dumps(plugins_dict, indent=2)
</file>

<file path="README.md">
# Pedalboard Pluginary

[![Codecov](https://codecov.io/gh/twardoch/pedalboard-pluginary/branch/main/graph/badge.svg?token=YOUR_CODECOV_TOKEN_HERE)](https://codecov.io/gh/twardoch/pedalboard-pluginary)
<!-- Replace YOUR_CODECOV_TOKEN_HERE with the actual token from Codecov if needed, or remove the token part if your repo is public and Codecov supports tokenless uploads for it.
The URL should also be verified once the repo is active on Codecov. -->

_Pedalboard Pluginary_ is an independent Python-based package and command-line tool that scans and lists VST-3 plugins on macOS and Windows, and Audio Unit (AU) plugins on macOS. It’s intended as a companion for the _[Pedalboard](https://github.com/spotify/pedalboard)_ Python library by Spotify, but it’s not affiliated with _Pedalboard_ or Spotify.

## Features

With _Pedalboard Pluginary_, you can scan and list VST-3 and AU audio plugins installed on your machine, including their default parameters. 

- It automatically scans and catalogs VST-3 and AU plugins installed on your system.
- Provides a command-line interface (CLI) for quick access to your plugin library.
- Saves the plugin information in a JSON file. This file has the information about the plugin parameters and their default values. 
- Works on Windows and macOS (Windows is currently untested).
- It bundles an `ignores.json` file, which “blacklists” some plugins that are known to cause issues with Pedalboard. It will not scan these, and will not include them in the cache. If you find that some plugins are not working with Pedalboard, you can add them to your `ignores.json` file. See “Contributing” section below.

## Future plans

I plan to extend the package with another functionality, “jobs”, which will allow to load a stack of plugins with their parameter values from a dictionary or JSON file, and run them in a batch using Pedalboard. 

## Installation

To install _Pedalboard Pluginary_, run:

```bash
python3 -m pip install --upgrade pedalboard-pluginary
```

For the current development version:

```bash
python3 -m pip install --upgrade git+https://github.com/twardoch/pedalboard-pluginary
```

## Command-line usage

After installation, you can use `pbpluginary` from the command line.

### Commands:

- `pbpluginary list` displays the plugin information stored in the cache, as a JSON. If no cache exists, it will scan your system and create the cache.
- `pbpluginary scan` scans all available plugins, and caches the information. Run this if you’ve installed or upgraded some VST-3 or AU plugins.

## Python usage

You can use _Pedalboard Pluginary_ as a library in your Python scripts. Here's a quick example:

```python
from pedalboard_pluginary import PedalboardPluginary

pluginary = PedalboardPluginary()
print(pluginary.list_plugins())
```

This snippet will list all plugins that have been scanned and cached, as a JSON.

## Changes

- **v1.1.0**: Added `update` CLI command which only scans plugins that aren’t cached yet. Not perfect. Added `json` and `yaml` CLI commands. Additional refactorings. 
- **v1.0.0**: Initial release with basic scanning and listing of both VST-3 and AU plugins, and command-line interface for easy interaction.

## License

- **Pedalboard Pluginary** is written by Adam Twardoch, with assistance from GPT-4.
- Copyright (c) 2023 Adam Twardoch.
- Licensed under the [Apache-2.0 license](https://raw.githubusercontent.com/twardoch/pedalboard-pluginary/main/LICENSE.txt).
- _Pedalboard Pluginary_ is not affiliated with [Pedalboard](https://github.com/spotify/pedalboard) or Spotify.

## Contributing

- If you encounter any issues or have suggestions, feel free to open an [issue](https://github.com/twardoch/pedalboard-pluginary/issues) on GitHub. 
- If you find that some plugins are not working with Pedalboard, open an issue that lists the key, which is the plugin type and the base filename, like `"aufx/CoreAudio"` or `"vst3/RX 10 Connect"`. You can also modify the [`default_ignores.json`](https://raw.githubusercontent.com/twardoch/pedalboard-pluginary/main/src/pedalboard_pluginary/resources/default_ignores.json) file, and submit a pull request.
- If you want to contribute code, please open a pull request.
</file>

</files>
